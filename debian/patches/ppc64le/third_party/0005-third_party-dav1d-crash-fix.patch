Index: b/third_party/dav1d/libdav1d/src/ppc/cdef_init_tmpl.c
--- a/third_party/dav1d/libdav1d/src/ppc/cdef_init_tmpl.c
+++ b/third_party/dav1d/libdav1d/src/ppc/cdef_init_tmpl.c
@@ -89,7 +89,15 @@ static inline void copy4xN(uint16_t *tmp
     vec_st(l0, 0, tmp + (h + 0) * 8);
     vec_st(l1, 0, tmp + (h + 1) * 8);
 
-    for (int y = 0; y < h; y++) {
+    int y_with_left_edge = 0;
+    if (!(edges & CDEF_HAVE_LEFT)) {
+        u16x8 l = u8h_to_u16(vec_vsx_ld(0, src));
+        vec_vsx_st(l, 0, tmp + 2);
+
+        y_with_left_edge = 1;
+    }
+
+    for (int y = y_with_left_edge; y < h; y++) {
         u16x8 l = u8h_to_u16(vec_vsx_ld(0, src - 2 + y * src_stride));
         vec_st(l, 0, tmp + y * 8);
     }
@@ -167,7 +175,18 @@ static inline void copy8xN(uint16_t *tmp
     vec_st(l1h, 0, tmp + (h + 1) * 16);
     vec_st(l1l, 0, tmp + (h + 1) * 16 + 8);
 
-    for (int y = 0; y < h; y++) {
+    int y_with_left_edge = 0;
+    if (!(edges & CDEF_HAVE_LEFT)) {
+        u8x16 l = vec_vsx_ld(0, src);
+        u16x8 lh = u8h_to_u16(l);
+        u16x8 ll = u8l_to_u16(l);
+        vec_vsx_st(lh, 0, tmp + 2);
+        vec_vsx_st(ll, 0, tmp + 8 + 2);
+
+        y_with_left_edge = 1;
+    }
+
+    for (int y = y_with_left_edge; y < h; y++) {
         u8x16 l = vec_vsx_ld(0, src - 2 + y * src_stride);
         u16x8 lh = u8h_to_u16(l);
         u16x8 ll = u8l_to_u16(l);
@@ -464,7 +483,7 @@ static void cdef_filter_##w##x##h##_vsx(
                                         const int damping, \
                                         const enum CdefEdgeFlags edges) \
 { \
-    ALIGN_STK_16(uint16_t, tmp_buf, 12 * tmp_stride,); \
+    ALIGN_STK_16(uint16_t, tmp_buf, 12 * tmp_stride + 8,); \
     uint16_t *tmp = tmp_buf + 2 * tmp_stride + 2; \
     filter_##w##xN(dst, dst_stride, left, top, bottom, w, h, pri_strength, \
                    sec_strength, dir, damping, edges, tmp_stride, tmp); \
Index: b/third_party/dav1d/libdav1d/src/ppc/looprestoration_init_tmpl.c
--- a/third_party/dav1d/libdav1d/src/ppc/looprestoration_init_tmpl.c
+++ b/third_party/dav1d/libdav1d/src/ppc/looprestoration_init_tmpl.c
@@ -52,12 +52,12 @@ static void wiener_filter_h_vsx(int32_t
                                 const int16_t filterh[8],
                                 const int w, const int h)
 {
-    static const i32x4 zerov = vec_splats(0);
-    static const i32x4 seven_vec = vec_splats(7);
-    static const i32x4 bitdepth_added_vec = vec_splats(1 << 14);
-    static const i32x4 round_bits_vec = vec_splats(3);
-    static const i32x4 rounding_off_vec = vec_splats(1<<2);
-    static const i32x4 clip_limit_v = vec_splats((1 << 13) - 1);
+    const i32x4 zerov = vec_splats(0);
+    const i32x4 seven_vec = vec_splats(7);
+    const i32x4 bitdepth_added_vec = vec_splats(1 << 14);
+    const i32x4 round_bits_vec = vec_splats(3);
+    const i32x4 rounding_off_vec = vec_splats(1<<2);
+    const i32x4 clip_limit_v = vec_splats((1 << 13) - 1);
 
     i16x8 filterhvall = vec_vsx_ld(0, filterh);
     i16x8 filterhv0 =  vec_splat( filterhvall, 0);
@@ -130,8 +130,8 @@ static void wiener_filter_h_vsx(int32_t
 }
 
 static inline i16x8 iclip_u8_vec(i16x8 v) {
-    static const i16x8 zerov = vec_splats((int16_t)0);
-    static const i16x8 maxv = vec_splats((int16_t)255);
+    const i16x8 zerov = vec_splats((int16_t)0);
+    const i16x8 maxv = vec_splats((int16_t)255);
     v = vec_max(zerov, v);
     v = vec_min(maxv, v);
     return v;
@@ -177,8 +177,8 @@ static inline void wiener_filter_v_vsx(u
                                        const int16_t filterv[8],
                                        const int w, const int h)
 {
-    static const i32x4 round_bits_vec = vec_splats(11);
-    static const i32x4 round_vec = vec_splats((1 << 10) - (1 << 18));
+    const i32x4 round_bits_vec = vec_splats(11);
+    const i32x4 round_vec = vec_splats((1 << 10) - (1 << 18));
 
     i32x4 filterv0 =  vec_splats((int32_t) filterv[0]);
     i32x4 filterv1 =  vec_splats((int32_t) filterv[1]);
