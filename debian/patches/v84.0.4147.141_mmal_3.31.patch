--- a/src/base/debug/stack_trace_posix.cc
+++ b/src/base/debug/stack_trace_posix.cc
@@ -834,7 +834,9 @@ size_t CollectStackTrace(void** trace, s
   // NOTE: This code MUST be async-signal safe (it's used by in-process
   // stack dumping signal handler). NO malloc or stdio is allowed here.
 
+// ARM backtrace sometimes MAPERRs
 #if !defined(__UCLIBC__) && !defined(_AIX)
+//#if !defined(__UCLIBC__) && !defined(_AIX) && !(defined(OS_LINUX) && defined(__arm__) && !defined(_DEBUG))
   // Though the backtrace API man page does not list any possible negative
   // return values, we take no chance.
   return base::saturated_cast<size_t>(backtrace(trace, count));
--- a/src/build/.gitignore
+++ b/src/build/.gitignore
@@ -20,6 +20,8 @@ ciopfs
 /x64/
 /linux/debian_*-sysroot/
 /linux/ubuntu_*-sysroot/
+/linux/ubuntu_*-sysroot/
+/linux/raspian_*-sysroot/
 /ios_files
 /mac_files
 
--- a/src/build/config/linux/BUILD.gn
+++ b/src/build/config/linux/BUILD.gn
@@ -5,6 +5,7 @@
 import("//build/config/c++/c++.gni")
 import("//build/config/chromeos/ui_mode.gni")
 import("//build/config/linux/pkg_config.gni")
+import("//build/config/sysroot.gni")
 import("//build/config/ui.gni")
 
 group("linux") {
@@ -41,6 +42,7 @@ config("x11") {
     "X11-xcb",
     "xcb",
     "xcb-dri3",
+    "xcb-shm",
     "Xcomposite",
     "Xcursor",
     "Xdamage",
@@ -50,6 +52,9 @@ config("x11") {
     "Xrender",
     "Xtst",
   ]
+  if (current_cpu == "arm") {
+     libs += [ "xcb-image" ]
+  }
 }
 
 config("xcomposite") {
@@ -111,3 +116,14 @@ if (use_glib) {
 config("export_dynamic") {
   ldflags = [ "-rdynamic" ]
 }
+
+# MMAL ld flags
+config("use_mmal") {
+  if (is_linux && target_cpu == "arm") {
+    ldflags = [
+      "-L$sysroot/opt/vc/lib",
+      "-Wl,--rpath=/opt/vc/lib,--rpath-link=$sysroot/opt/vc/lib",
+      "-Wl,--start-group", "-lbcm_host", "-lmmal", "-lmmal_util", "-lmmal_core", "-lmmal_vc_client", "-lvcos", "-lvcsm", "-lvchostif", "-lvchiq_arm", "-Wl,--end-group",
+    ]
+  }
+}
--- a/src/build/config/linux/atk/BUILD.gn
+++ b/src/build/config/linux/atk/BUILD.gn
@@ -10,7 +10,7 @@ import("//build/config/ui.gni")
 assert(!is_chromeos)
 
 # These packages should _only_ be expected when building for a target.
-assert(current_toolchain == default_toolchain)
+#assert(current_toolchain == default_toolchain)
 
 if (use_atk) {
   assert(use_glib, "use_atk=true requires that use_glib=true")
--- a/src/cc/layers/video_frame_provider.h
+++ b/src/cc/layers/video_frame_provider.h
@@ -97,6 +97,8 @@ class CC_EXPORT VideoFrameProvider {
   // the client.
   virtual base::TimeDelta GetPreferredRenderInterval() = 0;
 
+  virtual void DidStretchFrame(uint32_t width, uint32_t height) {}
+
  protected:
   virtual ~VideoFrameProvider() {}
 };
--- a/src/cc/mojo_embedder/async_layer_tree_frame_sink.h
+++ b/src/cc/mojo_embedder/async_layer_tree_frame_sink.h
@@ -136,6 +136,7 @@ class CC_MOJO_EMBEDDER_EXPORT AsyncLayer
   void OnBeginFramePausedChanged(bool paused) override;
   void ReclaimResources(
       const std::vector<viz::ReturnedResource>& resources) override;
+  void DidStretchFrame(uint32_t width, uint32_t height) override {}
 
   // ExternalBeginFrameSourceClient implementation.
   void OnNeedsBeginFrames(bool needs_begin_frames) override;
--- a/src/cc/test/test_layer_tree_frame_sink.h
+++ b/src/cc/test/test_layer_tree_frame_sink.h
@@ -104,6 +104,7 @@ class TestLayerTreeFrameSink : public La
                     const viz::FrameTimingDetailsMap& timing_details) override;
   void ReclaimResources(
       const std::vector<viz::ReturnedResource>& resources) override;
+  void DidStretchFrame(uint32_t width, uint32_t height) override {}
   void OnBeginFramePausedChanged(bool paused) override;
 
   // DisplayClient implementation.
--- a/src/chrome/BUILD.gn
+++ b/src/chrome/BUILD.gn
@@ -251,6 +251,16 @@ if (!is_android && !is_mac) {
         ldflags += [ "-Wl,--long-plt" ]
       }
 
+      # Add pi link stuff
+      # * is there a better place?
+      if (is_linux && target_cpu == "arm") {
+        configs += [ "//build/config/linux:use_mmal" ]
+        if (symbol_level >= 2) {
+          # For debug symbols!
+          ldflags += [ "-Wl,--long-plt" ]
+        }
+      }
+
       if (is_desktop_linux && !is_component_build && !using_sanitizer) {
         version_script = "//build/linux/chrome.map"
         inputs = [ version_script ]
--- a/src/chrome/app/chrome_main_delegate.cc
+++ b/src/chrome/app/chrome_main_delegate.cc
@@ -54,6 +54,7 @@
 #include "components/nacl/common/buildflags.h"
 #include "components/services/heap_profiling/public/cpp/profiling_client.h"
 #include "components/startup_metric_utils/browser/startup_metric_utils.h"
+#include "components/version_info/pi_patch_version_info.h"
 #include "components/version_info/version_info.h"
 #include "content/public/common/content_client.h"
 #include "content/public/common/content_constants.h"
@@ -341,6 +342,15 @@ bool HandleVersionSwitches(const base::C
   }
 #endif
 
+  if (command_line.HasSwitch(switches::kPiPatchVersion)) {
+    printf("%s %s %s\nPi patch: %s\n",
+           version_info::GetProductName().c_str(),
+           version_info::GetVersionNumber().c_str(),
+           chrome::GetChannelName().c_str(),
+           version_info::GetPiPatchVersionString().c_str());
+    return true;
+  }
+
   if (command_line.HasSwitch(switches::kVersion)) {
     printf("%s %s %s\n", version_info::GetProductName().c_str(),
            version_info::GetVersionNumber().c_str(),
--- a/src/chrome/common/chrome_switches.cc
+++ b/src/chrome/common/chrome_switches.cc
@@ -454,6 +454,9 @@ const char kPermissionRequestApiScope[]
 // TODO(bauerb): Remove when this flag is not needed anymore.
 const char kPermissionRequestApiUrl[]       = "permission-request-api-url";
 
+// Print the patch version and return
+const char kPiPatchVersion[] = "pi-patch-version";
+
 // Use the PPAPI (Pepper) Flash found at the given path.
 const char kPpapiFlashPath[]                = "ppapi-flash-path";
 
--- a/src/chrome/common/chrome_switches.h
+++ b/src/chrome/common/chrome_switches.h
@@ -136,6 +136,7 @@ extern const char kPackExtension[];
 extern const char kPackExtensionKey[];
 extern const char kPermissionRequestApiScope[];
 extern const char kPermissionRequestApiUrl[];
+extern const char kPiPatchVersion[];
 extern const char kPpapiFlashPath[];
 extern const char kPpapiFlashVersion[];
 extern const char kPrivetIPv6Only[];
--- a/src/components/version_info/BUILD.gn
+++ b/src/components/version_info/BUILD.gn
@@ -14,6 +14,9 @@ static_library("version_info") {
   sources = [
     "version_info.cc",
     "version_info.h",
+    "pi_patch_version_info.cc",
+    "pi_patch_version_info.h",
+    "pi_patch_version_values.h",
   ]
 
   deps = [
--- /dev/null
+++ b/src/components/version_info/pi_patch_version_info.cc
@@ -0,0 +1,11 @@
+#include "components/version_info/pi_patch_version_info.h"
+#include "components/version_info/pi_patch_version_values.h"
+
+namespace version_info {
+
+std::string GetPiPatchVersionString() {
+  return PI_PATCH_VERSION_STRING;
+}
+
+}  // namespace version_info
+
--- /dev/null
+++ b/src/components/version_info/pi_patch_version_info.h
@@ -0,0 +1,12 @@
+#ifndef COMPONENTS_PI_PATCH_VERSION_INFO_VERSION_INFO_H_
+#define COMPONENTS_PI_PATCH_VERSION_INFO_VERSION_INFO_H_
+
+#include <string>
+
+namespace version_info {
+
+// Returns a string with the patch tag for our patches
+std::string GetPiPatchVersionString();
+
+}  // namespace version_info
+#endif  // COMPONENTS_VERSION_INFO_VERSION_INFO_H_
--- /dev/null
+++ b/src/components/version_info/pi_patch_version_values.h
@@ -0,0 +1,2 @@
+// Pi patch version - generated by pi-util/settag.py
+#define PI_PATCH_VERSION_STRING "mmal_3.31"
--- a/src/components/viz/common/resources/transferable_resource.h
+++ b/src/components/viz/common/resources/transferable_resource.h
@@ -80,6 +80,9 @@ struct VIZ_COMMON_EXPORT TransferableRes
   // The number of pixels in the gpu mailbox/software bitmap.
   gfx::Size size;
 
+  // Interline stride (for images) - 0 => not an image - use width
+  uint32_t stride = 0;
+
   // The format of the pixels in the gpu mailbox/software bitmap. This should
   // almost always be RGBA_8888 for resources generated by compositor clients,
   // and must be RGBA_8888 always for software resources.
--- a/src/components/viz/host/host_gpu_memory_buffer_manager.cc
+++ b/src/components/viz/host/host_gpu_memory_buffer_manager.cc
@@ -46,7 +46,7 @@ HostGpuMemoryBufferManager::HostGpuMemor
       client_id_(client_id),
       gpu_memory_buffer_support_(std::move(gpu_memory_buffer_support)),
       task_runner_(std::move(task_runner)) {
-#if !defined(USE_X11)
+#if !defined(USE_X11) || RPI_PIXMAP  // (gpu_memory_buffer_support.h)  RPI needs configs fot Pi4
   native_configurations_ = gpu::GetNativeGpuMemoryBufferConfigurations(
       gpu_memory_buffer_support_.get());
   native_configurations_initialized_.Signal();
--- a/src/components/viz/service/BUILD.gn
+++ b/src/components/viz/service/BUILD.gn
@@ -76,6 +76,7 @@ viz_component("service") {
     "display/shader.cc",
     "display/shader.h",
     "display/shared_bitmap_manager.h",
+    "display/shared_bitmap_manager.cc",
     "display/skia_output_surface.cc",
     "display/skia_output_surface.h",
     "display/skia_renderer.cc",
@@ -218,6 +219,14 @@ viz_component("service") {
 
   if (use_x11) {
     sources += [
+      "display/overlay_processor_shm_x11.cc",
+      "display/overlay_processor_shm_x11.h",
+
+      "display/overlay_processor_using_strategy.cc",
+      "display/overlay_processor_using_strategy.h",
+
+      "display_embedder/shared_image_x11.cc",
+      "display_embedder/shared_image_x11.h",
       "display_embedder/software_output_device_x11.cc",
       "display_embedder/software_output_device_x11.h",
     ]
--- a/src/components/viz/service/display/display.cc
+++ b/src/components/viz/service/display/display.cc
@@ -508,7 +508,7 @@ void Display::InitializeRenderer(bool en
         &settings_, output_surface_.get(), resource_provider_.get(),
         overlay_processor_.get(), current_task_runner_);
   } else {
-    DCHECK(!overlay_processor_->IsOverlaySupported());
+//    DCHECK(!overlay_processor_->IsOverlaySupported());
     auto renderer = std::make_unique<SoftwareRenderer>(
         &settings_, output_surface_.get(), resource_provider_.get(),
         overlay_processor_.get());
--- a/src/components/viz/service/display/display_resource_provider.cc
+++ b/src/components/viz/service/display/display_resource_provider.cc
@@ -18,6 +18,7 @@
 #include "components/viz/common/resources/resource_sizes.h"
 #include "components/viz/service/display/shared_bitmap_manager.h"
 #include "components/viz/service/display/skia_output_surface.h"
+#include "components/viz/service/display_embedder/shared_image_x11.h"
 #include "gpu/GLES2/gl2extchromium.h"
 #include "gpu/command_buffer/client/context_support.h"
 #include "gpu/command_buffer/client/gles2_interface.h"
@@ -455,7 +456,8 @@ void DisplayResourceProvider::PopulateSk
       SkImageInfo::MakeN32Premul(resource->transferable.size.width(),
                                  resource->transferable.size.height());
   bool pixels_installed = sk_bitmap->installPixels(
-      info, resource->shared_bitmap->pixels(), info.minRowBytes());
+      info, resource->shared_bitmap->pixels(),
+      std::max((size_t)info.minRowBytes(), (size_t)resource->transferable.stride));
   DCHECK(pixels_installed);
 }
 
@@ -493,7 +495,7 @@ GLES2Interface* DisplayResourceProvider:
 }
 
 const DisplayResourceProvider::ChildResource*
-DisplayResourceProvider::LockForRead(ResourceId id) {
+DisplayResourceProvider::LockForRead(ResourceId id, bool no_bitmap_fetch) {
   // TODO(ericrk): We should never fail TryGetResource, but we appear to be
   // doing so on Android in rare cases. Handle this gracefully until a better
   // solution can be found. https://crbug.com/811858
@@ -526,7 +528,7 @@ DisplayResourceProvider::LockForRead(Res
     }
   }
 
-  if (!resource->shared_bitmap && !resource->is_gpu_resource_type()) {
+  if (!no_bitmap_fetch && !resource->shared_bitmap && !resource->is_gpu_resource_type()) {
     const SharedBitmapId& shared_bitmap_id = mailbox;
     std::unique_ptr<SharedBitmap> bitmap =
         shared_bitmap_manager_->GetSharedBitmapFromId(
@@ -986,6 +988,36 @@ DisplayResourceProvider::ScopedReadLockS
   return *this;
 }
 
+#if USE_SHARED_IMAGE_X11
+DisplayResourceProvider::ScopedReadLockSharedImageX11::ScopedReadLockSharedImageX11(
+    DisplayResourceProvider* resource_provider,
+    viz::ResourceId resource_id)
+    : xshm_(nullptr),
+      resource_provider_(resource_provider),
+      resource_id_(resource_id)
+{
+  const ChildResource * const resource = resource_provider->LockForRead(resource_id, true);
+
+  xshm_ = resource_provider_->shared_bitmap_manager_->GetSharedImageX11FromId(
+      resource->transferable.size,
+      resource->transferable.stride,
+      resource->transferable.format,
+      resource->transferable.mailbox_holder.mailbox);
+
+  if (!xshm_)
+  {
+    // No point in holding a lock if we don't have any memory
+    resource_provider_->UnlockForRead(resource_id);
+  }
+}
+
+DisplayResourceProvider::ScopedReadLockSharedImageX11::~ScopedReadLockSharedImageX11() {
+  if (xshm_) {
+    resource_provider_->UnlockForRead(resource_id_);
+  }
+}
+#endif
+
 DisplayResourceProvider::LockSetForExternalUse::LockSetForExternalUse(
     DisplayResourceProvider* resource_provider,
     ExternalUseClient* client)
--- a/src/components/viz/service/display/display_resource_provider.h
+++ b/src/components/viz/service/display/display_resource_provider.h
@@ -24,6 +24,7 @@
 #include "components/viz/common/resources/transferable_resource.h"
 #include "components/viz/service/display/external_use_client.h"
 #include "components/viz/service/display/resource_fence.h"
+#include "components/viz/service/display_embedder/shared_image_x11.h"
 #include "components/viz/service/viz_service_export.h"
 #include "gpu/command_buffer/common/sync_token.h"
 #include "third_party/khronos/GLES2/gl2.h"
@@ -47,6 +48,8 @@ namespace viz {
 class ContextProvider;
 class ScopedAllowGpuAccessForDisplayResourceProvider;
 class SharedBitmapManager;
+class SharedImageX11;
+class BitmapData;
 
 // This class provides abstractions for receiving and using resources from other
 // modules/threads/processes. It abstracts away GL textures vs GpuMemoryBuffers
@@ -207,6 +210,29 @@ class VIZ_SERVICE_EXPORT DisplayResource
     sk_sp<SkImage> sk_image_;
   };
 
+#if USE_SHARED_IMAGE_X11
+  class VIZ_SERVICE_EXPORT ScopedReadLockSharedImageX11 {
+  public:
+    ScopedReadLockSharedImageX11(DisplayResourceProvider* resource_provider,
+                           ResourceId resource_id);
+    ~ScopedReadLockSharedImageX11();
+
+    SharedImageX11 * shared_image_x11() const {
+      DCHECK(valid());
+      return xshm_.get();
+    }
+
+    bool valid() const { return xshm_ != nullptr; }
+
+   private:
+    scoped_refptr<SharedImageX11> xshm_;
+    DisplayResourceProvider* resource_provider_;
+    ResourceId resource_id_;
+
+    DISALLOW_COPY_AND_ASSIGN(ScopedReadLockSharedImageX11);
+  };
+#endif
+
  private:
   // Forward declared for LockSetForExternalUse below.
   struct ChildResource;
@@ -521,7 +547,7 @@ class VIZ_SERVICE_EXPORT DisplayResource
   // Returns null if we do not have a ContextProvider.
   gpu::gles2::GLES2Interface* ContextGL() const;
 
-  const ChildResource* LockForRead(ResourceId id);
+  const ChildResource* LockForRead(ResourceId id, bool no_bitmap_fetch = false);
   void UnlockForRead(ResourceId id);
 
   void TryReleaseResource(ResourceId id, ChildResource* resource);
--- a/src/components/viz/service/display/overlay_processor_interface.cc
+++ b/src/components/viz/service/display/overlay_processor_interface.cc
@@ -21,6 +21,7 @@
 #include "ui/ozone/public/overlay_manager_ozone.h"
 #include "ui/ozone/public/ozone_platform.h"
 #else
+#include "components/viz/service/display/overlay_processor_shm_x11.h"
 #include "components/viz/service/display/overlay_processor_stub.h"
 #endif
 
@@ -134,6 +135,12 @@ OverlayProcessorInterface::CreateOverlay
         shared_image_manager, memory_tracker, gpu_task_scheduler,
         overlay_enabled);
   }
+#elif USE_SHARED_IMAGE_X11
+  bool overlay_enabled = surface_handle != gpu::kNullSurfaceHandle;
+  if (overlay_enabled)
+    return std::make_unique<OverlayProcessorShmX11>(surface_handle);
+  else
+    return std::make_unique<OverlayProcessorStub>();
 #else  // Default
   return std::make_unique<OverlayProcessorStub>();
 #endif
--- /dev/null
+++ b/src/components/viz/service/display/overlay_processor_shm_x11.cc
@@ -0,0 +1,296 @@
+// Copyright 2019 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/viz/service/display/overlay_processor_shm_x11.h"
+
+#include <vector>
+
+#include "base/trace_event/trace_event.h"
+#include "build/build_config.h"
+#include "components/viz/common/quads/solid_color_draw_quad.h"
+#include "components/viz/service/display/display_resource_provider.h"
+#include "components/viz/service/display/output_surface.h"
+#include "ui/gfx/geometry/rect_conversions.h"
+
+#define TRACE_SINGLE_SHMID 0
+
+#if USE_SHARED_IMAGE_X11
+
+namespace viz {
+
+
+class StrategyShmX11 : public OverlayProcessorUsingStrategy::Strategy {
+  OverlayProcessorShmX11 * const overlay_processor_;
+
+ public:
+  StrategyShmX11(OverlayProcessorShmX11 * const overlay_processor) :
+    OverlayProcessorUsingStrategy::Strategy(),
+    overlay_processor_(overlay_processor)
+  {
+  }
+
+  ~StrategyShmX11() override = default;
+
+  bool TryOverlay(
+      QuadList* quad_list,
+      const PrimaryPlane* primary_plane,
+      OverlayCandidateList* candidate_list,
+      const OverlayCandidate& candidate,
+      QuadList::Iterator candidate_iterator)
+  {
+    // Check that no prior quads overlap it.
+    if (OverlayCandidate::IsOccluded(candidate, quad_list->cbegin(),
+                                     candidate_iterator))
+    {
+#if TRACE_SINGLE_SHMID
+        LOG(INFO) << "Is occluded";
+#endif
+        return false;
+    }
+
+    // Add the overlay.
+    OverlayCandidateList new_candidate_list = *candidate_list;
+    new_candidate_list.push_back(candidate);
+    new_candidate_list.back().plane_z_order = 1;
+    new_candidate_list.back().is_unoccluded = true;
+    new_candidate_list.back().is_opaque = true;
+
+    // Check for support.
+    overlay_processor_->CheckOverlaySupport(primary_plane, &new_candidate_list);
+
+    const OverlayCandidate& overlay_candidate = new_candidate_list.back();
+    // If the candidate can be handled by an overlay, create a pass for it.
+    if (overlay_candidate.overlay_handled) {
+#if TRACE_SINGLE_SHMID
+      LOG(INFO) << "Opaque=" << overlay_candidate.is_opaque << ", unocc=" << overlay_candidate.is_unoccluded;
+#endif
+      quad_list->EraseAndInvalidateAllPointers(candidate_iterator);
+      candidate_list->swap(new_candidate_list);
+#if TRACE_SINGLE_SHMID
+      LOG(INFO) << "Handled";
+#endif
+      return true;
+    }
+
+#if TRACE_SINGLE_SHMID
+    LOG(INFO) << "Not handled";
+#endif
+
+    return false;
+  }
+
+  bool Attempt(
+      const SkMatrix44& output_color_matrix,
+      const OverlayProcessorInterface::FilterOperationsMap& render_pass_backdrop_filters,
+      DisplayResourceProvider* resource_provider,
+      RenderPassList* render_pass_list,
+      const PrimaryPlane* primary_plane,
+      OverlayCandidateList* candidates,
+      std::vector<gfx::Rect>* content_bounds) override
+  {
+    RenderPass* const render_pass = render_pass_list->back().get();
+    QuadList* quad_list = &render_pass->quad_list;
+
+    for (auto it = quad_list->begin(); it != quad_list->end(); ++it) {
+      OverlayCandidate candidate;
+      candidate.no_occluding_damage = true;
+      candidate.is_unoccluded = true;
+
+      if (it->material != DrawQuad::Material::kTextureContent)
+        continue;
+
+      if (!OverlayCandidate::FromDrawQuad(resource_provider, output_color_matrix, *it, &candidate))
+        continue;
+
+  //    const gfx::Size image_size(resource_provider->ImageSize(candidate.resource_id));
+      const gfx::Size image_size(ScaleToCeiledSize(candidate.resource_size_in_pixels,
+                                                   candidate.uv_rect.width(), candidate.uv_rect.height()));
+
+#if TRACE_SINGLE_SHMID
+      const OverlayCandidate& x = candidate;
+
+      LOG(ERROR) << "Got candidate id=" << x.resource_id <<
+        ", is_unoccluded=" << x.is_unoccluded <<
+        ", no_occluding_damage=" << x.no_occluding_damage <<
+        ", is_opaque=" << x.is_opaque <<
+        ", display_rect=" << x.display_rect.ToString() <<
+        ", pixels=" << x.resource_size_in_pixels.ToString() <<
+        ", uv_rect=" << x.uv_rect.ToString() <<
+        ", clip_rect=" << x.clip_rect.ToString() <<
+        ", z=" << x.plane_z_order <<
+        ", image_size=" << image_size.ToString() <<
+        ", pass damage=" << render_pass->damage_rect.ToString();
+#endif
+
+      const gfx::Rect cand_rect(gfx::ToEnclosingRect(candidate.display_rect));
+
+      if (image_size != cand_rect.size()) {
+#if TRACE_SINGLE_SHMID
+        LOG(ERROR) << "Size mismatch " << image_size.ToString() << "/" << cand_rect.size().ToString();
+#endif
+        continue;
+      }
+
+      // Check we cover the damage rect
+      if (!cand_rect.Contains(render_pass->damage_rect)) {
+#if TRACE_SINGLE_SHMID
+        LOG(ERROR) << "Damage exceeds texture " << cand_rect.ToString() << "/" << render_pass->damage_rect.ToString();
+#endif
+        continue;
+      }
+
+      if (TryOverlay(quad_list, primary_plane, candidates, candidate, it)) {
+        return true;
+      }
+    }
+
+    return false;
+  }
+
+};
+
+OverlayProcessorShmX11::OverlayProcessorShmX11(const gpu::SurfaceHandle surface_handle) :
+    OverlayProcessorUsingStrategy(),
+    use_shm_(false),
+    widget_(surface_handle),
+    display_(gfx::GetXDisplay()),
+    gc_(XCreateGC(display_, widget_, 0, nullptr))
+{
+#if TRACE_SINGLE_SHMID
+  LOG(INFO) << "@@@ " << __func__;
+#endif
+
+  if (!gc_ || !SharedImageX11::check_support(display_)) {
+    LOG(INFO) << "No support for X11 shm";
+    return;
+  }
+
+  if (!XGetWindowAttributes(display_, widget_, &attributes_)) {
+    LOG(ERROR) << "XGetWindowAttributes failed for window " << widget_;
+    return;
+  }
+
+  strategies_.push_back(std::make_unique<StrategyShmX11>(this));
+  use_shm_ = true;
+}
+
+OverlayProcessorShmX11::~OverlayProcessorShmX11() {
+  if (gc_)
+    XFreeGC(display_, gc_);
+}
+
+
+bool
+OverlayProcessorShmX11::IsOverlaySupported() const {
+  return use_shm_;
+}
+
+// Returns true if the platform supports hw overlays and surface occluding
+// damage rect needs to be computed since it will be used by overlay
+// processor.
+bool
+OverlayProcessorShmX11::NeedsSurfaceOccludingDamageRect() const {
+  return false;
+}
+
+// Before the overlay refactor to use OverlayProcessorOnGpu, overlay
+// candidates are stored inside DirectRenderer. Those overlay candidates are
+// later sent over to the GPU thread by GLRenderer or SkiaRenderer. This
+// helper function will be called by DirectRenderer to take these overlay
+// candidates inside overlay processor to avoid sending over DirectRenderer
+// implementation. This is overridden by each platform that is ready to send
+// overlay candidates inside |OverlayProcessor|. Must be called before
+// ScheduleOverlays().
+void
+OverlayProcessorShmX11::TakeOverlayCandidates(CandidateList* candidate_list)
+{
+  overlay_candidates_ = std::move(*candidate_list);
+#if TRACE_SINGLE_SHMID
+  if (!overlay_candidates_.empty())
+    LOG(INFO) << "OverlayProcessorShmX11::TakeOverlayCandidates: size=" << overlay_candidates_.size();
+#endif
+}
+
+// TODO(weiliangc): Make it pure virtual after it is implemented by every
+// subclass.
+void
+OverlayProcessorShmX11::ScheduleOverlays(DisplayResourceProvider* resource_provider)
+{
+  if (overlay_candidates_.empty())
+    return;
+
+  // Release these locks at end of func - but allow reassignment before then
+  const std::unique_ptr<DisplayResourceProvider::ScopedReadLockSharedImageX11> lock(std::move(overlay_lock_));
+  // Ordering means sync will be released (on destruction) before overlay lock
+  const std::unique_ptr<XcbCookie> sync_cookie(std::move(last_cookie_));
+
+  for (const OverlayCandidate& ovly : overlay_candidates_ ) {
+
+    if (ovly.overlay_handled) {
+
+      overlay_lock_ = std::make_unique<DisplayResourceProvider::ScopedReadLockSharedImageX11>(
+          resource_provider, ovly.resource_id);
+
+      SharedImageX11 *const xshm = overlay_lock_->shared_image_x11();
+      if (xshm == nullptr){
+        LOG(ERROR) << "SharedMemory unexpectly null";
+        continue;
+      }
+
+      const gfx::Rect rect(gfx::ToEnclosingRect(ovly.display_rect));
+
+      if (!xshm->create_image(display_, attributes_))
+      {
+          LOG(ERROR) << "xshm.create_image failed!";
+          continue;
+      }
+
+      last_cookie_ = xshm->put_image(widget_, gc_, rect, gfx::Rect());
+    }
+  }
+  XFlush(display_);
+}
+
+// This is a signal from Display::DidReceiveSwapBuffersAck. This is used as
+// approximate signale for when the overlays are presented.
+void
+OverlayProcessorShmX11::OverlayPresentationComplete()
+{
+  last_cookie_.reset();
+  overlay_lock_.reset();
+  if (!overlay_candidates_.empty())
+  {
+#if TRACE_SINGLE_SHMID
+    LOG(INFO) << "OverlayProcessorShmX11::OverlayPresentationComplete";
+#endif
+    overlay_candidates_.clear();
+  }
+}
+
+
+
+// A list of possible overlay candidates is presented to this function.
+// The expected result is that those candidates that can be in a separate
+// plane are marked with |overlay_handled| set to true, otherwise they are
+// to be traditionally composited. Candidates with |overlay_handled| set to
+// true must also have their |display_rect| converted to integer
+// coordinates if necessary.
+void
+OverlayProcessorShmX11::CheckOverlaySupport(
+    const OverlayProcessorInterface::OutputSurfaceOverlayPlane* primary_plane,
+    OverlayCandidateList* candidate_list)
+{
+#if TRACE_SINGLE_SHMID
+  LOG(INFO) << "OverlayProcessorShmX11::CheckOverlaySupport";
+#endif
+  // Accept if we have shm support
+  for (auto& x: *candidate_list) {
+    x.overlay_handled = use_shm_;
+  }
+}
+
+
+}  // namespace viz
+
+#endif
--- /dev/null
+++ b/src/components/viz/service/display/overlay_processor_shm_x11.h
@@ -0,0 +1,70 @@
+// Copyright 2014 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_OVERLAY_PROCESSOR_SHM_X11_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_OVERLAY_PROCESSOR_SHM_X11_H_
+
+#include <memory>
+
+#include "base/containers/flat_map.h"
+#include "base/macros.h"
+#include "build/build_config.h"
+#include "components/viz/common/quads/render_pass.h"
+#include "components/viz/service/display/display_resource_provider.h"
+#include "components/viz/service/display/output_surface.h"
+#include "components/viz/service/display/overlay_candidate.h"
+#include "components/viz/service/display/overlay_processor_interface.h"
+#include "components/viz/service/display/overlay_processor_using_strategy.h"
+#include "components/viz/service/display_embedder/shared_image_x11.h"
+#include "components/viz/service/viz_service_export.h"
+#include "ui/gfx/x/x11.h"
+#include "ui/gfx/x/x11_types.h"
+
+#if USE_SHARED_IMAGE_X11
+
+namespace cc {
+class DisplayResourceProvider;
+}
+
+namespace viz {
+class VIZ_SERVICE_EXPORT OverlayProcessorShmX11
+    : public OverlayProcessorUsingStrategy {
+ public:
+  OverlayProcessorShmX11(const gpu::SurfaceHandle surface_handle);
+  ~OverlayProcessorShmX11() override;
+
+  // Override from OverlayProcessorInterface (required)
+  bool IsOverlaySupported() const override;
+  // Override from OverlayProcessorInterface (required)
+  bool NeedsSurfaceOccludingDamageRect() const override;
+
+  void TakeOverlayCandidates(CandidateList* candidate_list) override;
+  void ScheduleOverlays(
+      DisplayResourceProvider* display_resource_provider) override;
+  void OverlayPresentationComplete() override;
+
+  // Override from OverlayProcessorUsingStrategy (required)
+  void CheckOverlaySupport(
+      const OverlayProcessorInterface::OutputSurfaceOverlayPlane* primary_plane,
+      OverlayCandidateList* candidate_list) override;
+
+ private:
+  bool use_shm_;
+  CandidateList overlay_candidates_;
+
+  gfx::AcceleratedWidget widget_;
+  XDisplay* display_;
+  GC gc_;
+  XWindowAttributes attributes_;
+
+  std::unique_ptr<DisplayResourceProvider::ScopedReadLockSharedImageX11> overlay_lock_;
+  std::unique_ptr<XcbCookie> last_cookie_;
+
+  DISALLOW_COPY_AND_ASSIGN(OverlayProcessorShmX11);
+};
+
+}  // namespace viz
+
+#endif
+#endif  // COMPONENTS_VIZ_SERVICE_DISPLAY_OVERLAY_PROCESSOR_SHM_X11_H_
--- /dev/null
+++ b/src/components/viz/service/display/shared_bitmap_manager.cc
@@ -0,0 +1,29 @@
+#include "components/viz/service/display/shared_bitmap_manager.h"
+#include "components/viz/service/display_embedder/shared_image_x11.h"
+
+namespace viz {
+
+#if USE_SHARED_IMAGE_X11
+scoped_refptr<SharedImageX11>
+SharedBitmapManager::GetSharedImageX11FromId(
+      const gfx::Size& size,
+      uint32_t stride,
+      ResourceFormat format,
+      const SharedBitmapId& id)
+{
+  return nullptr;
+}
+#endif
+
+// We need the handle for X11 shared images, but where we don't need that
+// then default back to just the mapping
+bool
+SharedBitmapManager::ChildAllocatedSharedRegion(
+  base::ReadOnlySharedMemoryRegion& region,
+  const SharedBitmapId& id)
+{
+  return ChildAllocatedSharedBitmap(region.Map(), id);
+}
+
+}  // viz
+
--- a/src/components/viz/service/display/shared_bitmap_manager.h
+++ b/src/components/viz/service/display/shared_bitmap_manager.h
@@ -9,13 +9,16 @@
 
 #include "base/macros.h"
 #include "base/memory/shared_memory_mapping.h"
+#include "base/memory/read_only_shared_memory_region.h"
 #include "components/viz/common/resources/shared_bitmap.h"
+#include "components/viz/service/display_embedder/shared_image_x11.h"
 
 namespace gfx {
 class Size;
 }
 
 namespace viz {
+class SharedImageX11;
 
 class SharedBitmapManager {
  public:
@@ -27,12 +30,25 @@ class SharedBitmapManager {
       const gfx::Size& size,
       ResourceFormat format,
       const SharedBitmapId& id) = 0;
+#if USE_SHARED_IMAGE_X11
+  virtual scoped_refptr<SharedImageX11> GetSharedImageX11FromId(
+      const gfx::Size& size,
+      uint32_t stride,
+      ResourceFormat format,
+      const SharedBitmapId& id);
+#endif
   virtual base::UnguessableToken GetSharedBitmapTracingGUIDFromId(
       const SharedBitmapId& id) = 0;
   // Used in the display compositor to associate an id to a shm mapping.
   virtual bool ChildAllocatedSharedBitmap(
       base::ReadOnlySharedMemoryMapping mapping,
       const SharedBitmapId& id) = 0;
+  // We need the handle for X11 shared images, but where we don't need that
+  // then default back to just the mapping
+  virtual bool ChildAllocatedSharedRegion(
+      base::ReadOnlySharedMemoryRegion& region,
+      const SharedBitmapId& id);
+
   // Used in the display compositor to break an association of an id to a shm
   // handle.
   virtual void ChildDeletedSharedBitmap(const SharedBitmapId& id) = 0;
--- a/src/components/viz/service/display/software_output_device.cc
+++ b/src/components/viz/service/display/software_output_device.cc
@@ -62,4 +62,8 @@ int SoftwareOutputDevice::MaxFramesPendi
   return 1;
 }
 
+gpu::SurfaceHandle SoftwareOutputDevice::GetSurfaceHandle() const {
+  return gpu::kNullSurfaceHandle;
+}
+
 }  // namespace viz
--- a/src/components/viz/service/display/software_output_device.h
+++ b/src/components/viz/service/display/software_output_device.h
@@ -12,6 +12,7 @@
 #include "base/sequenced_task_runner.h"
 #include "components/viz/service/display/software_output_device_client.h"
 #include "components/viz/service/viz_service_export.h"
+#include "gpu/ipc/common/surface_handle.h"
 #include "third_party/skia/include/core/SkSurface.h"
 #include "ui/gfx/geometry/rect.h"
 #include "ui/gfx/geometry/size.h"
@@ -26,6 +27,7 @@ class VSyncProvider;
 namespace viz {
 
 class SoftwareOutputDeviceClient;
+class DisplayResourceProvider;
 
 // This is a "tear-off" class providing software drawing support to
 // OutputSurface, such as to a platform-provided window framebuffer.
@@ -75,6 +77,8 @@ class VIZ_SERVICE_EXPORT SoftwareOutputD
 
   virtual int MaxFramesPending() const;
 
+  virtual gpu::SurfaceHandle GetSurfaceHandle() const;
+
  protected:
   scoped_refptr<base::SequencedTaskRunner> task_runner_;
   SoftwareOutputDeviceClient* client_ = nullptr;
--- a/src/components/viz/service/display/surface_aggregator.cc
+++ b/src/components/viz/service/display/surface_aggregator.cc
@@ -1542,6 +1542,26 @@ gfx::Rect SurfaceAggregator::PrewalkTree
         gfx::Rect child_rect =
             PrewalkTree(child_surface, child_surface_info.has_moved_pixels,
                         child_surface_info.parent_pass_id, will_draw, result);
+
+        if (child_surface->GetActiveFrame().metadata.may_contain_video) {
+          if (child_surface->size_in_pixels() != child_surface_info.quad_rect.size())
+          {
+#if 0
+            LOG(INFO) << "Stretch: " <<  child_surface->size_in_pixels().width() << "x" <<
+                        child_surface->size_in_pixels().height() << " -> " <<
+                        child_surface_info.quad_rect.width() << "x" <<
+                        child_surface_info.quad_rect.height() << "; video=" << frame.metadata.may_contain_video << "/" <<
+                        child_surface->GetActiveFrame().metadata.may_contain_video;
+#endif
+            child_surface->DidStretchFrame(child_surface_info.quad_rect.width(),
+                                           child_surface_info.quad_rect.height());
+          }
+          else
+          {
+            child_surface->DidntStretchFrame();
+          }
+        }
+
         if (child_surface->size_in_pixels().GetCheckedArea().ValueOrDefault(0) >
             0) {
           float y_scale =
--- a/src/components/viz/service/display_embedder/server_shared_bitmap_manager.cc
+++ b/src/components/viz/service/display_embedder/server_shared_bitmap_manager.cc
@@ -13,12 +13,14 @@
 #include "base/memory/read_only_shared_memory_region.h"
 #include "base/memory/ref_counted.h"
 #include "base/memory/shared_memory_mapping.h"
+#include "base/posix/eintr_wrapper.h"
 #include "base/stl_util.h"
 #include "base/strings/string_number_conversions.h"
 #include "base/strings/stringprintf.h"
 #include "base/trace_event/process_memory_dump.h"
 #include "components/viz/common/resources/bitmap_allocation.h"
 #include "components/viz/common/resources/resource_sizes.h"
+#include "components/viz/service/display_embedder/shared_image_x11.h"
 #include "mojo/public/cpp/system/platform_handle.h"
 #include "ui/gfx/geometry/size.h"
 
@@ -26,18 +28,64 @@ namespace viz {
 
 class BitmapData : public base::RefCounted<BitmapData> {
  public:
-  explicit BitmapData(base::ReadOnlySharedMemoryMapping mapping)
-      : mapping_(std::move(mapping)) {}
+  explicit BitmapData(base::ReadOnlySharedMemoryMapping mapping,
+                      int map_handle)
+      : mapping_(std::move(mapping))
+  {
+    handle_.reset(map_handle == -1 ? -1 : HANDLE_EINTR(dup(map_handle)));
+  }
 
-  const void* memory() const { return mapping_.memory(); }
   size_t size() const { return mapping_.size(); }
-  const base::UnguessableToken& mapped_id() const { return mapping_.guid(); }
+
+#if USE_SHARED_IMAGE_X11
+  scoped_refptr<SharedImageX11> xshm_;
+#endif
+
+  const void * memory() const {
+#if USE_SHARED_IMAGE_X11
+    if (xshm_)
+      return (uint8_t *)xshm_->memory();
+#endif
+    return (uint8_t *)mapping_.memory();
+  }
+
+  const base::UnguessableToken mapped_id() const {
+#if USE_SHARED_IMAGE_X11
+    if (xshm_)
+      return xshm_->mapped_id();
+#endif
+    return mapping_.guid();
+  }
+
+#if USE_SHARED_IMAGE_X11
+  void GenerateSharedImageX11(const gfx::Size& size, uint32_t stride)
+  {
+    if (!xshm_) {
+      xshm_ = new SharedImageX11(std::move(mapping_), std::move(handle_));
+    }
+    xshm_->set_size(size, stride);
+  }
+
+  scoped_refptr<SharedImageX11> xshm() const {
+      return xshm_;
+  }
+#endif
+
+  bool is_xshm() const
+  {
+#if USE_SHARED_IMAGE_X11
+      return bool(xshm_);
+#else
+      return false;
+#endif
+  }
 
  private:
   friend class base::RefCounted<BitmapData>;
   ~BitmapData() {}
 
   base::ReadOnlySharedMemoryMapping mapping_;
+  base::ScopedFD handle_;
   DISALLOW_COPY_AND_ASSIGN(BitmapData);
 };
 
@@ -98,6 +146,35 @@ std::unique_ptr<SharedBitmap> ServerShar
   return std::make_unique<ServerSharedBitmap>(data);
 }
 
+#if USE_SHARED_IMAGE_X11
+scoped_refptr<SharedImageX11>
+ServerSharedBitmapManager::GetSharedImageX11FromId(
+      const gfx::Size& size,
+      uint32_t stride,
+      ResourceFormat format,
+      const SharedBitmapId& id)
+{
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+
+  auto it = handle_map_.find(id);
+  if (it == handle_map_.end())
+    return nullptr;
+
+  BitmapData* data = it->second.get();
+
+  if (!data->is_xshm()) {
+      size_t bitmap_size;
+      if (!ResourceSizes::MaybeSizeInBytes(size, format, &bitmap_size) ||
+          bitmap_size > data->size())
+        return nullptr;
+
+      data->GenerateSharedImageX11(size, stride);
+  }
+
+  return data->xshm();
+}
+#endif
+
 base::UnguessableToken
 ServerSharedBitmapManager::GetSharedBitmapTracingGUIDFromId(
     const SharedBitmapId& id) {
@@ -108,9 +185,10 @@ ServerSharedBitmapManager::GetSharedBitm
   return data->mapped_id();
 }
 
-bool ServerSharedBitmapManager::ChildAllocatedSharedBitmap(
+bool ServerSharedBitmapManager::ChildAllocatedSharedBitmapImpl(
     base::ReadOnlySharedMemoryMapping mapping,
-    const SharedBitmapId& id) {
+    const SharedBitmapId& id,
+    const int handle) {
   DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
 
   // Duplicate ids are not allowed.
@@ -122,12 +200,24 @@ bool ServerSharedBitmapManager::ChildAll
   if (!mapping.IsValid())
     return false;
 
-  handle_map_[id] = base::MakeRefCounted<BitmapData>(std::move(mapping));
+  handle_map_[id] = base::MakeRefCounted<BitmapData>(std::move(mapping), handle);
 
   // Note: |region| will be destroyed at scope exit, releasing the fd.
   return true;
 }
 
+bool ServerSharedBitmapManager::ChildAllocatedSharedBitmap(
+    base::ReadOnlySharedMemoryMapping mapping,
+    const SharedBitmapId& id) {
+  return ChildAllocatedSharedBitmapImpl(std::move(mapping), id, -1);
+}
+
+bool ServerSharedBitmapManager::ChildAllocatedSharedRegion(base::ReadOnlySharedMemoryRegion& region,
+    const SharedBitmapId& id) {
+  // We need a handle for plugging into shared images
+  return ChildAllocatedSharedBitmapImpl(region.Map(), id, region.GetPlatformHandle().fd);
+}
+
 void ServerSharedBitmapManager::ChildDeletedSharedBitmap(
     const SharedBitmapId& id) {
   DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
--- a/src/components/viz/service/display_embedder/server_shared_bitmap_manager.h
+++ b/src/components/viz/service/display_embedder/server_shared_bitmap_manager.h
@@ -14,6 +14,7 @@
 #include "base/unguessable_token.h"
 #include "components/viz/common/resources/resource_format_utils.h"
 #include "components/viz/service/display/shared_bitmap_manager.h"
+#include "components/viz/service/display_embedder/shared_image_x11.h"
 #include "components/viz/service/viz_service_export.h"
 
 namespace viz {
@@ -36,10 +37,19 @@ class VIZ_SERVICE_EXPORT ServerSharedBit
       const gfx::Size& size,
       ResourceFormat format,
       const SharedBitmapId& id) override;
+#if USE_SHARED_IMAGE_X11
+  scoped_refptr<SharedImageX11> GetSharedImageX11FromId(
+      const gfx::Size& size,
+      uint32_t stride,
+      ResourceFormat format,
+      const SharedBitmapId& id) override;
+#endif
   base::UnguessableToken GetSharedBitmapTracingGUIDFromId(
       const SharedBitmapId& id) override;
   bool ChildAllocatedSharedBitmap(base::ReadOnlySharedMemoryMapping mapping,
                                   const SharedBitmapId& id) override;
+  bool ChildAllocatedSharedRegion(base::ReadOnlySharedMemoryRegion& region,
+                                  const SharedBitmapId& id) override;
   void ChildDeletedSharedBitmap(const SharedBitmapId& id) override;
 
   // base::trace_event::MemoryDumpProvider implementation.
@@ -49,6 +59,9 @@ class VIZ_SERVICE_EXPORT ServerSharedBit
  private:
   SEQUENCE_CHECKER(sequence_checker_);
 
+  bool ChildAllocatedSharedBitmapImpl(
+      base::ReadOnlySharedMemoryMapping mapping, const SharedBitmapId& id, const int handle);
+
   std::unordered_map<SharedBitmapId,
                      scoped_refptr<BitmapData>,
                      SharedBitmapIdHash>
--- /dev/null
+++ b/src/components/viz/service/display_embedder/shared_image_x11.cc
@@ -0,0 +1,449 @@
+#include <stddef.h>
+#include <stdint.h>
+#include <string.h>
+
+#include "base/memory/read_only_shared_memory_region.h"
+#include "base/memory/writable_shared_memory_region.h"
+#include "base/memory/platform_shared_memory_region.h"
+#include "components/viz/service/display_embedder/shared_image_x11.h"
+#include "ui/gfx/x/x11_types.h"
+
+#define XCB_IMAGE_SUPPORT USE_SHARED_IMAGE_X11
+
+#include <X11/Xlib-xcb.h>
+#include <xcb/shm.h>
+#if XCB_IMAGE_SUPPORT
+#include <xcb/xcb_image.h>
+
+namespace viz
+{
+
+class XcbCookieTrue : public XcbCookie
+{
+public:
+  bool sync() override {return true;}
+};
+
+
+class XcbCookieVoid : public XcbCookie
+{
+  xcb_connection_t * const xcbc_;
+  const xcb_void_cookie_t cookie_;
+  xcb_generic_error_t * err_;
+  bool sync_done_;
+
+public:
+  XcbCookieVoid(xcb_connection_t * const xcbc, const xcb_void_cookie_t& cookie) :
+    xcbc_(xcbc),
+    cookie_(cookie),
+    sync_done_(false)
+  {
+  }
+
+  bool sync() override
+  {
+    if (!sync_done_)
+    {
+      err_ = xcb_request_check(xcbc_, cookie_);
+      sync_done_ = true;
+      if (err_)
+      {
+          LOG(ERROR) << "X sync fail: rtype=" << (int)err_->response_type << ", err=" << (int)err_->error_code;
+      }
+    }
+    return err_ == nullptr;
+  }
+
+  ~XcbCookieVoid() override
+  {
+    sync();
+    if (err_ != nullptr)
+      free(err_);
+  }
+};
+
+
+
+
+class SharedImageX11::X
+{
+  // ?? There must be a STL template that does this wrapping for me...
+  struct XcbImageDeleter
+  {
+    void operator ()(xcb_image_t * const img) {
+      xcb_image_destroy(img);
+    }
+  };
+
+  xcb_connection_t * xcbc_;
+  xcb_shm_seg_t shm_seg_;
+
+  // Use an image structure to store image info
+  // Will calculate expected strides for us
+  std::unique_ptr<xcb_image_t, XcbImageDeleter> img_;
+  bool attached_;
+
+public:
+  X(xcb_connection_t * const xcbc, unsigned int depth, const gfx::Size& size) :
+    xcbc_(xcbc),
+    shm_seg_(~0U),
+    img_(xcb_image_create_native(xcbc_, size.width(), size.height(), XCB_IMAGE_FORMAT_Z_PIXMAP, depth, nullptr, ~0U, nullptr)),
+    attached_(false)
+  {
+  }
+
+  ~X()
+  {
+//    LOG(ERROR) << __func__ << ": shmid=" << std::hex << shminfo_.shmid;
+    if (attached_)
+      xcb_shm_detach(xcbc_, shm_seg_);
+  }
+
+  bool check() const
+  {
+    return img_ != nullptr;
+  }
+
+  size_t stride() const
+  {
+    return img_ == nullptr ? 0 : img_->stride;
+  }
+
+  size_t image_size() const
+  {
+    if (img_ == nullptr)
+      return 0;
+
+    return img_->size;
+  }
+
+  bool attach_smh(const base::ScopedFD& shmfd)
+  {
+    if (attached_)
+    {
+      LOG(ERROR) << "Already attached";
+      return false;
+    }
+    if (img_ == nullptr)
+    {
+      LOG(ERROR) << "No image";
+      return false;
+    }
+
+    shm_seg_ = xcb_generate_id(xcbc_); // Error value is ~0U
+
+    // This closes the fd once sent so must dup to avoid local confusion
+    XcbCookieVoid err(xcbc_,
+      xcb_shm_attach_fd_checked(xcbc_, shm_seg_, dup(shmfd.get()), 1));
+    if (!err.sync())
+    {
+      LOG(ERROR) << "SHM attach failed";
+      return false;
+    }
+
+    attached_ = true;
+    return true;
+  }
+
+  // Messy declaration
+  std::unique_ptr<XcbCookie> put_image(const Drawable drawable, const xcb_gcontext_t cid, const gfx::Rect& rect, const gfx::Rect& src_rect)
+  {
+    if (!attached_)
+    {
+      LOG(ERROR) << "Not attached";
+      return nullptr;
+    }
+    if (img_ == nullptr)
+    {
+      LOG(ERROR) << "No image";
+      return nullptr;
+    }
+
+    // Xlib XID types should be compatible with xcb
+    // This includes Drawable, gcontext_t is extractable from GC
+
+//    LOG(INFO) << "Put image: " << img_->width << "x" << img_->height << ", rect=" << rect.ToString() << ", src_rect=" << src_rect.ToString() <<
+//        ", depth=" << img_->depth << ", format=" << img_->format;
+
+    return std::make_unique<XcbCookieVoid>(xcbc_,
+      xcb_shm_put_image_checked(xcbc_, drawable, cid,
+        img_->width, img_->height, /* total width/height */
+        src_rect.x(), src_rect.y(),
+        rect.width(), rect.height(),  /* ?? should be src_width, src_height ?? */
+        rect.x(), rect.y(),
+        (int)img_->depth,  // bits per pixel (probably)
+        img_->format,
+        0, /* send event */
+        shm_seg_,
+        0  /* offset */));
+  }
+
+  std::string ToString() const
+  {
+    if (img_ == nullptr)
+    {
+      return "<null>";
+    }
+
+    std::ostringstream s;
+    s << "imgsize=" << img_->width << "x" << img_->height;
+    return s.str();
+  }
+};
+
+
+
+
+SharedImageX11::SharedImageX11(base::ReadOnlySharedMemoryMapping&& mapping, base::ScopedFD&& fd) :
+  is_ro_(true),
+  mapping_{.ro_ = std::move(mapping)},
+  map_fd_(std::move(fd))
+{
+}
+
+#if 0
+SharedImageX11::SharedImageX11(const base::SharedMemoryHandle& shmh, const bool ro) :
+  shm_(std::make_unique<base::SharedMemory>(shmh, ro)),
+  stride_(0),
+  buffer_size_(0)
+{
+}
+#endif
+
+SharedImageX11::SharedImageX11() :
+  is_ro_(false)
+{
+}
+
+SharedImageX11::~SharedImageX11()
+{
+}
+
+
+// Check if the X Shared Memory extension is available.
+bool
+SharedImageX11::check_support(Display *const display)
+{
+#if !XCB_IMAGE_SUPPORT
+  return false;
+#else
+  xcb_connection_t * const xcbc = XGetXCBConnection(display);
+  bool rv = false;
+
+  if (xcbc == nullptr)
+  {
+    LOG(ERROR) << "Unable to get xcb connection";
+    return false;
+  }
+
+  // Do not free this result
+  const xcb_query_extension_reply_t * xd;
+  if ((xd = xcb_get_extension_data(xcbc, &xcb_shm_id)) == nullptr ||
+      xd->response_type != 1 ||  // X_Reply - doesn't seem to be defined in xcb
+      !xd->present)
+  {
+    LOG(WARNING) << "SHM extension not supported";
+    return false;
+  }
+
+  xcb_generic_error_t * err = nullptr;
+  xcb_shm_query_version_reply_t * const qvr =
+    xcb_shm_query_version_reply(xcbc, xcb_shm_query_version(xcbc), &err);
+
+  if (err != nullptr)
+    LOG(ERROR) << __func__ << ": Error reply: code=" << err->error_code;
+  else if (qvr == nullptr || qvr->response_type != 1)
+    LOG(ERROR) << "SHM query version reply bad";
+  else if (qvr->major_version < 1 || (qvr->major_version == 1 && qvr->minor_version < 2))
+    LOG(WARNING) << "SHM version " << qvr->major_version << "." << qvr->minor_version <<" is too low; need 1.2";
+  else
+  {
+      LOG(INFO) << "SHM version " << qvr->major_version << "." << qvr->minor_version << ": OK";
+      rv = true;
+  }
+
+  if (err != nullptr)
+    free(err);
+  if (qvr != nullptr)
+    free(qvr);
+
+  return rv;
+#endif
+}
+
+
+
+bool
+SharedImageX11::create_image(XDisplay * const display, const XWindowAttributes& attributes)
+{
+  if (x_ != nullptr)
+  {
+    // Assume everything matches
+    return true;
+  }
+
+  xcb_connection_t * const xcbc = XGetXCBConnection(display);
+  if (stride_ == 0)
+  {
+    // Let X pick our stride (probably creating a new image)
+    std::unique_ptr<X> x(std::make_unique<X>(xcbc, attributes.depth, size_));
+    if (!x->check())
+      return false;
+    x_ = std::move(x);
+  }
+  else
+  {
+    std::unique_ptr<X> x(std::make_unique<X>(xcbc, attributes.depth,
+      gfx::Size(stride_ / 4, size_.height())));
+    if (x->stride() != stride_)
+    {
+      LOG(ERROR) << "Generated mismatched strides: " << x->stride() << "/" << stride_;
+      return false;
+    }
+    x_ = std::move(x);
+  }
+
+  if (buffer_size_ == 0)
+    buffer_size_ = x_->image_size();
+  else if (buffer_size_ < x_->image_size())
+  {
+    LOG(ERROR) << "Image larger than buffer";
+    return false;
+  }
+
+  if (!map_fd_.is_valid())
+  {
+    if (is_ro_)
+    {
+      LOG(ERROR) << "RO shared image can't be created";
+      return false;
+    }
+
+    base::MappedReadOnlyRegion shm(base::ReadOnlySharedMemoryRegion::Create(buffer_size_));
+    if (!shm.IsValid()) {
+      LOG(ERROR) << "Failed to create RO anon shm: size=" << buffer_size_;
+      return false;
+    }
+    mapping_.rw_ = std::move(shm.mapping);
+    map_fd_ = std::move(base::ReadOnlySharedMemoryRegion::TakeHandleForSerialization(std::move(shm.region)).PassPlatformHandle().fd);
+  }
+
+  if (!x_->attach_smh(map_fd_))
+  {
+    x_ = nullptr;
+    return false;
+  }
+
+  return true;
+}
+
+std::unique_ptr<XcbCookie>
+SharedImageX11::put_image(const Drawable drawable, const GC gc,
+                            const gfx::Rect& rect, const gfx::Rect& src_rect)
+{
+  return x_ == nullptr ? nullptr :
+    x_->put_image(drawable, XGContextFromGC(gc), rect, src_rect);
+}
+
+size_t
+SharedImageX11::stride() const
+{
+  return x_ == nullptr ? 0 : x_->stride();
+}
+
+const void *
+SharedImageX11::memory() const
+{
+  return is_ro_ ? mapping_.ro_.memory() : mapping_.rw_.memory();
+}
+
+void *
+SharedImageX11::memory_rw() const
+{
+  return is_ro_ ? nullptr : mapping_.rw_.memory();
+}
+
+}  // namespace viz
+
+#elif 0
+
+namespace viz {
+
+// *** Stub for when we have no xcb-image
+//     For unknown reasons we end up compiling this for x86 without the expected lib
+
+class SharedImageX11::X
+{
+public:
+  X() {}
+
+  ~X() {}
+};
+
+SharedImageX11::SharedImageX11(std::unique_ptr<base::SharedMemory>&& shm) :
+  stride_(0),
+  buffer_size_(0)
+{
+}
+
+SharedImageX11::SharedImageX11(const base::SharedMemoryHandle& shmh, const bool ro) :
+  stride_(0),
+  buffer_size_(0)
+{
+}
+
+SharedImageX11::SharedImageX11() :
+  stride_(0),
+  buffer_size_(0)
+{
+}
+
+SharedImageX11::~SharedImageX11()
+{
+}
+
+// Check if the X Shared Memory extension is available.
+bool
+SharedImageX11::check_support(Display *const display)
+{
+  return false;
+}
+
+bool
+SharedImageX11::create_image(XDisplay * const display, const XWindowAttributes& attributes)
+{
+  return false;
+}
+
+std::unique_ptr<XcbCookie>
+SharedImageX11::put_image(const Drawable drawable, const GC gc,
+                            const gfx::Rect& rect, const gfx::Rect& src_rect)
+{
+  return nullptr;
+}
+
+size_t
+SharedImageX11::stride() const
+{
+  return 0;
+}
+
+void *
+SharedImageX11::memory_rw() const
+{
+  return nullptr;
+}
+
+const void *
+SharedImageX11::memory() const
+{
+  return nullptr;
+}
+
+}  // namespace viz
+
+
+#endif
+
+
+
--- /dev/null
+++ b/src/components/viz/service/display_embedder/shared_image_x11.h
@@ -0,0 +1,90 @@
+#ifndef COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_SHARED_IMAGE_X11_H_
+#define COMPONENTS_VIZ_SERVICE_DISPLAY_EMBEDDER_SHARED_IMAGE_X11_H_
+
+#if defined(__ARMEL__) && USE_X11
+#define USE_SHARED_IMAGE_X11 1
+#else
+#define USE_SHARED_IMAGE_X11 0
+#endif
+
+#if USE_SHARED_IMAGE_X11
+
+#include "base/files/scoped_file.h"
+#include "base/memory/ref_counted.h"
+#include "base/memory/shared_memory_mapping.h"
+#include "components/viz/service/viz_service_export.h"
+#include "ui/gfx/x/x11_types.h"
+#include "ui/base/x/x11_util_internal.h"
+#include "ui/gfx/geometry/rect.h"
+
+namespace viz
+{
+
+class VIZ_SERVICE_EXPORT XcbCookie
+{
+public:
+  virtual ~XcbCookie() {}
+  virtual bool sync() = 0;
+};
+
+class VIZ_SERVICE_EXPORT SharedImageX11 : public base::RefCounted<SharedImageX11>
+{
+  class X;
+
+  // *** Arguably should implemement via two classes with common parent...
+  const bool is_ro_;
+  struct {  // Actually this is really a union but construct / destruct argh!
+    base::WritableSharedMemoryMapping rw_;
+    base::ReadOnlySharedMemoryMapping ro_;
+  } mapping_;
+  base::ScopedFD map_fd_;
+
+  // Hide all the X shm stuff so we don't have to include the X libs
+  // which conflict with a number standard defs.
+  std::unique_ptr<X> x_;
+  size_t stride_ = 0;
+  gfx::Size size_;
+  size_t buffer_size_ = 0;
+
+public:
+  SharedImageX11(base::ReadOnlySharedMemoryMapping&& shm, base::ScopedFD&& fd); // Can move a shm pointer into this
+//  SharedImageX11(const base::SharedMemoryHandle& shmh, const bool ro = false);
+  SharedImageX11();
+  void set_buffer_size(const size_t buffer_size) {
+    buffer_size_ = buffer_size;
+  }
+  void set_size(const gfx::Size& size, const size_t stride) {
+    stride_ = stride;
+    size_ = size;
+  }
+  const gfx::Size& get_size() const {
+    return size_;
+  }
+
+  static bool check_support(XDisplay * const display);
+  bool create_image(XDisplay * const display, const XWindowAttributes& attributes);
+  std::unique_ptr<XcbCookie> put_image(const Drawable drawable, const GC gc,
+                 const gfx::Rect& rect, const gfx::Rect& src_rect);
+
+  size_t stride() const;
+  void * memory_rw() const;
+  const void * memory() const;
+
+  // Returns an ID for the mapped region. This is ID of the SharedMemoryHandle
+  // that was mapped. The ID is valid even after the SharedMemoryHandle is
+  // Closed, as long as the region is not unmapped.
+  const base::UnguessableToken& mapped_id() const {
+    return is_ro_ ? mapping_.ro_.guid() : mapping_.rw_.guid();
+  }
+
+private:
+  friend class base::RefCounted<SharedImageX11>;
+  ~SharedImageX11();
+  DISALLOW_COPY_AND_ASSIGN(SharedImageX11);
+};
+
+}  // namespace viz
+
+#endif
+#endif
+
--- a/src/components/viz/service/display_embedder/software_output_device_x11.cc
+++ b/src/components/viz/service/display_embedder/software_output_device_x11.cc
@@ -64,4 +64,8 @@ int SoftwareOutputDeviceX11::MaxFramesPe
   return x11_software_bitmap_presenter_.MaxFramesPending();
 }
 
+gpu::SurfaceHandle SoftwareOutputDeviceX11::GetSurfaceHandle() const {
+  return x11_software_bitmap_presenter_.GetAcceleratedWidget();
+}
+
 }  // namespace viz
--- a/src/components/viz/service/display_embedder/software_output_device_x11.h
+++ b/src/components/viz/service/display_embedder/software_output_device_x11.h
@@ -10,6 +10,7 @@
 #include "base/threading/thread_checker.h"
 #include "components/viz/service/display/software_output_device.h"
 #include "components/viz/service/viz_service_export.h"
+#include "gpu/ipc/common/surface_handle.h"
 #include "ui/base/x/x11_software_bitmap_presenter.h"
 #include "ui/gfx/native_widget_types.h"
 #include "ui/gfx/x/x11.h"
@@ -32,6 +33,7 @@ class VIZ_SERVICE_EXPORT SoftwareOutputD
   void EndPaint() override;
   void OnSwapBuffers(SwapBuffersCallback swap_ack_callback) override;
   int MaxFramesPending() const override;
+  gpu::SurfaceHandle GetSurfaceHandle() const override;
 
   ui::X11SoftwareBitmapPresenter x11_software_bitmap_presenter_;
 
--- a/src/components/viz/service/display_embedder/software_output_surface.cc
+++ b/src/components/viz/service/display_embedder/software_output_surface.cc
@@ -30,6 +30,10 @@ SoftwareOutputSurface::SoftwareOutputSur
 
 SoftwareOutputSurface::~SoftwareOutputSurface() = default;
 
+gpu::SurfaceHandle SoftwareOutputSurface::GetSurfaceHandle() const {
+  return software_device()->GetSurfaceHandle();
+}
+
 void SoftwareOutputSurface::BindToClient(OutputSurfaceClient* client) {
   DCHECK(client);
   DCHECK(!client_);
--- a/src/components/viz/service/display_embedder/software_output_surface.h
+++ b/src/components/viz/service/display_embedder/software_output_surface.h
@@ -28,6 +28,7 @@ class VIZ_SERVICE_EXPORT SoftwareOutputS
   ~SoftwareOutputSurface() override;
 
   // OutputSurface implementation.
+  gpu::SurfaceHandle GetSurfaceHandle() const override;
   void BindToClient(OutputSurfaceClient* client) override;
   void EnsureBackbuffer() override;
   void DiscardBackbuffer() override;
--- a/src/components/viz/service/frame_sinks/compositor_frame_sink_support.cc
+++ b/src/components/viz/service/frame_sinks/compositor_frame_sink_support.cc
@@ -376,8 +376,8 @@ void CompositorFrameSinkSupport::SubmitC
 bool CompositorFrameSinkSupport::DidAllocateSharedBitmap(
     base::ReadOnlySharedMemoryRegion region,
     const SharedBitmapId& id) {
-  if (!frame_sink_manager_->shared_bitmap_manager()->ChildAllocatedSharedBitmap(
-          region.Map(), id)) {
+  if (!frame_sink_manager_->shared_bitmap_manager()->ChildAllocatedSharedRegion(
+          region, id)) {
     return false;
   }
 
@@ -633,6 +633,12 @@ void CompositorFrameSinkSupport::DidPres
   UpdateNeedsBeginFramesInternal();
 }
 
+void CompositorFrameSinkSupport::DidStretchFrame(uint32_t width, uint32_t height) {
+  if (client_)
+    client_->DidStretchFrame(width, height);
+}
+
+
 void CompositorFrameSinkSupport::DidRejectCompositorFrame(
     uint32_t frame_token,
     std::vector<TransferableResource> frame_resource_list,
--- a/src/components/viz/service/frame_sinks/compositor_frame_sink_support.h
+++ b/src/components/viz/service/frame_sinks/compositor_frame_sink_support.h
@@ -120,6 +120,7 @@ class VIZ_SERVICE_EXPORT CompositorFrame
       const std::vector<TransferableResource>& resources) override;
   void UnrefResources(const std::vector<ReturnedResource>& resources) override;
   void ReturnResources(const std::vector<ReturnedResource>& resources) override;
+  void DidStretchFrame(uint32_t width, uint32_t height) override;
   void ReceiveFromChild(
       const std::vector<TransferableResource>& resources) override;
   // Takes the CopyOutputRequests that were requested for a surface with at
--- a/src/components/viz/service/surfaces/surface.cc
+++ b/src/components/viz/service/surfaces/surface.cc
@@ -661,6 +661,32 @@ void Surface::UnrefFrameResourcesAndRunC
     info.Terminate();
 }
 
+void Surface::DidStretchFrame(uint32_t width, uint32_t height) {
+  // Rate limit requests if we seem to be ignoring them
+
+  if (stretch_frame_count_ != 0 && width == stretch_last_width_ && height == stretch_last_height_) {
+//    LOG(INFO) << "Sink stretch request: " << stretch_frame_count_;
+    --stretch_frame_count_;
+    return;
+  }
+//  LOG(INFO) << "Attempt stretch request";
+
+  stretch_last_width_ = width;
+  stretch_last_height_ = height;
+  stretch_frame_count_ = 32;
+
+  if (surface_client_)
+    surface_client_->DidStretchFrame(width, height);
+  else
+    LOG(INFO) << "No surface_client_";
+}
+
+void Surface::DidntStretchFrame() {
+  if (stretch_frame_count_ != 0) {
+    --stretch_frame_count_;
+  }
+}
+
 void Surface::ClearCopyRequests() {
   if (active_frame_data_) {
     for (const auto& render_pass : active_frame_data_->frame.render_pass_list) {
--- a/src/components/viz/service/surfaces/surface.h
+++ b/src/components/viz/service/surfaces/surface.h
@@ -131,6 +131,9 @@ class VIZ_SERVICE_EXPORT Surface final {
   // Decrements the reference count on resources specified by |resources|.
   void UnrefResources(const std::vector<ReturnedResource>& resources);
 
+  void DidStretchFrame(uint32_t width, uint32_t height);
+  void DidntStretchFrame();
+
   // Returns false if |frame| is invalid.
   // |frame_rejected_callback| will be called once if the frame will not be
   // displayed.
@@ -344,6 +347,10 @@ class VIZ_SERVICE_EXPORT Surface final {
 
   SurfaceAllocationGroup* const allocation_group_;
 
+  uint32_t stretch_last_width_ = 0;
+  uint32_t stretch_last_height_ = 0;
+  uint32_t stretch_frame_count_ = 0;
+
   base::WeakPtrFactory<Surface> weak_factory_{this};
 
   DISALLOW_COPY_AND_ASSIGN(Surface);
--- a/src/components/viz/service/surfaces/surface_client.h
+++ b/src/components/viz/service/surfaces/surface_client.h
@@ -81,6 +81,9 @@ class VIZ_SERVICE_EXPORT SurfaceClient {
       const gfx::SwapTimings& swap_timings,
       const gfx::PresentationFeedback& feedback) = 0;
 
+  // OK - this probably should be pure but that makes the patch bigger...
+  virtual void DidStretchFrame(uint32_t width, uint32_t height) {}
+
   // This is called when |surface| or one of its descendents is determined to be
   // damaged at aggregation time.
   virtual void OnSurfaceAggregatedDamage(
--- a/src/components/viz/test/fake_compositor_frame_sink_client.h
+++ b/src/components/viz/test/fake_compositor_frame_sink_client.h
@@ -29,6 +29,7 @@ class FakeCompositorFrameSinkClient : pu
                     const FrameTimingDetailsMap& timing_details) override;
   void ReclaimResources(
       const std::vector<ReturnedResource>& resources) override;
+  void DidStretchFrame(uint32_t width, uint32_t height) override {}
   void OnBeginFramePausedChanged(bool paused) override;
 
   void clear_returned_resources() { returned_resources_.clear(); }
--- a/src/content/browser/browser_main_loop.cc
+++ b/src/content/browser/browser_main_loop.cc
@@ -612,6 +612,12 @@ int BrowserMainLoop::EarlyInitialization
 #endif
 
 #if defined(USE_X11)
+#if 0
+  // (Pi) The mmal shared memory passthrough requires MT X as the frame
+  // can be deleted (and detached) outside the display thread
+  if (!gfx::InitializeThreadedX11()) {
+    LOG(ERROR) << "Failed to put Xlib into threaded mode.";
+#endif
   if (UsingInProcessGpu()) {
     if (!gfx::GetXDisplay()) {
       LOG(ERROR) << "Failed to open an X11 connection.";
--- a/src/content/browser/renderer_host/render_process_host_impl.cc
+++ b/src/content/browser/renderer_host/render_process_host_impl.cc
@@ -3420,6 +3420,15 @@ void RenderProcessHostImpl::PropagateBro
     switches::kIpcDumpDirectory,
     switches::kIpcFuzzerTestcase,
 #endif
+
+    switches::kMmalFrameBuffers, switches::kMmalCopyMode,
+    switches::kMmalDecodeI420,   switches::kMmalDecodeOpaque,
+    switches::kMmalResizeIsp,    switches::kMmalResizeResizer,
+    switches::kMmalResizeMode,
+    switches::kMmalLowDelay,
+    switches::kMmalRedPixel,     switches::kMmalDecoders,
+    switches::kMmalDebugBench,   switches::kMmalDebugFps,
+    switches::kMmalDebugFixedSize,
   };
   renderer_cmd->CopySwitchesFrom(browser_cmd, kSwitchNames,
                                  base::size(kSwitchNames));
--- a/src/content/browser/sandbox_ipc_linux.cc
+++ b/src/content/browser/sandbox_ipc_linux.cc
@@ -8,6 +8,7 @@
 #include <stddef.h>
 #include <stdint.h>
 #include <string.h>
+#include <sys/ioctl.h>
 #include <sys/poll.h>
 #include <sys/socket.h>
 #include <sys/stat.h>
@@ -123,6 +124,12 @@ void SandboxIPCHandler::HandleRequestFro
       service_manager::SandboxLinux::METHOD_MAKE_SHARED_MEMORY_SEGMENT) {
     HandleMakeSharedMemorySegment(fd, iter, fds);
     return;
+  } else if (kind == service_manager::SandboxLinux::METHOD_OPEN_DEV_VCHIQ) {
+    HandleOpenDevVchiq(fd, iter, fds);
+    return;
+  } else if (kind == service_manager::SandboxLinux::METHOD_OPEN_DEV_VCSM) {
+    HandleOpenDevVcsm(fd, iter, fds);
+    return;
   }
   NOTREACHED();
 }
@@ -154,6 +161,89 @@ void SandboxIPCHandler::HandleMakeShared
   // shm_fd will close the handle which is no longer needed by this process.
 }
 
+#define IOCTL_MBOX_PROPERTY _IOWR(100, 0, char *)
+#define VCIO_PATH "/dev/vcio"
+
+static uint32_t pi_firmware_date()
+{
+  int vcio_fd = IGNORE_EINTR(open(VCIO_PATH, 0));
+
+  if (vcio_fd == -1) {
+    PLOG(ERROR) << "Failed to open " VCIO_PATH;
+    return 0;
+  }
+
+  uint32_t req_buf[256] = {
+    (4+3)*4, 0,  // 4 args, + 3 overhead
+    1, 4, 4, 0,  // args
+  };
+
+  int err = IGNORE_EINTR(ioctl(vcio_fd, IOCTL_MBOX_PROPERTY, req_buf));
+  uint32_t rv = req_buf[5];
+
+  if (err < 0) {
+    PLOG(ERROR) << VCIO_PATH ": ioctl";
+    rv = 0;
+  }
+
+  if (IGNORE_EINTR(close(vcio_fd)) < 0)
+    PLOG(ERROR) << VCIO_PATH ": close";
+  return rv;
+}
+
+void SandboxIPCHandler::HandleOpenDevVchiq(
+    int fd,
+    base::PickleIterator iter,
+    const std::vector<base::ScopedFD>& fds)
+{
+  const int vchiq_fd = IGNORE_EINTR(open("/dev/vchiq", O_RDWR));
+
+  if (vchiq_fd == -1) {
+    PLOG(ERROR) << "Failed to open vchiq";
+  }
+
+  base::Pickle reply;
+  reply.WriteUInt32(pi_firmware_date());
+  SendRendererReply(fds, reply, vchiq_fd);
+
+  if (vchiq_fd >= 0) {
+    if (IGNORE_EINTR(close(vchiq_fd)) < 0)
+      PLOG(ERROR) << "close";
+  }
+}
+
+void SandboxIPCHandler::HandleOpenDevVcsm(
+    int fd,
+    base::PickleIterator iter,
+    const std::vector<base::ScopedFD>& fds)
+{
+  bool cma_req;
+  bool cma_opened = true;
+  if (!iter.ReadBool(&cma_req))
+    return;
+
+  int vcsm_fd = cma_req ? IGNORE_EINTR(open("/dev/vcsm-cma", O_RDWR)) : -1;
+
+  if (vcsm_fd == -1) {
+    vcsm_fd = IGNORE_EINTR(open("/dev/vcsm", O_RDWR));
+    cma_opened = false;
+  }
+
+  if (vcsm_fd == -1) {
+    PLOG(ERROR) << "Failed to open vcsm";
+  }
+
+  base::Pickle reply;
+  reply.WriteBool(cma_opened);
+  SendRendererReply(fds, reply, vcsm_fd);
+
+  if (vcsm_fd >= 0) {
+    if (IGNORE_EINTR(close(vcsm_fd)) < 0)
+      PLOG(ERROR) << "close";
+  }
+}
+
+
 void SandboxIPCHandler::SendRendererReply(
     const std::vector<base::ScopedFD>& fds,
     const base::Pickle& reply,
--- a/src/content/browser/sandbox_ipc_linux.h
+++ b/src/content/browser/sandbox_ipc_linux.h
@@ -37,6 +37,13 @@ class SandboxIPCHandler : public base::D
                                      base::PickleIterator iter,
                                      const std::vector<base::ScopedFD>& fds);
 
+  void HandleOpenDevVchiq(int fd,
+                               base::PickleIterator iter,
+                               const std::vector<base::ScopedFD>& fds);
+  void HandleOpenDevVcsm(int fd,
+                               base::PickleIterator iter,
+                               const std::vector<base::ScopedFD>& fds);
+
   void SendRendererReply(const std::vector<base::ScopedFD>& fds,
                          const base::Pickle& reply,
                          int reply_fd);
--- a/src/content/renderer/android/synchronous_layer_tree_frame_sink.h
+++ b/src/content/renderer/android/synchronous_layer_tree_frame_sink.h
@@ -129,6 +129,7 @@ class SynchronousLayerTreeFrameSink
   void ReclaimResources(
       const std::vector<viz::ReturnedResource>& resources) override;
   void OnBeginFramePausedChanged(bool paused) override;
+  void DidStretchFrame(uint32_t width, uint32_t height) override {}
 
   // viz::ExternalBeginFrameSourceClient overrides.
   void OnNeedsBeginFrames(bool needs_begin_frames) override;
--- a/src/content/test/fake_renderer_compositor_frame_sink.h
+++ b/src/content/test/fake_renderer_compositor_frame_sink.h
@@ -38,6 +38,7 @@ class FakeRendererCompositorFrameSink
   void OnBeginFramePausedChanged(bool paused) override {}
   void ReclaimResources(
       const std::vector<viz::ReturnedResource>& resources) override;
+  void DidStretchFrame(uint32_t width, uint32_t height) override {}
 
   // Resets test data.
   void Reset();
--- a/src/gpu/command_buffer/service/gl_utils.cc
+++ b/src/gpu/command_buffer/service/gl_utils.cc
@@ -1127,6 +1127,7 @@ bool ValidateCopyTextureCHROMIUMInternal
       source_internal_format == GL_LUMINANCE_ALPHA ||
       source_internal_format == GL_BGRA_EXT ||
       source_internal_format == GL_BGRA8_EXT ||
+      source_internal_format == GL_RGB_YCRCB_420_CHROMIUM ||  // RPI: Was missing - why?
       source_internal_format == GL_RGB_YCBCR_420V_CHROMIUM ||
       source_internal_format == GL_RGB_YCBCR_422_CHROMIUM ||
       source_internal_format == GL_RGB_YCBCR_P010_CHROMIUM ||
--- a/src/gpu/ipc/common/gpu_memory_buffer_support.cc
+++ b/src/gpu/ipc/common/gpu_memory_buffer_support.cc
@@ -92,6 +92,29 @@ bool GpuMemoryBufferSupport::IsNativeGpu
   }
   NOTREACHED();
   return false;
+#elif RPI_PIXMAP
+  switch (usage) {
+    case gfx::BufferUsage::GPU_READ:
+    case gfx::BufferUsage::SCANOUT:
+    case gfx::BufferUsage::SCANOUT_CPU_READ_WRITE:
+    case gfx::BufferUsage::GPU_READ_CPU_READ_WRITE:
+      return
+#if 0
+             format == gfx::BufferFormat::BGRA_8888 ||
+             format == gfx::BufferFormat::RGBA_8888 ||
+             format == gfx::BufferFormat::BGRX_8888 ||
+             format == gfx::BufferFormat::RGBX_8888 ||
+#endif
+             format == gfx::BufferFormat::YVU_420 ||
+             format == gfx::BufferFormat::YUV_420_BIPLANAR;
+    case gfx::BufferUsage::SCANOUT_VDA_WRITE:
+    case gfx::BufferUsage::SCANOUT_CAMERA_READ_WRITE:
+    case gfx::BufferUsage::CAMERA_AND_CPU_READ_WRITE:
+    case gfx::BufferUsage::SCANOUT_VEA_READ_CAMERA_AND_CPU_READ_WRITE:
+      return false;
+  }
+  NOTREACHED();
+  return false;
 #elif defined(OS_ANDROID)
   if (!base::AndroidHardwareBufferCompat::IsSupportAvailable()) {
     return false;
--- a/src/gpu/ipc/common/gpu_memory_buffer_support.h
+++ b/src/gpu/ipc/common/gpu_memory_buffer_support.h
@@ -16,6 +16,8 @@
 #include "ui/gfx/geometry/size.h"
 #include "ui/gfx/gpu_memory_buffer.h"
 
+#define RPI_PIXMAP 1
+
 #if defined(OS_LINUX) || defined(USE_OZONE)
 namespace gfx {
 class ClientNativePixmapFactory;
--- a/src/gpu/ipc/host/gpu_memory_buffer_support.cc
+++ b/src/gpu/ipc/host/gpu_memory_buffer_support.cc
@@ -16,7 +16,7 @@ GpuMemoryBufferConfigurationSet GetNativ
   GpuMemoryBufferConfigurationSet configurations;
 
 #if defined(USE_OZONE) || defined(OS_MACOSX) || defined(OS_WIN) || \
-    defined(OS_ANDROID)
+    defined(OS_ANDROID) || RPI_PIXMAP
   const gfx::BufferFormat kBufferFormats[] = {
       gfx::BufferFormat::R_8,          gfx::BufferFormat::R_16,
       gfx::BufferFormat::RG_88,        gfx::BufferFormat::BGR_565,
@@ -55,7 +55,7 @@ bool GetImageNeedsPlatformSpecificTextur
   if (!NativeBufferNeedsPlatformSpecificTextureTarget(format))
     return false;
 #if defined(USE_OZONE) || defined(OS_MACOSX) || defined(OS_WIN) || \
-    defined(OS_ANDROID)
+    defined(OS_ANDROID) || RPI_PIXMAP
   GpuMemoryBufferSupport support;
   GpuMemoryBufferConfigurationSet native_configurations =
       GetNativeGpuMemoryBufferConfigurations(&support);
--- a/src/gpu/ipc/service/gpu_memory_buffer_factory_native_pixmap.cc
+++ b/src/gpu/ipc/service/gpu_memory_buffer_factory_native_pixmap.cc
@@ -11,6 +11,7 @@
 #include "ui/gfx/buffer_usage_util.h"
 #include "ui/gfx/client_native_pixmap.h"
 #include "ui/gfx/linux/native_pixmap_dmabuf.h"
+#include "ui/gfx/linux/native_pixmap_vcsm.h"
 #include "ui/gfx/native_pixmap.h"
 #include "ui/gl/gl_bindings.h"
 #include "ui/gl/gl_enums.h"
@@ -67,12 +68,18 @@ GpuMemoryBufferFactoryNativePixmap::Crea
     gfx::BufferUsage usage,
     int client_id,
     SurfaceHandle surface_handle) {
+
+#if defined(USE_OZONE) || RPI_PIXMAP_VCSM
 #if defined(USE_OZONE)
   scoped_refptr<gfx::NativePixmap> pixmap =
       ui::OzonePlatform::GetInstance()
           ->GetSurfaceFactoryOzone()
           ->CreateNativePixmap(surface_handle, GetVulkanDevice(), size, format,
                                usage);
+#else
+  scoped_refptr<gfx::NativePixmap> pixmap(CreateVCSMPixmap(size, format));
+#endif
+
   return CreateGpuMemoryBufferFromNativePixmap(id, size, format, usage,
                                                client_id, std::move(pixmap));
 #elif defined(USE_X11)
@@ -161,6 +168,11 @@ GpuMemoryBufferFactoryNativePixmap::Crea
                  ->CreateNativePixmapFromHandle(
                      surface_handle, size, format,
                      std::move(handle.native_pixmap_handle));
+#elif RPI_PIXMAP_VCSM
+    // This is easy enough to build but I don't think it should ever happen
+    LOG(WARNING) << "Unexpected failure to find pixmap handle id " << handle.id.id << "/" << client_id;
+
+    pixmap = CreateVCSMPixmapFromHandle(size, format, std::move(handle.native_pixmap_handle));
 #else
     DCHECK_EQ(surface_handle, gpu::kNullSurfaceHandle);
     pixmap = base::WrapRefCounted(new gfx::NativePixmapDmaBuf(
@@ -191,7 +203,7 @@ GpuMemoryBufferFactoryNativePixmap::Crea
 }
 
 bool GpuMemoryBufferFactoryNativePixmap::SupportsCreateAnonymousImage() const {
-#if defined(USE_OZONE)
+#if defined(USE_OZONE) || RPI_PIXMAP_VCSM
   return true;
 #else
   return false;
@@ -211,6 +223,8 @@ GpuMemoryBufferFactoryNativePixmap::Crea
                ->GetSurfaceFactoryOzone()
                ->CreateNativePixmap(surface_handle, GetVulkanDevice(), size,
                                     format, usage);
+#elif RPI_PIXMAP_VCSM
+  pixmap = CreateVCSMPixmap(size, format);
 #else
   NOTIMPLEMENTED();
 #endif
--- a/src/media/base/media_switches.cc
+++ b/src/media/base/media_switches.cc
@@ -201,6 +201,21 @@ const char kUserGestureRequiredPolicy[]
 
 }  // namespace autoplay
 
+const char kMmalFrameBuffers[]              = "mmal-frame-buffers";
+const char kMmalCopyMode[]                  = "mmal-copy-mode";
+const char kMmalDecodeI420[]                = "mmal-decode-i420";
+const char kMmalDecodeOpaque[]              = "mmal-decode-opaque";
+const char kMmalResizeIsp[]                 = "mmal-resize-isp";
+const char kMmalResizeResizer[]             = "mmal-resize-resizer";
+const char kMmalResizeMode[]                = "mmal-resize-mode";
+const char kMmalLowDelay[]                  = "mmal-low-delay";
+const char kMmalRedPixel[]                  = "mmal-red-pixel";
+const char kMmalDecoders[]                  = "mmal-decoders";
+
+const char kMmalDebugBench[]                = "mmal-debug-bench";
+const char kMmalDebugFps[]                  = "mmal-debug-fps";
+const char kMmalDebugFixedSize[]            = "mmal-debug-fixed-size";
+
 }  // namespace switches
 
 namespace media {
--- a/src/media/base/media_switches.h
+++ b/src/media/base/media_switches.h
@@ -93,6 +93,21 @@ MEDIA_EXPORT extern const char kUserGest
 
 }  // namespace autoplay
 
+MEDIA_EXPORT extern const char kMmalFrameBuffers[];
+MEDIA_EXPORT extern const char kMmalCopyMode[];
+MEDIA_EXPORT extern const char kMmalDecodeI420[];
+MEDIA_EXPORT extern const char kMmalDecodeOpaque[];
+MEDIA_EXPORT extern const char kMmalResizeIsp[];
+MEDIA_EXPORT extern const char kMmalResizeResizer[];
+MEDIA_EXPORT extern const char kMmalResizeMode[];
+MEDIA_EXPORT extern const char kMmalLowDelay[];
+MEDIA_EXPORT extern const char kMmalRedPixel[];
+MEDIA_EXPORT extern const char kMmalDecoders[];
+
+MEDIA_EXPORT extern const char kMmalDebugBench[];
+MEDIA_EXPORT extern const char kMmalDebugFps[];
+MEDIA_EXPORT extern const char kMmalDebugFixedSize[];
+
 }  // namespace switches
 
 namespace media {
--- a/src/media/base/video_decoder.h
+++ b/src/media/base/video_decoder.h
@@ -134,6 +134,9 @@ class MEDIA_EXPORT VideoDecoder {
   // [|limits::kMinVideoDecodeThreads|, |limits::kMaxVideoDecodeThreads|].
   static int GetRecommendedThreadCount(int desired_threads);
 
+  // Alert that we would like a differet frame size
+  virtual void TryResizeFrame(uint32_t width, uint32_t height) {}
+
  protected:
   // Deletion is only allowed via Destroy().
   virtual ~VideoDecoder();
--- a/src/media/base/video_frame.cc
+++ b/src/media/base/video_frame.cc
@@ -1323,4 +1323,21 @@ std::vector<size_t> VideoFrame::Calculat
   return plane_size;
 }
 
+// Frame tracking
+
+// Not supported by default
+const base::ReadOnlySharedMemoryRegion* VideoFrame::ro_shm_region() const {
+  return nullptr;
+}
+
+bool VideoFrame::SetBitmapIdAndKillCB(const gpu::Mailbox& id, base::OnceClosure kill) {
+  return false;
+}
+
+const gpu::Mailbox& VideoFrame::GetBitmapId() const {
+  static const gpu::Mailbox empty_mailbox;
+  NOTREACHED();
+  return empty_mailbox;
+}
+
 }  // namespace media
--- a/src/media/base/video_frame.h
+++ b/src/media/base/video_frame.h
@@ -18,6 +18,7 @@
 #include "base/logging.h"
 #include "base/macros.h"
 #include "base/memory/aligned_memory.h"
+#include "base/memory/read_only_shared_memory_region.h"
 #include "base/memory/ref_counted.h"
 #include "base/memory/unsafe_shared_memory_region.h"
 #include "base/optional.h"
@@ -52,6 +53,8 @@ namespace media {
 
 class MEDIA_EXPORT VideoFrame : public base::RefCountedThreadSafe<VideoFrame> {
  public:
+  typedef base::Callback<void(const gfx::Size&)> MmalResizeCB;
+
   enum {
     kFrameSizeAlignment = 16,
     kFrameSizePadding = 16,
@@ -485,6 +488,13 @@ class MEDIA_EXPORT VideoFrame : public b
   // mailbox, the caller must wait for the included sync point.
   const gpu::MailboxHolder& mailbox_holder(size_t texture_index) const;
 
+#if 1
+  // Shared (mmal) frame tracking
+  virtual const base::ReadOnlySharedMemoryRegion* ro_shm_region() const;
+  virtual bool SetBitmapIdAndKillCB(const gpu::Mailbox& id, base::OnceClosure kill);
+  virtual const gpu::Mailbox& GetBitmapId() const;
+#endif
+
 #if defined(OS_LINUX)
   // Returns a vector containing the backing DmaBufs for this frame. The number
   // of returned DmaBufs will be equal or less than the number of planes of
@@ -594,6 +604,10 @@ class MEDIA_EXPORT VideoFrame : public b
     data_[plane] = ptr;
   }
 
+  void set_mailbox_holder(const unsigned int plane, const gpu::MailboxHolder& mailbox_holder) {
+    mailbox_holders_[plane] = mailbox_holder;
+  }
+
  private:
   static scoped_refptr<VideoFrame> CreateFrameInternal(
       VideoPixelFormat format,
--- a/src/media/base/video_renderer_sink.h
+++ b/src/media/base/video_renderer_sink.h
@@ -42,6 +42,8 @@ class MEDIA_EXPORT VideoRendererSink {
     // client.
     virtual base::TimeDelta GetPreferredRenderInterval() = 0;
 
+    virtual void TryResizeFrame(uint32_t width, uint32_t height) {}
+
     virtual ~RenderCallback() {}
   };
 
--- a/src/media/base/video_types.h
+++ b/src/media/base/video_types.h
@@ -82,6 +82,13 @@ enum VideoPixelFormat {
       PIXEL_FORMAT_BGRA,  // Must always be equal to largest entry logged.
 };
 
+
+// *****
+// Alias MMAL to XRGB so it is easy to spot where I've used this
+// * In the fullness of time remove this and rename to actual fmt
+#define PIXEL_FORMAT_MMAL_BUFFER PIXEL_FORMAT_XRGB
+
+
 // Returns the name of a Format as a string.
 MEDIA_EXPORT std::string VideoPixelFormatToString(VideoPixelFormat format);
 
--- a/src/media/blink/video_frame_compositor.cc
+++ b/src/media/blink/video_frame_compositor.cc
@@ -177,6 +177,13 @@ void VideoFrameCompositor::PutCurrentFra
   rendered_last_frame_ = true;
 }
 
+void VideoFrameCompositor::DidStretchFrame(uint32_t width, uint32_t height)
+{
+  base::AutoLock lock(callback_lock_);
+  if (callback_)
+    callback_->TryResizeFrame(width, height);
+}
+
 bool VideoFrameCompositor::UpdateCurrentFrame(base::TimeTicks deadline_min,
                                               base::TimeTicks deadline_max) {
   DCHECK(task_runner_->BelongsToCurrentThread());
--- a/src/media/blink/video_frame_compositor.h
+++ b/src/media/blink/video_frame_compositor.h
@@ -96,6 +96,7 @@ class MEDIA_BLINK_EXPORT VideoFrameCompo
   scoped_refptr<VideoFrame> GetCurrentFrame() override;
   void PutCurrentFrame() override;
   base::TimeDelta GetPreferredRenderInterval() override;
+  void DidStretchFrame(uint32_t width, uint32_t height) override;
 
   // Returns |current_frame_|, without offering a guarantee as to how recently
   // it was updated. In certain applications, one might need to periodically
--- a/src/media/filters/BUILD.gn
+++ b/src/media/filters/BUILD.gn
@@ -6,6 +6,7 @@ import("//build/config/jumbo.gni")
 import("//media/gpu/args.gni")
 import("//media/media_options.gni")
 import("//third_party/libaom/options.gni")
+import("//build/config/sysroot.gni")
 
 jumbo_source_set("filters") {
   # Do not expand the visibility here without double-checking with OWNERS, this
@@ -97,6 +98,9 @@ jumbo_source_set("filters") {
   ]
 
   libs = []
+  include_dirs = []
+  public_configs = []
+  public_deps = []
 
   if (proprietary_codecs) {
     sources += [
@@ -105,6 +109,22 @@ jumbo_source_set("filters") {
     ]
   }
 
+  # Really should have some sort of global enable_mmal switch
+  if (current_cpu == "arm" && is_linux) {
+    sources += [
+      "mmal_video_decoder.cc",
+      "mmal_video_decoder.h",
+    ]
+    include_dirs += [
+      "$target_sysroot/opt/vc/include",
+      "$target_sysroot/opt/vc/include/interface/vcos/pthreads",
+      "$target_sysroot/opt/vc/include/interface/vmcs_host/linux",
+    ]
+
+    public_configs += [ "//build/config/linux:use_mmal" ]
+    public_deps += [ "//services/service_manager/zygote" ]
+  }
+
   if (media_use_ffmpeg) {
     deps += [
       "//media/ffmpeg",
--- a/src/media/filters/decoder_stream.cc
+++ b/src/media/filters/decoder_stream.cc
@@ -1017,6 +1017,14 @@ void DecoderStream<StreamType>::Complete
   preparing_output_ = false;
 }
 
+template <DemuxerStream::Type StreamType>
+void DecoderStream<StreamType>::TryResizeFrame(uint32_t width, uint32_t height) const {}
+
+template <>
+void DecoderStream<DemuxerStream::VIDEO>::TryResizeFrame(uint32_t width, uint32_t height) const {
+  decoder_->TryResizeFrame(width, height);
+}
+
 template class DecoderStream<DemuxerStream::VIDEO>;
 template class DecoderStream<DemuxerStream::AUDIO>;
 
--- a/src/media/filters/decoder_stream.h
+++ b/src/media/filters/decoder_stream.h
@@ -154,6 +154,8 @@ class MEDIA_EXPORT DecoderStream {
     return fallback_buffers_.size();
   }
 
+  void TryResizeFrame(uint32_t width, uint32_t height) const;
+
  private:
   enum State {
     STATE_UNINITIALIZED,
@@ -310,6 +312,9 @@ bool DecoderStream<DemuxerStream::AUDIO>
 template <>
 int DecoderStream<DemuxerStream::AUDIO>::GetMaxDecodeRequests() const;
 
+template <>
+void DecoderStream<DemuxerStream::VIDEO>::TryResizeFrame(uint32_t width, uint32_t height) const;
+
 using VideoDecoderStream = DecoderStream<DemuxerStream::VIDEO>;
 using AudioDecoderStream = DecoderStream<DemuxerStream::AUDIO>;
 
--- /dev/null
+++ b/src/media/filters/mmal_video_decoder.cc
@@ -0,0 +1,5256 @@
+// Copyright (c) 2012 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+
+// ***
+// gpu_factories passed to constructor so we may consider generating h/w frames
+// * only want to do this is we have a h/w compositor
+// * if we can generate CMA handles we may be able to use then for full
+//   s/w passthrough, as we should both
+//      be able to use them in xcb_sm_put_image
+//      and be able to decode into them directly
+// Maybe look at
+//  media/video/gpu_memory_buffer_video_frame_pool.cc
+// for inspiration on what is needed.
+
+
+#include "media/filters/mmal_video_decoder.h"
+
+#include <GLES2/gl2.h>
+#include <GLES2/gl2ext.h>
+#include <stddef.h>
+#include <stdint.h>
+
+#include <algorithm>
+#include <string>
+#include <queue>
+
+//#include "base/base_switches.h"
+#include "base/bind.h"
+#include "base/callback_helpers.h"
+#include "base/command_line.h"
+#include "base/location.h"
+#include "base/single_thread_task_runner.h"
+#include "base/pickle.h"
+#include "base/memory/ptr_util.h"
+#include "base/posix/unix_domain_socket.h"
+//#include "content/public/common/content_switches.h"
+
+#include "gpu/command_buffer/client/shared_image_interface.h"
+#include "gpu/command_buffer/common/shared_image_usage.h"
+
+#include "media/base/bind_to_current_loop.h"
+#include "media/base/decoder_buffer.h"
+#include "media/base/limits.h"
+#include "media/base/media_switches.h"
+#include "media/base/timestamp_constants.h"
+#include "media/base/video_frame.h"
+#include "media/base/video_util.h"
+#include "media/video/gpu_video_accelerator_factories.h"
+//#include "mojo/public/cpp/base/shared_memory_utils.h"
+//#include "mojo/public/cpp/system/platform_handle.h"
+#include "services/service_manager/public/cpp/connector.h"
+#include "services/service_manager/sandbox/linux/sandbox_linux.h"
+#include "services/service_manager/zygote/common/common_sandbox_support_linux.h"
+#include "services/viz/public/cpp/gpu/context_provider_command_buffer.h"
+
+extern "C" {
+#include <interface/mmal/mmal.h>
+#include <interface/mmal/mmal_buffer.h>
+#include <interface/mmal/mmal_parameters_video.h>
+#include <interface/mmal/util/mmal_util.h>
+#include <interface/mmal/util/mmal_util_params.h>
+#include <interface/mmal/util/mmal_default_components.h>
+#include <interface/mmal/util/mmal_connection.h>
+#include <interface/mmal/core/mmal_buffer_private.h>  // *** debug
+#include <interface/mmal/vc/mmal_vc_api.h>
+#include <interface/vcsm/user-vcsm.h>
+#include <interface/vmcs_host/vc_vchi_gencmd.h>
+}
+
+#include <iomanip>
+
+// Debug & test defines
+
+// Really the DMA version should be better but in actual performance terms
+// copying on the ARM seems to work better :-(
+#define OPT_FRAME_COPY_DEFAULT FrameCopyMode::FRAME_ARGB_DMA
+//#define OPT_FRAME_COPY_DEFAULT FrameCopyMode::FRAME_ARGB_COPY
+//#define OPT_FRAME_COPY_GPU_DEFAULT FrameCopyMode::FRAME_I420
+#define OPT_FRAME_COPY_GPU_DEFAULT FrameCopyMode::FRAME_GPU_YUV_VCSM
+//#define OPT_FRAME_COPY_GPU_DEFAULT FrameCopyMode::FRAME_GPU_YUV_COPY
+//#define OPT_FRAME_COPY_GPU_DEFAULT FrameCopyMode::FRAME_NV12
+#define TRACE_COMPONENT_CREATION        0
+#define TRACE_TRAMPOLINE                0
+#define TRACE_FRAME_STASH_NEW           0  // Traces memory allocated by FrameStash
+#define TRACE_DESC                      0
+#define TRACE_BUFFER_EVENT              0
+
+// Missing defn
+#define MMAL_COMPONENT_DEFAULT_RESIZER "vc.ril.resize"
+#define MMAL_COMPONENT_ISP_RESIZER "vc.ril.isp"
+
+#define MMAL_SLICE_HEIGHT 16
+#define MMAL_ALIGN_W      32
+#define MMAL_ALIGN_H      16
+
+#define MMAL_LIMIT_WIDTH  VCOS_ALIGN_UP(1920, MMAL_ALIGN_W)
+#define MMAL_LIMIT_HEIGHT VCOS_ALIGN_UP(1088, MMAL_ALIGN_H)
+//#define MMAL_LIMIT_WIDTH  VCOS_ALIGN_UP(2048, MMAL_ALIGN_W)
+//#define MMAL_LIMIT_HEIGHT VCOS_ALIGN_UP(1280, MMAL_ALIGN_H)
+
+#define FRAME_COPY_DEFAULT_BUFFERS      2
+#define SLICE_COPY_DEFAULT_BUFFERS      16
+
+#define MAX_COPY_FRAMES_IN_FLIGHT       8
+
+#define ipc_fd ::service_manager::GetSandboxFD
+
+namespace media {
+
+enum class FrameDescType {
+  unset,
+  SingleShm,
+  SingleGPU,
+  MultiGPU
+};
+
+enum class PortCopy {
+  unset,
+  Copy,
+  Dma,
+  Zc
+};
+
+enum class ResizeMode {
+  unset,
+  Never,
+  Always,
+  Smaller
+};
+
+
+class FrameCopyMode {
+public:
+  enum Mode {
+    unset = 0,
+    SLICE,
+    FRAME_I420,
+    FRAME_NV12,
+    FRAME_ARGB_DMA,
+    FRAME_ARGB_COPY,
+    FRAME_GPU_ARGB_DMA,
+    FRAME_GPU_ARGB_VCSM,
+    FRAME_GPU_YUV_COPY,
+    FRAME_GPU_YUV_VCSM,
+  };
+  static constexpr unsigned int MODE_COUNT = FRAME_GPU_YUV_VCSM + 1;
+
+  static const struct Xlat {
+    const char * name;
+    PortCopy port_copy;
+    unsigned int planes;
+    uint8_t bp4w[4], lp4h[4];
+    VideoPixelFormat pixel_format;
+    MMAL_FOURCC_T mmal_encoding;
+    FrameDescType frame_desc_type;
+    gfx::BufferFormat gfx_buffer_format;
+  } xlat[MODE_COUNT];
+
+  FrameCopyMode(const Mode copy_mode = unset) :
+    copy_mode_(copy_mode)
+  {
+  }
+
+  static FrameCopyMode FromString(const char * name)
+  {
+    for (unsigned int i = 0; i != MODE_COUNT; ++i) {
+      if (strcasecmp(name, xlat[i].name) == 0)
+        return FrameCopyMode((Mode)i);
+    }
+    return FrameCopyMode();
+  }
+
+  ~FrameCopyMode() = default;
+  FrameCopyMode(const FrameCopyMode&) = default;
+  FrameCopyMode& operator=(const FrameCopyMode&) = default;
+
+  FrameCopyMode& operator=(const Mode copy_mode)
+  {
+    copy_mode_ = copy_mode;
+    return *this;
+  }
+
+  operator bool() const
+  {
+    return copy_mode_ != unset;
+  }
+
+  bool operator==(const Mode mode) const
+  {
+    return copy_mode_ == mode;
+  }
+  bool operator!=(const Mode mode) const
+  {
+    return copy_mode_ != mode;
+  }
+
+  bool operator==(const FrameCopyMode& x) const
+  {
+    return copy_mode_ == x.copy_mode_;
+  }
+  bool operator!=(const FrameCopyMode& x) const
+  {
+    return copy_mode_ != x.copy_mode_;
+  }
+
+  Mode get() const
+  {
+    return copy_mode_;
+  }
+
+  gfx::BufferFormat gfx_buffer_format() const
+  {
+    DCHECK(is_gpu());
+    return xlat[copy_mode_].gfx_buffer_format;
+  }
+
+  MMAL_FOURCC_T mmal_encoding() const
+  {
+    return xlat[copy_mode_].mmal_encoding;
+  }
+
+  VideoPixelFormat pixel_format() const
+  {
+    return xlat[copy_mode_].pixel_format;
+  }
+
+  FrameDescType frame_desc_type() const
+  {
+    return xlat[copy_mode_].frame_desc_type;
+  }
+
+  PortCopy port_copy() const
+  {
+    return xlat[copy_mode_].port_copy;
+  }
+
+  bool port_has_pool() const
+  {
+    return port_copy() == PortCopy::Copy;
+  }
+
+  VideoFrame::StorageType frame_storage_type() const
+  {
+    // *** Hmmm...
+    return port_copy() == PortCopy::Zc && is_gpu() ? VideoFrame::STORAGE_DMABUFS : VideoFrame::STORAGE_UNOWNED_MEMORY;
+  }
+
+  unsigned int planes() const
+  {
+    return xlat[copy_mode_].planes;
+  }
+
+  unsigned int width_to_stride(const unsigned int plane, const unsigned width) const
+  {
+    return (xlat[copy_mode_].bp4w[plane] * width) >> 2;
+  }
+
+  unsigned int height_to_lines(const unsigned int plane, const unsigned height) const
+  {
+    return (xlat[copy_mode_].lp4h[plane] * height) >> 2;
+  }
+
+  bool is_slice() const
+  {
+    return copy_mode_ == SLICE;
+  }
+
+  bool is_gpu() const
+  {
+    return frame_desc_type() == FrameDescType::SingleGPU || frame_desc_type() == FrameDescType::MultiGPU;
+  }
+
+  bool is_yuv() const
+  {
+    return
+      copy_mode_ == FrameCopyMode::FRAME_GPU_YUV_COPY ||
+      copy_mode_ == FrameCopyMode::FRAME_GPU_YUV_VCSM ||
+      copy_mode_ == FrameCopyMode::FRAME_NV12 ||
+      copy_mode_ == FrameCopyMode::FRAME_I420;
+  }
+
+  const char * cstr() const
+  {
+    return xlat[copy_mode_].name;
+  }
+
+  friend std::ostream& operator<<(std::ostream& os, const FrameCopyMode& mode);
+
+private:
+  Mode copy_mode_;
+};
+
+#define GEO_UNSET  0, {0,  0,  0,  0}, {0,  0,  0,  0}
+#define GEO_RGBX_1 1, {16, 0,  0,  0}, {4,  0,  0,  0}
+#define GEO_YUV_3  3, {4,  2,  2,  0}, {4,  2,  2,  0}
+#define GEO_YC_2   2, {4,  4,  0,  0}, {4,  2,  0,  0}
+
+// Array designators now not allowed (v80) so have to get the order right here :-(
+const FrameCopyMode::Xlat FrameCopyMode::xlat[FrameCopyMode::MODE_COUNT] =
+{
+//  [unset]               =
+  {"unset",                 PortCopy::unset,          GEO_UNSET,
+    PIXEL_FORMAT_UNKNOWN, MMAL_ENCODING_UNKNOWN,    FrameDescType::unset,     gfx::BufferFormat::R_8},
+//  [SLICE]               =
+  {"SLICE",                 PortCopy::Copy,           GEO_RGBX_1,
+    PIXEL_FORMAT_XRGB,    MMAL_ENCODING_BGRA_SLICE, FrameDescType::SingleShm, gfx::BufferFormat::R_8},
+//  [FRAME_I420]          = 
+  {"SHM-YUV-DMA",           PortCopy::Dma,            GEO_YUV_3,
+    PIXEL_FORMAT_I420,    MMAL_ENCODING_I420,       FrameDescType::SingleShm, gfx::BufferFormat::R_8},
+//  [FRAME_NV12]          = 
+  {"SHM-YC-DMA",            PortCopy::Dma,            GEO_YC_2,
+    PIXEL_FORMAT_NV12,    MMAL_ENCODING_NV12,       FrameDescType::SingleShm, gfx::BufferFormat::R_8},
+//  [FRAME_ARGB_DMA]      = 
+  {"SHM-RGB-DMA",           PortCopy::Dma,            GEO_RGBX_1,
+    PIXEL_FORMAT_XRGB,    MMAL_ENCODING_BGRA,       FrameDescType::SingleShm, gfx::BufferFormat::R_8},
+//  [FRAME_ARGB_COPY]     = 
+  {"SHM-RGB-COPY",          PortCopy::Copy,           GEO_RGBX_1,
+    PIXEL_FORMAT_XRGB,    MMAL_ENCODING_BGRA,       FrameDescType::SingleShm, gfx::BufferFormat::R_8},
+//  [FRAME_GPU_ARGB_DMA]  = 
+  {"GPU-RGB-DMA",           PortCopy::Dma,            GEO_RGBX_1,
+    PIXEL_FORMAT_XRGB,    MMAL_ENCODING_BGRA,       FrameDescType::SingleGPU, gfx::BufferFormat::BGRX_8888},
+//  [FRAME_GPU_ARGB_VCSM] = 
+  {"GPU-RGB-ZC",            PortCopy::Zc,             GEO_RGBX_1,
+    PIXEL_FORMAT_XRGB,    MMAL_ENCODING_BGRA,       FrameDescType::SingleGPU, gfx::BufferFormat::BGRX_8888},
+//  [FRAME_GPU_YUV_COPY]  = 
+  {"GPU-YUV-COPY",          PortCopy::Copy,           GEO_YUV_3,
+    PIXEL_FORMAT_I420,    MMAL_ENCODING_I420,       FrameDescType::MultiGPU,  gfx::BufferFormat::R_8},
+//  [FRAME_GPU_YUV_VCSM]  = 
+  {"GPU-YUV-ZC",            PortCopy::Zc,             GEO_YUV_3,
+    PIXEL_FORMAT_YV12,    MMAL_ENCODING_YV12,       FrameDescType::SingleGPU, gfx::BufferFormat::YVU_420},
+};
+
+
+std::ostream& operator<<(std::ostream& os, const FrameCopyMode& mode)
+{
+  return os << mode.cstr();
+}
+
+
+// Not strictly a decoder count - this is inced @ initialisation
+static volatile base::subtle::Atomic32 decoder_count = 0;
+
+// Supported decoder bitmap (indexed by VideoCodec)
+static unsigned int supported_video_codecs = 0;
+
+// Task runner - current SingleThread - probably no reason
+// why it shouldn't be Sequenced so typedef for ease of changing
+typedef scoped_refptr<base::SequencedTaskRunner> MmalTaskRunner;
+
+
+// Some classes that we have fwd refs to
+class MmalConnectedPort;
+class MmalComponent;
+
+// ----------------------------------------------------------------------------
+//
+// Misc helper fns
+
+// Zap & release buffer
+static void buffer_release(MMAL_BUFFER_HEADER_T * const buffer)
+{
+  mmal_buffer_header_reset(buffer);
+  mmal_buffer_header_release(buffer);
+}
+
+// Calculate pixel aspect ratio
+static gfx::Size par_from_sizes(const gfx::Size& coded, const gfx::Size& natural)
+{
+  uint32_t a = coded.width() * natural.height();
+  uint32_t b = coded.height() * natural.width();
+
+  // Deal with the trivial case
+
+  if (a == b) {
+    return gfx::Size(1, 1);
+  }
+
+  // reduce - probably not needed but it might well save overflow
+  // or precision reduction later in the code
+  // We only expect to do this at init time so inefficiency isn't important
+
+  static const uint32_t primes[] = {2, 3, 5, 7, 11, 13, 17, 19};
+  for (int i = 0; i != sizeof(primes)/sizeof(primes[0]); ++i) {
+    const uint32_t p = primes[i];
+    while (a % p == 0 && b % p == 0) {
+      a /= p;
+      b /= p;
+    }
+  }
+
+  return gfx::Size(b, a);
+}
+
+// Convert a time_t to a printable string
+// * Surely there is a std C++ fn for this?
+static std::string strgmtimet(const time_t tt)
+{
+  char tbuf[32];
+  struct tm tm;
+  gmtime_r(&tt, &tm);
+  tbuf[sizeof(tbuf)-1] = 0;
+  snprintf(tbuf, sizeof(tbuf) - 1, "%04d-%02d-%02d %02d:%02d:%02d UTC",
+      tm.tm_year + 1900, tm.tm_mon + 1, tm.tm_mday,
+      tm.tm_hour, tm.tm_min, tm.tm_sec);
+  return std::string(tbuf);
+}
+
+static std::string fourcc_string(const MMAL_FOURCC_T fourcc)
+{
+  char buf[10];
+  mmal_4cc_to_string(buf, sizeof(buf), fourcc);
+  return std::string(buf);
+}
+
+
+static VideoCodec fourcc_to_video_codec(const MMAL_FOURCC_T x)
+{
+  switch (x) {
+    case MMAL_ENCODING_H264:
+      return VideoCodec::kCodecH264;
+    case MMAL_ENCODING_WVC1:
+      return VideoCodec::kCodecVC1;
+    case MMAL_ENCODING_MP1V:
+    case MMAL_ENCODING_MP2V:
+      return VideoCodec::kCodecMPEG2;
+    case MMAL_ENCODING_MP4V:
+      return VideoCodec::kCodecMPEG4;
+    case MMAL_ENCODING_THEORA:
+      return VideoCodec::kCodecTheora;
+    case MMAL_ENCODING_VP8:
+      return VideoCodec::kCodecVP8;
+    // Missing FOURCC for
+    // kCodecVP9,
+    // kCodecHEVC,
+    default:
+      break;
+  }
+  return VideoCodec::kUnknownVideoCodec;
+}
+
+static MMAL_FOURCC_T video_codec_to_fourcc(const VideoCodec x)
+{
+  switch (x) {
+    case VideoCodec::kCodecH264:
+      return MMAL_ENCODING_H264;
+    case VideoCodec::kCodecVC1:
+      return MMAL_ENCODING_WVC1;
+    case VideoCodec::kCodecMPEG2:
+      return MMAL_ENCODING_MP2V;
+    case VideoCodec::kCodecMPEG4:
+      return MMAL_ENCODING_MP4V;
+    case VideoCodec::kCodecTheora:
+      return MMAL_ENCODING_THEORA;
+    case VideoCodec::kCodecVP8:
+      return MMAL_ENCODING_VP8;
+    // Missing FOURCC for
+    // kCodecVP9,
+    // kCodecHEVC,
+    default:
+      break;
+  }
+  return MMAL_ENCODING_UNKNOWN;
+}
+
+#if 0
+static MMAL_FOURCC_T video_pixel_format_to_fourcc(const VideoPixelFormat pixel_format)
+{
+  switch (pixel_format) {
+    case PIXEL_FORMAT_I420:
+      return MMAL_ENCODING_I420;
+    case PIXEL_FORMAT_ARGB:
+      return MMAL_ENCODING_BGRA;
+    case PIXEL_FORMAT_ABGR:
+      return MMAL_ENCODING_RGBA;
+    default:
+      break;
+  }
+  return MMAL_ENCODING_UNKNOWN;
+}
+#endif
+
+static MMAL_FOURCC_T color_space_to_mmal(const VideoColorSpace &color_space)
+{
+  switch (color_space.primaries) {
+    case VideoColorSpace::PrimaryID::BT709:
+      return color_space.range == gfx::ColorSpace::RangeID::LIMITED ?
+        MMAL_COLOR_SPACE_ITUR_BT709 :
+        MMAL_COLOR_SPACE_JPEG_JFIF;
+
+    case VideoColorSpace::PrimaryID::SMPTE170M:
+      return MMAL_COLOR_SPACE_ITUR_BT601;
+
+    case VideoColorSpace::PrimaryID::SMPTE240M:
+      return MMAL_COLOR_SPACE_SMPTE240M;
+
+    case VideoColorSpace::PrimaryID::BT470M:
+      return MMAL_COLOR_SPACE_BT470_2_M;
+
+    case VideoColorSpace::PrimaryID::BT470BG:
+      return MMAL_COLOR_SPACE_BT470_2_BG;
+
+    default:
+      break;
+  }
+  return MMAL_COLOR_SPACE_UNKNOWN;
+}
+
+
+static inline uint32_t hashid(const gpu::Mailbox& id)
+{
+  uint32_t x = 0;
+  for (uint32_t c : id.name) {
+    x = x * 67 + c;
+  }
+  return x;
+}
+
+// Do a stride converting copy - if the strides are the same and line_len is
+// close then do a single block copy - we don't expect to have to preserve
+// pixels in the output frame
+static inline void mem_copy_2d(uint8_t * d_ptr, const size_t d_stride, const uint8_t * s_ptr, const size_t s_stride, size_t lines, const size_t line_len)
+{
+  if (s_stride == d_stride && s_stride < line_len + 32)
+  {
+    memcpy(d_ptr, s_ptr, s_stride * lines);
+  }
+  else
+  {
+    while (lines-- != 0) {
+      memcpy(d_ptr, s_ptr, line_len);
+      d_ptr += d_stride;
+      s_ptr += s_stride;
+    }
+  }
+}
+
+//-----------------------------------------------------------------------------
+
+class FpS
+{
+  // Average over this number of frames for running average
+  static const size_t avg_size_ = 128;
+
+  static uint64_t utime()
+  {
+    struct timespec ts;
+    clock_gettime(CLOCK_MONOTONIC, &ts);
+    return (uint64_t)ts.tv_sec * 1000000 + ts.tv_nsec / 1000;
+  }
+
+  uint64_t start_time_;
+  uint64_t period_time_;
+  unsigned int frame_count_;
+
+  uint64_t time_stash_[avg_size_];
+  size_t stash_n_;
+
+  void do_start(const uint64_t now)
+  {
+    start_time_ = now;
+    period_time_ = now;
+    stash_n_ = 0;
+  }
+
+public:
+  FpS() :
+    start_time_(0),
+    period_time_(0),
+    frame_count_(0),
+    time_stash_{0}
+  {
+  }
+
+  void start()
+  {
+    frame_count_ = 0;
+  }
+
+  void inc_frames()
+  {
+    const uint64_t now = utime();
+    if (frame_count_++ == 0)
+      do_start(now);
+    time_stash_[stash_n_] = now;
+    if (++stash_n_ >= avg_size_)
+      stash_n_ = 0;
+  }
+
+  bool period_expired(const uint64_t duration_us)
+  {
+    const uint64_t now = utime();
+    if (period_time_ + duration_us <= now) {
+      period_time_ += duration_us;
+      return true;
+    }
+    return false;
+  }
+
+  std::string ToString()
+  {
+    if (start_time_ == 0) {
+      return std::string("<uninit>");
+    }
+    const uint64_t now = utime();
+    if (start_time_ == now) {
+      return std::string("<inf>");
+    }
+
+    const uint64_t mFpS = ((uint64_t)frame_count_ * 1000000000) / (now - start_time_);
+    const uint64_t mFpS_avg = frame_count_ < avg_size_ ? 0 :
+      ((uint64_t)avg_size_ * 1000000000) / (now - time_stash_[stash_n_]);
+    std::ostringstream s;
+    s << frame_count_  << " @ "
+      << mFpS / 1000 << "." << std::setfill('0') << std::setw(3) << mFpS % 1000 << std::setw(0)
+      << ", avg: " << mFpS_avg / 1000 << "." << std::setfill('0') << std::setw(3) << mFpS_avg % 1000;
+
+    return s.str();
+  }
+};
+
+
+class MmalVideoDecoder::Options
+{
+  const bool single_process_;
+  const FrameCopyMode copy_mode_;
+  const bool red_pixel_;
+  const bool decode_opaque_;
+  const bool decode_i420_;
+  const bool resize_isp_;
+  const bool resize_resizer_;
+  const ResizeMode resize_mode_;
+  const bool low_delay_;
+  const unsigned int frame_buffers_;
+  const int decoders_;
+
+  const bool debug_bench_;
+  const bool debug_fps_;
+  const gfx::Size debug_fixed_size_;
+
+  size_t gpu_mem_ = 0;
+  uint32_t firmware_date_ = 0;
+  bool gpu_frames_ = false;
+  bool tex_import_ = false;
+
+  static unsigned int cl_uint(const base::CommandLine& cmd_line, const char name[], const unsigned int def_val = 0)
+  {
+    unsigned int val;
+    return base::StringToUint(cmd_line.GetSwitchValueNative(name), &val) ? val : def_val;
+  }
+
+  static int cl_int(const base::CommandLine& cmd_line, const char name[], const int def_val = 0)
+  {
+    int val;
+    return base::StringToInt(cmd_line.GetSwitchValueNative(name), &val) ? val : def_val;
+  }
+
+  static bool cl_flag(const base::CommandLine& cmd_line, const char name[])
+  {
+    return cmd_line.HasSwitch(name);
+  }
+
+  static gfx::Size cl_size(const base::CommandLine& cmd_line, const char name[])
+  {
+    base::CommandLine::StringType cl_str(cmd_line.GetSwitchValueNative(name));
+    const char * const cl(cl_str.c_str());
+    char * eoi = nullptr;
+    const unsigned long w = strtoul(cl, &eoi, 10);
+    if (*eoi != 'x' && *eoi != 'X') {
+      return gfx::Size();
+    }
+    const unsigned long h = strtoul(eoi + 1, &eoi, 10);
+    if (*eoi != '\0') {
+      return gfx::Size();
+    }
+    return gfx::Size(w, h);
+  }
+
+  static ResizeMode cl_resize_mode(const base::CommandLine& cmd_line, const char name[])
+  {
+    base::CommandLine::StringType cl_str(cmd_line.GetSwitchValueNative(name));
+    const char * const cl(cl_str.c_str());
+    if (!*cl)
+      return ResizeMode::unset;
+    else if (strcasecmp(cl, "never") == 0)
+      return ResizeMode::Never;
+    else if (strcasecmp(cl, "always") == 0)
+      return ResizeMode::Always;
+    else if (strcasecmp(cl, "smaller") == 0)
+      return ResizeMode::Smaller;
+    LOG(INFO) << "Unexpected resize mode: '" << cl << "'";
+    return ResizeMode::unset;
+  }
+
+  struct FirmwareDates {
+    static constexpr uint32_t HasOpaque = 1477958400;  // 2016-11-01
+    static constexpr uint32_t HasIsp = 1477958400;  // 2016-11-01
+  };
+
+  Options(const base::CommandLine& cmd_line) :
+    single_process_(cl_flag(cmd_line, "single-process" /*switches::kSingleProcess*/)),  // Just too hard to get libs right
+    copy_mode_(FrameCopyMode::FromString(cmd_line.GetSwitchValueNative(switches::kMmalCopyMode).c_str())),
+    red_pixel_(cl_flag(cmd_line, switches::kMmalRedPixel)),
+    decode_opaque_(cl_flag(cmd_line, switches::kMmalDecodeOpaque)),
+    decode_i420_(cl_flag(cmd_line, switches::kMmalDecodeI420)),
+    resize_isp_(cl_flag(cmd_line, switches::kMmalResizeIsp)),
+    resize_resizer_(cl_flag(cmd_line, switches::kMmalResizeResizer)),
+    resize_mode_(cl_resize_mode(cmd_line, switches::kMmalResizeMode)),
+    low_delay_(cl_flag(cmd_line, switches::kMmalLowDelay)),
+    frame_buffers_(cl_uint(cmd_line, switches::kMmalFrameBuffers)),
+    decoders_(cl_int(cmd_line, switches::kMmalDecoders, -1)),
+    debug_bench_(cl_flag(cmd_line, switches::kMmalDebugBench)),
+    debug_fps_(cl_flag(cmd_line, switches::kMmalDebugFps)),
+    debug_fixed_size_(cl_size(cmd_line, switches::kMmalDebugFixedSize))
+  {
+  }
+
+  bool opaque_good() const
+  {
+    return firmware_date_ >= FirmwareDates::HasOpaque;
+  }
+
+  bool isp_resize_good() const
+  {
+    return firmware_date_ >= FirmwareDates::HasIsp &&
+      gpu_mem_ >= (76 << 20);  // Take 76M as threshold for ISP use
+  }
+
+public:
+  static std::unique_ptr<Options> Create(const base::CommandLine& cmd_line = *base::CommandLine::ForCurrentProcess())
+  {
+    return std::unique_ptr<Options>(new Options(cmd_line));
+  }
+
+  // Default encoding now opaque
+  MMAL_FOURCC_T decoder_out_encoding() const
+  {
+    return  decode_i420_ || !(decode_opaque_ || opaque_good()) ?
+      MMAL_ENCODING_I420 :
+      MMAL_ENCODING_OPAQUE;
+  }
+
+  const char * resizer_component_name() const
+  {
+    return resize_resizer_ || copy_mode_.is_slice() || !(resize_isp_ || isp_resize_good()) ?
+      MMAL_COMPONENT_DEFAULT_RESIZER :
+      MMAL_COMPONENT_ISP_RESIZER;
+  }
+
+  FrameCopyMode frame_copy_mode(const bool has_slice_resize) const
+  {
+    return
+      copy_mode_ ? copy_mode_ :
+      has_slice_resize && !isp_resize_good() ? FrameCopyMode::SLICE :
+      !gpu_frames_ ?
+        OPT_FRAME_COPY_DEFAULT :
+      !tex_import_ ?
+        FrameCopyMode::FRAME_GPU_YUV_COPY :
+        OPT_FRAME_COPY_GPU_DEFAULT;
+  }
+
+  unsigned int frame_buffers(const FrameCopyMode copy_mode) const
+  {
+    return frame_buffers_ != 0 ? frame_buffers_ :
+      copy_mode == FrameCopyMode::SLICE ? SLICE_COPY_DEFAULT_BUFFERS : FRAME_COPY_DEFAULT_BUFFERS;
+  }
+
+  bool single_process() const
+  {
+    return single_process_;
+  }
+
+  unsigned int max_decoders() const
+  {
+    return decoders_ >= 0 ? decoders_ :
+      gpu_mem_ < (64 << 20) ? 0 : 1;  // Kill MMAL decode if we clearly have insufficient GPU mem
+  }
+
+  bool red_pixel() const
+  {
+    return red_pixel_;
+  }
+
+  bool low_delay(const bool low_delay_req = false) const
+  {
+    return low_delay_ || low_delay_req;
+  }
+
+  bool debug_bench() const
+  {
+    return debug_bench_;
+  }
+
+  bool debug_fps() const
+  {
+    return debug_bench_ || debug_fps_;
+  }
+
+  bool debug_fixed_size_set() const
+  {
+    return debug_fixed_size_.width() > 0 && debug_fixed_size_.height()  > 0;
+  }
+
+  gfx::Size debug_fixed_size() const
+  {
+    return debug_fixed_size_;
+  }
+
+  bool gpu_frames() const
+  {
+    return gpu_frames_;
+  }
+
+  ResizeMode resize_mode() const
+  {
+    return resize_mode_ != ResizeMode::unset ? resize_mode_ :
+      !gpu_frames() ? ResizeMode::Always :
+        ResizeMode::Smaller;
+  }
+
+  void set_gpu_mem(const size_t size)
+  {
+    gpu_mem_ = size;
+  }
+
+  void set_firmware_date(const uint32_t date)
+  {
+    firmware_date_ = date;
+  }
+
+  void set_gpu_frames(const bool gpu_frames)
+  {
+    gpu_frames_ = gpu_frames;
+  }
+
+  void set_tex_import(const bool tex_import)
+  {
+    tex_import_ = tex_import;
+  }
+
+  std::string ToString() const
+  {
+    std::ostringstream s;
+    s << "mmal frame_buffers=" << frame_buffers_ <<
+       ", mmal_copy_mode=" << copy_mode_ <<
+       ", mmal_low_delay=" << low_delay_ <<
+       ", mmal_decode_i420/opaque=" << decode_i420_ << "/" << decode_opaque_ <<
+       ", mmal_resize_isp/resizer=" << resize_isp_ << "/" << resize_resizer_ <<
+       ", mmal_resize_mode=" << (int)resize_mode_ <<
+       ", mmal_decoders=" << decoders_ <<
+       ", mmal_debug_bench=" << debug_bench_ <<
+       ", mmal_debug_fps=" << debug_fps_ <<
+       ", mmal_debug_fixed_size=" << debug_fixed_size_.ToString() <<
+       ", gpu_mem=" << gpu_mem_ <<
+       ", firmware_date=" << strgmtimet(firmware_date_) <<
+       ", gpu_frames=" << gpu_frames_ <<
+       ", tex_import=" << tex_import_;
+    return s.str();
+  }
+
+  std::string OptString() const
+  {
+    std::ostringstream s;
+    s << "isp_resize_good=" << isp_resize_good() <<
+      ", frame_copy_mode=" << frame_copy_mode(true) <<
+      ", resizer_component=" << resizer_component_name() <<
+      ", encoding=" << fourcc_string(decoder_out_encoding());
+    return s.str();
+  }
+};
+
+
+//-----------------------------------------------------------------------------
+
+
+#if TRACE_FRAME_STASH_NEW
+volatile base::subtle::Atomic32 total_stash_alloc = 0;
+#endif
+
+class VcsmAlloc
+{
+  unsigned int handle_ = 0;
+  unsigned int vc_ = 0;
+
+public:
+  VcsmAlloc() = default;
+
+  ~VcsmAlloc()
+  {
+    if (handle_ != 0)
+      vcsm_free(handle_);
+  }
+
+  operator bool() const
+  {
+    return handle_ != 0;
+  }
+
+  unsigned int get() const
+  {
+    return handle_;
+  }
+
+  unsigned int vc() const
+  {
+    return vc_;
+  }
+
+  bool ImportDmaBuf(const int fd)
+  {
+    DCHECK(handle_ == 0);
+    if (fd < 0 || (handle_ = vcsm_import_dmabuf(fd, "ChromeVideo")) == 0) {
+      return false;
+    }
+    vc_ = vcsm_vc_hdl_from_hdl(handle_);
+    return true;
+  }
+};
+
+class VcGenCmd {
+  bool init_good;
+  VCHI_INSTANCE_T vchi_instance;
+  VCHI_CONNECTION_T *vchi_connection = nullptr;
+
+public:
+  VcGenCmd() :
+    init_good(false),
+    vchi_instance(0),
+    vchi_connection(nullptr)
+  {
+    if (vchi_initialise(&vchi_instance) != 0) {
+      LOG(ERROR) << "VCHI initialization failed";
+      return;
+    }
+
+    //create a vchi connection
+    if (vchi_connect(nullptr, 0, vchi_instance) != 0) {
+      LOG(ERROR) << "VCHI connection failed";
+      return;
+    }
+
+    vc_vchi_gencmd_init(vchi_instance, &vchi_connection, 1);
+    init_good = true;
+  }
+
+  ~VcGenCmd()
+  {
+    if (init_good) {
+      int err;
+
+      vc_gencmd_stop();
+
+      //close the vchi connection
+      if ((err = vchi_disconnect(vchi_instance)) != 0) {
+        LOG(ERROR) << "VCHI disconnect failed, err=" << err;
+      }
+    }
+  }
+
+  size_t get_memory_gpu() const
+  {
+    int err;
+
+    if (!init_good) {
+      return 0;
+    }
+
+    //send the gencmd for the argument
+    if ((err = vc_gencmd_send("get_mem gpu")) != 0) {
+      LOG(ERROR) << "vc_gencmd_send returned " << err;
+      return 0;
+    }
+
+    char rbuf[1024] = {0};
+    if ((err = vc_gencmd_read_response(rbuf, sizeof(rbuf) - 1)) != 0) {
+      LOG(ERROR) << "vc_gencmd_read_response returned " << err;
+      return 0;
+    }
+
+    if (strncmp(rbuf, "gpu=", 4) != 0) {
+      LOG(ERROR) << "Unexpected response for get_mem gpu: '" << rbuf << "'";
+      return 0;
+    }
+
+    char * p;
+    unsigned long m = strtoul(rbuf + 4, &p, 10);
+
+    if (p[0] != 'M' || p[1] !='\0') {
+      LOG(ERROR) << "Unexpected numeric for get_mem gpu: '" << rbuf << "'";
+      return 0;
+    }
+
+    return m << 20;
+  }
+};
+
+class MmalVcInit : public base::RefCountedThreadSafe<MmalVcInit>
+{
+  static base::Lock& lock_;
+  static int ref_count_;
+
+  // Firmware & gpu_mem aren't going to change mid run so read once and
+  // use everywhere
+  static uint32_t firmware_date_;
+  static size_t gpu_mem_;
+  static bool cma_opened_;
+
+  bool init_done_;
+
+  friend base::RefCountedThreadSafe<MmalVcInit>;
+  virtual ~MmalVcInit()
+  {
+#if TRACE_COMPONENT_CREATION
+    LOG(INFO) << "@@@ Destroy MmalVcInit done=" << init_done_ << ", count=" << ref_count_;
+#endif
+
+    if (init_done_) {
+      base::AutoLock lock(lock_);
+      if (--ref_count_ == 0) {
+        mmal_vc_deinit();
+        vcsm_exit();
+      }
+    }
+  }
+
+  MmalVcInit(const bool single_process, const bool cma_req) :
+    init_done_(false)
+  {
+#if TRACE_COMPONENT_CREATION
+    LOG(INFO) << "@@@ Create MmalVcInit";
+#endif
+
+    base::AutoLock lock(lock_);
+
+    // Already done in this process?
+    if (ref_count_ != 0)
+    {
+      ++ref_count_;
+      init_done_ = true;
+      return;
+    }
+
+    // 1st time init static
+    cma_opened_ = false;
+
+    // The returned fds are at a minimum duped so close unconditionally when we exit
+    base::ScopedFD vchiq_fd;
+    base::ScopedFD vcsm_fd;
+
+    if (!single_process) {
+      {
+        base::Pickle request;
+        request.WriteInt(::service_manager::SandboxLinux::METHOD_OPEN_DEV_VCSM);
+        request.WriteBool(cma_req);
+
+        uint8_t reply_buf[512];
+        int fd;
+        const ssize_t reply_len = base::UnixDomainSocket::SendRecvMsgWithFlags(
+            ipc_fd(), reply_buf, sizeof(reply_buf), 0, &fd, request);
+        vcsm_fd = base::ScopedFD(fd);
+
+        if (reply_len == -1 || !vcsm_fd.is_valid()) {
+          LOG(ERROR) << "### Failed to open /dev/vchiq";
+          return;
+        }
+
+        base::Pickle reply(reinterpret_cast<char *>(reply_buf), reply_len);
+        base::PickleIterator pickle_iter(reply);
+        if (!pickle_iter.ReadBool(&cma_opened_))
+        {
+          LOG(ERROR) << "### Failed to valid vcsm open reply";
+          return;
+        }
+      }
+
+      {
+        base::Pickle request;
+        request.WriteInt(::service_manager::SandboxLinux::METHOD_OPEN_DEV_VCHIQ);
+
+        uint8_t reply_buf[512];
+        int fd;
+        const ssize_t reply_len = base::UnixDomainSocket::SendRecvMsgWithFlags(
+            ipc_fd(), reply_buf, sizeof(reply_buf), 0, &fd, request);
+        vchiq_fd = base::ScopedFD(fd);
+
+        if (reply_len == -1 || !vchiq_fd.is_valid()) {
+          LOG(ERROR) << "### Failed to open /dev/vchiq";
+          return;
+        }
+
+        // * Single process version of this?
+        base::Pickle reply(reinterpret_cast<char *>(reply_buf), reply_len);
+        base::PickleIterator pickle_iter(reply);
+        if (!pickle_iter.ReadUInt32(&firmware_date_))
+        {
+          LOG(ERROR) << "### Failed to get firmware date";
+          return;
+        }
+      }
+    }
+
+    int rv = vcsm_init_ex(cma_opened_, vcsm_fd.get());
+    if (rv != 0)
+    {
+      LOG(ERROR) << "### vcsm_init_ex("  << cma_opened_ << ", " << vcsm_fd.get() <<  ") failed, rv=" << rv;
+      return;
+    }
+
+    MMAL_STATUS_T err = mmal_vc_init_fd(vchiq_fd.get());
+    if (err != MMAL_SUCCESS) {
+      LOG(ERROR) << "### mmal_vc_init_fd failed: fd=" << vchiq_fd.get() << ", err=" << err;
+      vcsm_exit();
+      return;
+    }
+
+    ++ref_count_;
+    init_done_ = true;
+
+    gpu_mem_ = VcGenCmd().get_memory_gpu();
+  }
+public:
+  static scoped_refptr<MmalVcInit> Init(const bool single_process, const bool cma_wanted)
+  {
+    scoped_refptr<MmalVcInit> vci(new MmalVcInit(single_process, cma_wanted));
+
+    if (!vci->init_done_)
+      return nullptr;
+
+    return vci;
+  }
+
+  uint32_t firmware_date() const
+  {
+    return firmware_date_;
+  }
+
+  uint32_t gpu_mem() const
+  {
+    return gpu_mem_;
+  }
+
+  bool cma_opened() const
+  {
+    return cma_opened_;
+  }
+};
+
+
+base::Lock& MmalVcInit::lock_ = *new base::Lock();  // Somewhat nasty way of avoiding exit-time destruction
+int MmalVcInit::ref_count_ = 0;
+uint32_t MmalVcInit::firmware_date_ = 0;
+size_t MmalVcInit::gpu_mem_ = 0;
+bool MmalVcInit::cma_opened_ = false;
+
+// ----------------------------------------------------------------------------
+
+class FrameDescGPU;
+class FrameDesc
+{
+protected:
+  const unsigned int n_;  // Number of buffers
+  const uint32_t buffer_size_;
+  const gfx::Size frame_size_;
+  const gfx::ColorSpace color_space_;
+  uint32_t length_ = 0;
+  gpu::Mailbox id_;
+
+  FrameDesc(const unsigned int n, const size_t buffer_size, const gfx::Size& frame_size, const gfx::ColorSpace& color_space) :
+    n_(n),
+    buffer_size_(buffer_size),
+    frame_size_(frame_size),
+    color_space_(color_space)
+  {
+#if TRACE_DESC
+    LOG(INFO) << __func__ << ": " << (void *)this;
+#endif
+  }
+
+public:
+  virtual ~FrameDesc() {
+#if TRACE_DESC
+    LOG(INFO) << __func__ << ": " << (void *)this;
+#endif
+  }
+
+  size_t size() const {
+    return buffer_size_;
+  }
+
+  unsigned int buffer_count() const
+  {
+    return n_;
+  }
+
+  const gfx::Size& frame_size() const {
+    return frame_size_;
+  }
+
+  const gfx::ColorSpace& color_space() const {
+    return color_space_;
+  }
+
+  const gpu::Mailbox& get_id() const
+  {
+    return id_;
+  }
+
+  virtual unsigned int vc_handle()
+  {
+    return 0;
+  }
+
+  virtual FrameDescGPU * as_gpu()
+  {
+    return nullptr;
+  }
+  virtual const FrameDescGPU * as_gpu() const
+  {
+    return nullptr;
+  }
+
+  // 0 => no idea (needs a pixel type)
+  virtual int stride(const unsigned int plane_no = 0) const
+  {
+    return 0;
+  }
+
+  // Frame data
+  virtual uint8_t * frame(const unsigned int plane_no = 0) = 0;  // Not const as we may map
+  virtual base::ReadOnlySharedMemoryRegion * shared_memory()
+  {
+    return nullptr;
+  }
+  virtual void set_id_and_kill_cb(const gpu::Mailbox& id, base::OnceClosure kill_cb) = 0;
+
+  static FrameDesc * Extract(MMAL_BUFFER_HEADER_T * const buffer)
+  {
+    FrameDesc *const desc = (FrameDesc *)buffer->user_data;
+    DCHECK(desc != nullptr);
+//    DCHECK(desc->frame() == buffer->data);  // ** untrue for zc
+
+    buffer->user_data = nullptr;
+    buffer->data = nullptr;
+    buffer->length = 0;
+    buffer->alloc_size = 0;
+
+    return desc;
+  }
+
+  // ?? Maybe generate an Import method?
+};
+
+
+
+class FrameDescShmSingleBuffer : public FrameDesc
+{
+  base::ReadOnlySharedMemoryRegion smr_;
+  base::WritableSharedMemoryMapping smm_;
+
+//  std::unique_ptr<base::SharedMemory> shm_;
+  base::OnceClosure on_kill_cb_;
+
+public:
+  FrameDescShmSingleBuffer(const size_t size, const gfx::Size& frame_size, const gfx::ColorSpace& color_space) :
+    FrameDesc(1, size, frame_size, color_space)
+  {
+#if TRACE_FRAME_STASH_NEW
+    const base::subtle::Atomic32 talloc = base::subtle::NoBarrier_AtomicIncrement(&total_stash_alloc, (base::subtle::Atomic32)size);
+    LOG(ERROR) << "New frame: size=" << size << ", total=" << talloc;
+#endif
+
+    base::WritableSharedMemoryRegion wsmr(base::WritableSharedMemoryRegion::Create(size));
+    if (!wsmr.IsValid())
+    {
+      LOG(ERROR) << "### Smr creation failed";
+      return;
+    }
+
+    smm_ = wsmr.Map();
+    if (!smm_.IsValid())
+    {
+      LOG(ERROR) << "### Smm creation failed";
+      return;
+    }
+
+    smr_ = base::WritableSharedMemoryRegion::ConvertToReadOnly(std::move(wsmr));
+    if (!smr_.IsValid())
+    {
+      LOG(ERROR) << "### Smr make RO failed";
+      return;
+    }
+  }
+
+  ~FrameDescShmSingleBuffer() override
+  {
+//    LOG(ERROR) << " destroy frame desc fd=" << (shm_ == nullptr ? -99 : shm_->handle().fd);
+    if (!on_kill_cb_.is_null()) {
+      std::move(on_kill_cb_).Run();
+    }
+#if TRACE_FRAME_STASH_NEW
+    if (smm_.memory()) {
+      const base::subtle::Atomic32 talloc = base::subtle::NoBarrier_AtomicIncrement(&total_stash_alloc, -(base::subtle::Atomic32)buffer_size_);
+      LOG(ERROR) << "Delete frame: size=" << buffer_size_ << ", total=" << talloc;
+    }
+#endif
+  }
+
+  uint8_t * frame(const unsigned int plane_no = 0) override
+  {
+    DCHECK(plane_no == 0);
+    return (uint8_t *)smm_.memory();
+  }
+
+  base::ReadOnlySharedMemoryRegion * shared_memory() override
+  {
+    return &smr_;
+  }
+
+  void set_id_and_kill_cb(const gpu::Mailbox& id, base::OnceClosure kill_cb) override
+  {
+    if (id.IsZero()) {
+      return;
+    }
+    if (!id_.IsZero()) {
+      if (id != id_) {
+        LOG(ERROR) << "FrameDesc::" << __func__ << " ids don't match: " << hashid(id) << " -> " << hashid(id_);
+      }
+      return;
+    }
+    id_ = id;
+//    LOG(ERROR) << "FrameDesc::" << __func__ << " id=" << MmalVideoFrame::hashid(id);
+    if (!kill_cb.is_null()) {
+      on_kill_cb_ = std::move(kill_cb);
+    }
+  }
+};
+
+class FrameDescGPU : public FrameDesc
+{
+#if 0
+  static void DoMailboxHoldersReleased(
+      GpuVideoAcceleratorFactories* const gpu_factories,
+      const gpu::SyncToken release_sync_token,
+      std::unique_ptr<base::ScopedClosureRunner> waited_cb)
+  {
+    gpu_factories->SignalSyncToken(
+        release_sync_token,
+        base::BindOnce(&base::ScopedClosureRunner::RunAndReset, std::move(waited_cb)));
+  }
+#endif
+
+protected:
+  GpuVideoAcceleratorFactories* const gpu_factories_;
+  scoped_refptr<base::SingleThreadTaskRunner> gpu_thread_;
+
+  FrameDescGPU(
+      GpuVideoAcceleratorFactories* const gpu_factories,
+      const unsigned int n,
+      const size_t buffer_size, const gfx::Size& frame_size, const gfx::ColorSpace& color_space) :
+    FrameDesc(n, buffer_size, frame_size, color_space),
+    gpu_factories_(gpu_factories),
+    gpu_thread_(gpu_factories->GetTaskRunner())
+  {
+#if TRACE_DESC
+    LOG(INFO) << __func__;
+#endif
+  }
+  ~FrameDescGPU() override
+  {
+  }
+
+public:
+  const FrameDescGPU * as_gpu() const override
+  {
+    return this;
+  }
+  FrameDescGPU * as_gpu() override
+  {
+    return this;
+  }
+
+  void set_id_and_kill_cb(const gpu::Mailbox &id, base::OnceClosure kill_cb) override {
+    LOG(ERROR) << __func__ << ": Unexpected for GPU frame";
+    id_ = id;
+  }
+
+  void RunInGPUThreadOnce(base::OnceClosure closure)
+  {
+    gpu_thread_->PostTask(FROM_HERE, std::move(closure));
+  }
+
+  virtual int SetSyncImage(gpu::MailboxHolder * const boxes) = 0;
+#if 0
+  void MailboxHoldersReleased(const gpu::SyncToken& release_sync_token, std::unique_ptr<base::ScopedClosureRunner> waited_cb)
+  {
+    RunInGPUThreadOnce(base::BindOnce(&FrameDescGPU::DoMailboxHoldersReleased,
+                                      base::Unretained(gpu_factories_), release_sync_token, std::move(waited_cb)));
+  }
+#endif
+};
+
+
+class FrameDescGPUSingleBuffer : public FrameDescGPU
+{
+  enum class MapState {
+    Unmapped,
+    Mapped,
+    Fail
+  };
+
+  std::unique_ptr<gfx::GpuMemoryBuffer> gpu_buf_;
+  MapState map_state_ = MapState::Unmapped;
+  VcsmAlloc vcsm_;
+  MapState vcsm_state_ = MapState::Unmapped;
+
+//  const gfx::BufferFormat buffer_format_;
+  const uint32_t texture_target_;
+  gpu::Mailbox mailbox_;  // ?? Use Frame mailbox or id_ ??
+
+  static void DestroySharedImage(GpuVideoAcceleratorFactories* const gpu_factories, gpu::Mailbox mailbox)
+  {
+    gpu::SharedImageInterface *const sii = gpu_factories->SharedImageInterface();
+    if (sii == nullptr) {
+      LOG(INFO) << __func__ << "SharedImageInterface gone away";
+    }
+    else {
+      sii->DestroySharedImage(gpu::SyncToken(), mailbox);
+    }
+  }
+
+public:
+  FrameDescGPUSingleBuffer(GpuVideoAcceleratorFactories* const gpu_factories,
+                          const size_t buffer_size, const gfx::Size& frame_size, const gfx::ColorSpace& color_space,
+                          const gfx::BufferFormat buffer_format) :
+    FrameDescGPU(gpu_factories, 1, buffer_size, frame_size, color_space),
+//    buffer_format_(buffer_format),
+    texture_target_(gpu_factories_->ImageTextureTarget(buffer_format))
+  {
+#if TRACE_DESC
+    LOG(INFO) << __func__ << ": factories=" << (void*)gpu_factories;
+//     << ": " << frame_size.ToString() << ", type=" << gpu_buf_->GetType() << ", target=" << texture_target_;
+#endif
+    gpu_buf_ = gpu_factories->CreateGpuMemoryBuffer(frame_size, buffer_format,
+                                                  gfx::BufferUsage::SCANOUT_CPU_READ_WRITE);
+  }
+
+  void DeleteTexture()
+  {
+    if (!mailbox_.IsZero()) {
+      // Annoyingly must be run on gpu thread - so do that
+      RunInGPUThreadOnce(base::BindOnce(&FrameDescGPUSingleBuffer::DestroySharedImage, gpu_factories_, mailbox_));
+      mailbox_.SetZero();
+    }
+  }
+
+  ~FrameDescGPUSingleBuffer() override {
+    DeleteTexture();
+    if (map_state_ == MapState::Mapped)
+      gpu_buf_->Unmap();
+  }
+
+  // Used by GPUMultiBuffer
+  void SetSharedImage(gpu::MailboxHolder * const boxes)
+  {
+    gpu::SharedImageInterface *const sii = gpu_factories_->SharedImageInterface();
+    if (!mailbox_.IsZero()) {
+      sii->UpdateSharedImage(gpu::SyncToken(), mailbox_);   // *** Sync?? **
+    }
+    else {
+      const uint32_t flags =
+          gpu::SHARED_IMAGE_USAGE_GLES2_FRAMEBUFFER_HINT |
+          gpu::SHARED_IMAGE_USAGE_GLES2 | gpu::SHARED_IMAGE_USAGE_RASTER |
+          gpu::SHARED_IMAGE_USAGE_DISPLAY | gpu::SHARED_IMAGE_USAGE_SCANOUT;
+
+      mailbox_ = sii->CreateSharedImage(gpu_buf_.get(),
+                                   gpu_factories_->GpuMemoryBufferManager(),
+                                   color_space_,
+                                   flags);
+    }
+
+    if (mailbox_.IsZero()) {
+      LOG(ERROR) << __func__ << ": Failed to create output mailbox";
+    }
+
+    boxes[0].mailbox = mailbox_;
+    boxes[0].texture_target = texture_target_;
+  }
+
+  int SetSyncImage(gpu::MailboxHolder * const boxes) override
+  {
+    SetSharedImage(boxes);
+
+    gpu::SharedImageInterface *const sii = gpu_factories_->SharedImageInterface();
+    boxes[0].sync_token = sii->GenUnverifiedSyncToken();
+    return 1;
+  }
+
+  uint8_t * frame(const unsigned int plane_no = 0) override
+  {
+    if (map_state_ == MapState::Unmapped) {
+      map_state_ = gpu_buf_->Map() ? MapState::Mapped : MapState::Fail;
+    }
+    return map_state_ != MapState::Mapped ? nullptr : (uint8_t *)gpu_buf_->memory(plane_no);
+  }
+
+  unsigned int vc_handle() override
+  {
+    if (vcsm_state_ == MapState::Unmapped)
+    {
+      vcsm_state_ = MapState::Fail;
+      if (gpu_buf_->GetType() == gfx::NATIVE_PIXMAP)
+      {
+        // We don't have a ref method so have to copy :-(
+        // Cloned handles will close with bh
+        gfx::GpuMemoryBufferHandle bh(gpu_buf_->CloneHandle());
+        if (!bh.is_null()) {
+          if (vcsm_.ImportDmaBuf(bh.native_pixmap_handle.planes[0].fd.get()))
+            vcsm_state_ = MapState::Mapped;
+        }
+      }
+    }
+    return vcsm_state_ != MapState::Mapped ? 0 : vcsm_.vc();
+  }
+
+  int stride(const unsigned int plane_no = 0) const override {
+    return gpu_buf_->stride(plane_no);
+  }
+};
+
+
+class FrameDescGPUMultiBuffer : public FrameDescGPU
+{
+  gpu::Mailbox mailbox_;  // ?? Use Frame mailbox or id_ ??
+  std::unique_ptr<FrameDescGPUSingleBuffer> planes_[4];
+
+public:
+  enum MultiType {
+    YUV,
+    YC
+  };
+
+  FrameDescGPUMultiBuffer(GpuVideoAcceleratorFactories* const gpu_factories,
+                         const size_t buffer_size, const gfx::Size& frame_size, const gfx::ColorSpace& color_space,
+                         const gfx::BufferFormat buffer_format, const MultiType mt) :
+    FrameDescGPU(gpu_factories, mt == YC ? 2 : 3, buffer_size, frame_size, color_space)
+  {
+#if TRACE_DESC
+    LOG(INFO) << __func__;
+#endif
+    // All mutitypes start with a full size plane
+    planes_[0] = std::make_unique<FrameDescGPUSingleBuffer>(gpu_factories, buffer_size, frame_size, color_space, buffer_format);
+    switch (mt){
+      case YUV:
+      {
+        const gfx::Size uv_size((frame_size.width() + 1) / 2, (frame_size.height() + 1) / 2);
+        planes_[1] = std::make_unique<FrameDescGPUSingleBuffer>(gpu_factories, buffer_size/4, uv_size, color_space, buffer_format);
+        planes_[2] = std::make_unique<FrameDescGPUSingleBuffer>(gpu_factories, buffer_size/4, uv_size, color_space, buffer_format);
+        break;
+      }
+      case YC:
+      {
+        const gfx::Size c_size(frame_size.width(), (frame_size.height() + 1) / 2);
+        planes_[1] = std::make_unique<FrameDescGPUSingleBuffer>(gpu_factories, buffer_size/2, c_size, color_space, buffer_format);
+        break;
+      }
+    }
+  }
+
+  ~FrameDescGPUMultiBuffer() override
+  {
+  }
+
+  // Frame data
+  uint8_t * frame(const unsigned int plane_no = 0) override
+  {
+    return planes_[plane_no]->frame();
+  }
+
+  int stride(const unsigned int plane_no = 0) const override
+  {
+    return planes_[plane_no]->stride();
+  }
+
+  int SetSyncImage(gpu::MailboxHolder * const boxes) override
+  {
+    for (unsigned int i = 0; i != n_; ++i)
+      planes_[i]->SetSharedImage(boxes + i);
+
+    gpu::SharedImageInterface *const sii = gpu_factories_->SharedImageInterface();
+    const gpu::SyncToken token(sii->GenUnverifiedSyncToken());
+
+    for (unsigned int i = 0; i != n_; ++i)
+      boxes[i].sync_token = token;
+
+    return n_;
+  }
+};
+
+// Simple class to stash frames
+// Thread unsafe - use external locks
+class FrameStash
+{
+  bool killing_ = false;
+  const size_t size_ = 0;
+  const gfx::Size frame_size_;
+  const FrameCopyMode copy_mode_;
+  const gfx::ColorSpace color_space_;
+
+  std::queue<FrameDesc *> frames_;
+  GpuVideoAcceleratorFactories* const gpu_factories_;
+
+  FrameDesc * frame_pop()
+  {
+    FrameDesc * const frame = frames_.front();
+    frames_.pop();
+    return frame;
+  }
+
+  void empty_frames()
+  {
+    while (!frames_.empty()) {
+      delete frame_pop();
+    }
+  }
+
+  FrameDesc * new_frame() const
+  {
+    switch (copy_mode_.frame_desc_type())
+    {
+      case FrameDescType::SingleShm:
+        return new FrameDescShmSingleBuffer(size_, frame_size_, color_space_);
+      case FrameDescType::SingleGPU:
+        return new FrameDescGPUSingleBuffer(gpu_factories_, size_, frame_size_, color_space_,
+                                           copy_mode_.gfx_buffer_format());
+      case FrameDescType::MultiGPU:
+        return new FrameDescGPUMultiBuffer(gpu_factories_, size_, frame_size_, color_space_,
+                                          copy_mode_.gfx_buffer_format(), FrameDescGPUMultiBuffer::MultiType::YUV);
+      case FrameDescType::unset:
+        break;
+    }
+    return nullptr;
+  }
+
+public:
+  FrameStash(GpuVideoAcceleratorFactories* const gpu_factories,
+             const uint32_t buffer_size, const gfx::Size& frame_size,
+             const FrameCopyMode& copy_mode, const gfx::ColorSpace color_space) :
+    size_(buffer_size),
+    frame_size_(frame_size),
+    copy_mode_(copy_mode),
+    color_space_(color_space),
+    gpu_factories_(gpu_factories)
+  {
+  }
+
+  virtual ~FrameStash()
+  {
+    empty_frames();
+  }
+
+  void free_frame(FrameDesc * const frame)
+  {
+    if (killing_)
+      delete frame;
+    else
+      frames_.push(frame);
+  }
+
+  FrameDesc * alloc_frame()
+  {
+    if (killing_)
+      return nullptr;
+
+//    return !frames_.empty() ? frame_pop() : new_frame();
+    // ### Keep an old one to avoid any possibility of overwrite
+    return frames_.size() > 1 ? frame_pop() : new_frame();
+  }
+
+  void free_all_frames()
+  {
+    killing_ = true;
+    empty_frames();
+  }
+
+  const FrameCopyMode& copy_mode() const
+  {
+    return copy_mode_;
+  }
+
+  GpuVideoAcceleratorFactories* gpu_factories() const {
+    return gpu_factories_;
+  }
+};
+
+//-----------------------------------------------------------------------------
+
+// If main list is being reclaimed then all subsequent extracts should fail
+// If we have one or more running extracts then they must finish before
+// reclaim starts (by definition they must be on another thread)
+
+class DeferredList;
+class DeferredReclaim;
+class DeferredBuffer
+{
+  friend DeferredList;
+
+  scoped_refptr<DeferredList> list_;
+
+  MMAL_BUFFER_HEADER_T * buffer;    // protected by list_->reclaim_lock_
+  DeferredBuffer * next = nullptr;  // protected by list_->list_lock_
+  DeferredBuffer * prev = nullptr;  // protected by list_->list_lock_
+  bool has_lock = false;
+
+  DeferredBuffer(DeferredList * const dlist, MMAL_BUFFER_HEADER_T * const buffer) :
+    list_(dlist),
+    buffer(buffer)
+  {
+    DCHECK(buffer != nullptr);
+  }
+
+public:
+  ~DeferredBuffer();
+
+  MMAL_BUFFER_HEADER_T * ExtractAndLock();
+};
+
+// Locking:
+//   Reclaim = ReclaimStart -> ReclaimFinish
+//   InUse = Extract -> DeferredBuffer destruction
+//
+//   ReclaimStart waits for !InUse
+//   Extract fails on Reclaim
+//   AddBuffer fails on Reclaim
+
+
+class DeferredList : public base::RefCountedThreadSafe<DeferredList>
+{
+  friend base::RefCountedThreadSafe<DeferredList>;
+  friend DeferredReclaim;
+  friend DeferredBuffer;
+
+  base::Lock list_lock_;
+  base::Lock reclaim_lock_;
+  bool reclaim_ = false;
+
+  DeferredBuffer * head_ = nullptr;
+  DeferredBuffer * tail_ = nullptr;
+
+  int reclaim_count_;
+
+  ~DeferredList()
+  {
+    DCHECK(head_ == nullptr);
+    DCHECK(tail_ == nullptr);
+  }
+
+  void ReclaimStart() EXCLUSIVE_LOCK_FUNCTION(reclaim_lock_)
+  {
+    {
+      base::AutoLock lock(list_lock_);
+      reclaim_ = true;
+    }
+
+    reclaim_lock_.Acquire();
+  }
+
+  MMAL_BUFFER_HEADER_T* ExtractTail() ASSERT_EXCLUSIVE_LOCK(reclaim_lock_)
+  {
+    reclaim_lock_.AssertAcquired();
+
+    base::AutoLock lock(list_lock_);
+    DeferredBuffer * const dbuf = tail_;
+    if (!dbuf)
+      return nullptr;
+
+    MMAL_BUFFER_HEADER_T *const buffer = dbuf->buffer;
+    DCHECK(buffer != nullptr);
+
+    dbuf->buffer = nullptr;
+    tail_ = dbuf->prev;
+    *(dbuf->prev ? &dbuf->prev->next : &head_) = dbuf->next;
+    dbuf->next = dbuf->prev = nullptr;
+
+    return buffer;
+  }
+
+  void ReclaimFinish() UNLOCK_FUNCTION(reclaim_lock_)
+  {
+    reclaim_ = false;
+    reclaim_lock_.Release();
+  }
+
+  MMAL_BUFFER_HEADER_T * Extract(DeferredBuffer * const dbuf) EXCLUSIVE_TRYLOCK_FUNCTION(true, reclaim_lock_)
+  {
+    if (!reclaim_lock_.Try())
+    {
+      // If we failed to get the reclaim lock assume that our buffer
+      // will be eaten by the reclaim process if it hasn't been already
+      return nullptr;
+    }
+
+    MMAL_BUFFER_HEADER_T * const buffer = dbuf->buffer;
+
+    if (!buffer) {
+      // Buffer already grabbed by reclaim
+      // Release lock & return null
+      reclaim_lock_.Release();
+      return nullptr;
+    }
+
+    base::AutoLock lock(list_lock_);
+    dbuf->buffer = nullptr;
+    *(dbuf->next ? &dbuf->next->prev : &tail_) = dbuf->prev;
+    *(dbuf->prev ? &dbuf->prev->next : &head_) = dbuf->next;
+    dbuf->next = dbuf->prev = nullptr;
+    // has_lock means we will drop the lock when the calling DBuffer is
+    // deleted
+    dbuf->has_lock = true;
+
+    return buffer;
+  }
+
+  // Only called from DeferredBuffer destructor so cleanup of
+  // dbuf vars is ignored
+  void ExtractDone() UNLOCK_FUNCTION(reclaim_lock_)
+  {
+    reclaim_lock_.Release();
+  }
+
+public:
+  DeferredList()
+  {
+  }
+
+  std::unique_ptr<DeferredBuffer> AddBuffer(MMAL_BUFFER_HEADER_T * const buffer)
+  {
+    if (!buffer) {
+      LOG(ERROR) << "Unexpected NULL deferred buffer";
+      return std::unique_ptr<DeferredBuffer>();
+    }
+
+    base::AutoLock lock(list_lock_);
+
+    if (reclaim_)
+      return std::unique_ptr<DeferredBuffer>();
+
+    std::unique_ptr<DeferredBuffer> dbuf(new DeferredBuffer(this, buffer));
+
+    if (head_) {
+      head_->prev = dbuf.get();
+      dbuf->next = head_;
+    }
+    else {
+      tail_ = dbuf.get();
+    }
+    head_ = dbuf.get();
+
+    return dbuf;
+  }
+};
+
+class DeferredReclaim
+{
+  scoped_refptr<DeferredList> list_;
+public:
+  DeferredReclaim(const scoped_refptr<DeferredList>& dlist) :
+    list_(dlist)
+  {
+    list_->ReclaimStart();
+  }
+  ~DeferredReclaim()
+  {
+    list_->ReclaimFinish();
+  }
+  MMAL_BUFFER_HEADER_T * Extract()
+  {
+    return list_->ExtractTail();
+  }
+};
+
+DeferredBuffer::~DeferredBuffer()
+{
+  if (buffer) {
+    MMAL_BUFFER_HEADER_T * const buf = list_->Extract(this);
+    if (buf) {
+      // Shouldn't happen - if it does then winge and do our best
+      LOG(ERROR) << __func__ << ": Buffer still valid";
+      mmal_buffer_header_release(buf);
+    }
+  }
+  if (has_lock)
+    list_->ExtractDone();
+}
+
+MMAL_BUFFER_HEADER_T *
+DeferredBuffer::ExtractAndLock()
+{
+  // has_lock get set as part of Extract
+  return list_->Extract(this);
+}
+
+
+class ESBufferHolder {
+  scoped_refptr<DecoderBuffer> buffer_;
+  VideoDecoder::DecodeCB decode_cb_;
+  const bool not_pkt_ = false;
+  uint32_t offset_ = 0;
+
+  ESBufferHolder(const scoped_refptr<DecoderBuffer>& buffer, VideoDecoder::DecodeCB decode_cb, const bool not_pkt) :
+    buffer_(buffer),
+    decode_cb_(std::move(decode_cb)),
+    not_pkt_(not_pkt)
+  {
+  }
+
+public:
+  static std::unique_ptr<ESBufferHolder>
+  Create(const scoped_refptr<DecoderBuffer>& buffer, VideoDecoder::DecodeCB decode_cb)
+  {
+    return std::unique_ptr<ESBufferHolder>(new ESBufferHolder(buffer, std::move(decode_cb), false));
+  }
+
+  static std::unique_ptr<ESBufferHolder>
+  Create(const scoped_refptr<DecoderBuffer>& buffer)
+  {
+    return std::unique_ptr<ESBufferHolder>(new ESBufferHolder(buffer, VideoDecoder::DecodeCB(), false));
+  }
+
+  static std::unique_ptr<ESBufferHolder>
+  CreateExtra(const scoped_refptr<DecoderBuffer>& buffer)
+  {
+    return std::unique_ptr<ESBufferHolder>(new ESBufferHolder(buffer, VideoDecoder::DecodeCB(), true));
+  }
+
+  ~ESBufferHolder() = default;
+
+  bool is_eos() const
+  {
+    return buffer_->end_of_stream();
+  }
+
+  bool is_start() const
+  {
+    return offset_ == 0;
+  }
+
+  bool is_done() const
+  {
+    return !buffer_;
+  }
+
+  bool is_not_pkt() const
+  {
+    return not_pkt_;
+  }
+
+  const uint8_t * data() const
+  {
+    return buffer_->data() + offset_;
+  }
+
+  uint32_t length(uint32_t max_length) const
+  {
+    return std::min(buffer_->data_size() - offset_, max_length);
+  }
+
+  VideoDecoder::DecodeCB take_callback()
+  {
+    return std::move(decode_cb_);
+  }
+
+  void Consume()
+  {
+    buffer_.reset();
+  }
+
+  void Consume(const uint32_t size)
+  {
+    if ((offset_ += size) >= buffer_->data_size()) {
+      buffer_.reset();
+    }
+  }
+
+  base::TimeDelta pts() const
+  {
+    return buffer_->timestamp();
+  }
+
+};
+
+//-----------------------------------------------------------------------------
+
+// Trampoline class
+// This allows us to attach callbacks from VideoFrames to our
+// component / port without it locking down the component.
+// If the component is dead by the time the callback arrives then it is simply
+// dropped on the floor
+//
+// * Extended well past original intention - rather more than just
+//   a trampoline now... Should be renamed
+
+// A number of functions in this class (in particular "kill") look like they
+// might cause suicide which would be bad as the AutoLock would be removed
+// after it was destroyed. This is prevented by the fact that this class should
+// only be accessed though scoped_refptrs so the calling fn should have a ref
+// on us for at least the duration of the call.
+
+class MmalTrampoline : public base::RefCountedThreadSafe<MmalTrampoline>
+{
+  typedef base::RepeatingCallback<void(const int)> MmalCopiedFramedDestructionCB;
+#if TRACE_TRAMPOLINE
+  // These two are only used for debug
+  static int seq_count_; // Seq number counter
+  const int seq_;  // Debugging sequence number
+#endif
+  // We need this for VCSM GPU stuff but there is little harm
+  // in general
+  const scoped_refptr<MmalVcInit> vc_init_;
+
+  base::Lock lock_;
+  int in_flight_;
+  bool low_traced_;
+  const int max_in_flight_;
+  MmalCopiedFramedDestructionCB destruction_cb_;
+  FrameStash frame_stash_;
+
+  friend base::RefCountedThreadSafe<MmalTrampoline>;
+  virtual ~MmalTrampoline()
+  {
+#if TRACE_TRAMPOLINE
+    LOG(ERROR) << "@@@ " << __func__ << "[" << seq_ << "]";
+#endif
+  }
+public:
+  MmalTrampoline(
+      const scoped_refptr<MmalVcInit>& vc_init,
+      GpuVideoAcceleratorFactories* const gpu_factories,
+      const uint32_t buffer_size, const gfx::Size& frame_size,
+      const FrameCopyMode& copy_mode,
+      const gfx::ColorSpace& color_space,
+      const int max_in_flight,
+      const MmalCopiedFramedDestructionCB& destruction_cb) :
+#if TRACE_TRAMPOLINE
+    seq_(++seq_count_),
+#endif
+    vc_init_(vc_init),
+    in_flight_(0),
+    low_traced_(true),
+    max_in_flight_(max_in_flight),
+    destruction_cb_(destruction_cb),
+    frame_stash_(gpu_factories, buffer_size, frame_size, copy_mode, color_space)
+  {
+#if TRACE_TRAMPOLINE
+    LOG(ERROR) << "@@@ " <<  __func__ << "[" << seq_ << "]";
+#endif
+  }
+
+  void kill()
+  {
+#if TRACE_TRAMPOLINE
+    LOG(ERROR) << "--- "  << "[" << seq_ << "] Trampoline::kill";
+#endif
+    base::AutoLock lock(lock_);
+    destruction_cb_.Reset();
+    frame_stash_.free_all_frames();
+  }
+
+  void free_frame(FrameDesc * const frame, const int buffer_count)
+  {
+    lock_.Acquire();
+
+    // Some callbacks can call us back
+    // We don't have recursive locks - so copy the callback for later use
+    // outside the lock
+    const MmalCopiedFramedDestructionCB cb = destruction_cb_;
+
+    frame_stash_.free_frame(frame);
+
+    // in_flight_ can exceed max_in_flight_ by the number of frames
+    // that can fit in the mmal port.  Avoid stuffing more than we have had returned.
+    const int stuff_count = std::min(in_flight_ - max_in_flight_, buffer_count);
+
+    if ((in_flight_ -= buffer_count) < 0)
+      LOG(FATAL) << "Buffers in flight underflow";
+
+#if TRACE_TRAMPOLINE
+    LOG(ERROR)  << "[" << seq_ << "] killed=" << destruction_cb_.is_null() << ", in_flight:" << in_flight_ << "/" << max_in_flight_ <<
+      ", BCount=" << buffer_count <<
+      ", Stuff=" << stuff_count;
+#endif
+    // Some hysteresis on in_flight logging - do not log if killed
+    if (in_flight_ < max_in_flight_ / 2 && !low_traced_ && !cb.is_null()) {
+      low_traced_ = true;
+      LOG(INFO) << "--- In flight low: " << in_flight_ << "/" << max_in_flight_;
+    }
+    else if (in_flight_ >= max_in_flight_ - 1 && low_traced_) {
+      low_traced_ = false;
+      LOG(INFO) << "--- In flight OK: " << in_flight_ << "/" << max_in_flight_;
+    }
+
+    lock_.Release();
+
+    if (stuff_count > 0 && !cb.is_null())
+      cb.Run(std::min(buffer_count, stuff_count));
+  }
+
+  const FrameCopyMode& copy_mode() const
+  {
+    return frame_stash_.copy_mode();
+  }
+
+  // *** ?? Can size or format ever change in the lifetime of a trampoline ??
+  FrameDesc * alloc_frame()
+  {
+    base::AutoLock lock(lock_);
+    return frame_stash_.alloc_frame();
+  }
+
+  bool recycle_buffer_in_flight(MMAL_BUFFER_HEADER_T * const buffer)
+  {
+    lock_.Acquire();
+    const bool wants_recycle = (++in_flight_ <= max_in_flight_);
+    lock_.Release();
+
+    if (wants_recycle)
+    {
+#if TRACE_TRAMPOLINE
+      LOG(ERROR) << "[" << seq_ << "] recycle: in flight=" << in_flight_;
+#endif
+      return true;
+    }
+#if TRACE_TRAMPOLINE
+    LOG(ERROR) << "[" << seq_ << "] release, in_flight=" << in_flight_;
+#endif
+
+    // Was Deadlock opportunity
+    // ?? pool starvation opportunity now
+
+    buffer_release(buffer);
+    return false;
+  }
+
+  bool is_stalling() const
+  {
+    return in_flight_ >= max_in_flight_;
+  }
+
+  // GPU frame only callbacks
+  // Replace the kill_id_ & id_ processing for GPU frames
+
+  void MailboxHoldersWaited(FrameDescGPU * const frame_desc)
+  {
+#if TRACE_DESC
+    LOG(INFO) << __func__ << ": " << (void*)frame_desc;
+#endif
+    free_frame(frame_desc, 1);
+  }
+
+public:
+  void MailboxHoldersReleased(FrameDescGPU * const frame_desc, const gpu::SyncToken& release_sync_token)
+  {
+#if TRACE_DESC
+    LOG(INFO) << __func__ << ": " << (void*)frame_desc;
+#endif
+
+    // TODO(sandersd): Remove once https://crbug.com/819914 is fixed. Correct
+    // clients must wait for READ_LOCK_FENCES_ENABLED frames to be read before
+    // returning the frame, so waiting on the sync token should be a no-op.
+    //
+    // If the context is lost, SignalSyncToken() drops its callbacks. Using a
+    // ScopedClosureRunner ensures MailboxHoldersWaited() is called if that
+    // happens.
+
+//    frame_desc->MailboxHoldersReleased(release_sync_token,
+//                                       std::make_unique<base::ScopedClosureRunner>(base::BindOnce(
+//                                           &::media::MmalTrampoline::MailboxHoldersWaited, this,
+//                                           frame_desc)));
+    frame_desc->RunInGPUThreadOnce(base::BindOnce(
+                                           &::media::MmalTrampoline::MailboxHoldersWaited, this,
+                                           frame_desc));
+  }
+
+};
+
+#if TRACE_TRAMPOLINE
+int MmalTrampoline::seq_count_ = 0;
+#endif
+
+//--------------------------------------------- --------------------------------
+
+
+static base::Optional<VideoFrameLayout> MakeLayout(const FrameCopyMode& copy_mode, const FrameDesc * const frame)
+{
+  const unsigned int buf_n = frame->buffer_count();
+  const unsigned int plane_n = copy_mode.planes();
+
+  std::vector<ColorPlaneLayout> planes;
+
+  size_t offset = 0;
+  for (unsigned int i = 0; i != plane_n; ++i) {
+    size_t stride = frame->stride(i);
+    size_t size = stride * copy_mode.height_to_lines(i, frame->frame_size().height());
+
+    if (stride == 0)
+      stride = copy_mode.width_to_stride(i, frame->frame_size().width());
+
+    planes.emplace_back(stride, offset, size);
+    // Whilst we have backing buffers assume that planes match them 1:1
+    if (i + 1 >= buf_n)
+      offset += size;
+  }
+
+  if (buf_n == 1) {
+    return VideoFrameLayout::CreateWithPlanes(copy_mode.pixel_format(),
+                                              frame->frame_size(), planes); // **** Modifiers *****????
+  }
+  return VideoFrameLayout::CreateMultiPlanar(copy_mode.pixel_format(),
+                                            frame->frame_size(), planes); // **** Modifiers *****????
+}
+
+class MmalVideoFrame : public VideoFrame
+{
+protected:
+  const scoped_refptr<MmalTrampoline> trampoline_;
+  FrameDesc * const frame_desc_;
+  gpu::Mailbox id_;
+
+  ~MmalVideoFrame() override {
+#if TRACE_DESC
+    LOG(INFO) << "@@@ " << __func__ << ": " << (void*)this;
+#endif
+  }
+
+private:
+  void set_frame_data()
+  {
+    if (IsMappable()) {
+      unsigned int buf_no = 0;
+      for (size_t i = 0; i != layout().num_planes(); ++i) {
+        const size_t offset = layout().planes()[i].offset;
+        if (offset == 0 && i != 0)
+          ++buf_no;
+
+//        LOG(INFO) << "[" << i << "/" << buf_no << "] offset=" << offset;
+        set_data(i, frame_desc_->frame(buf_no) + offset);
+      }
+    }
+  }
+
+public:
+  MmalVideoFrame(
+      FrameDesc * const frame_desc,
+      const scoped_refptr<MmalTrampoline>& trampoline,
+      const gfx::Rect& visible_rect,
+      const gfx::Size& natural_size,
+      const base::TimeDelta timestamp) :
+    VideoFrame(
+      MakeLayout(trampoline->copy_mode(), frame_desc).value(),
+      trampoline->copy_mode().frame_storage_type(),
+      visible_rect, natural_size, timestamp),
+    trampoline_(trampoline),
+    frame_desc_(frame_desc),
+    id_(frame_desc->get_id())
+  {
+#if TRACE_DESC
+    LOG(INFO) << "@@@ " << __func__ << ": " << (void*)this << ": " << visible_rect.ToString();
+#endif
+    set_frame_data();
+  }
+
+  static scoped_refptr<MmalVideoFrame> Coerce(const scoped_refptr<VideoFrame>& frame)
+  {
+    if (frame->format() != PIXEL_FORMAT_MMAL_BUFFER) {
+      NOTREACHED();
+      return scoped_refptr<MmalVideoFrame>();
+    }
+    return scoped_refptr<MmalVideoFrame>(static_cast<MmalVideoFrame *>(frame.get()));
+  }
+
+  uint32_t hashid() const
+  {
+    return media::hashid(id_);
+  }
+
+  const base::ReadOnlySharedMemoryRegion * ro_shm_region() const override {
+    return frame_desc_->shared_memory();
+  }
+
+  const gpu::Mailbox& GetBitmapId() const override {
+    return id_;
+  }
+
+  void copy_buffer(const MMAL_BUFFER_HEADER_T * const buffer)
+  {
+    for (size_t i = 0; i != layout().num_planes(); ++i) {
+      mem_copy_2d(data(i), layout().planes()[i].stride,
+                  buffer->data + buffer->type->video.offset[i], buffer->type->video.pitch[i],
+                  rows(i), row_bytes(i));
+    }
+  }
+};
+
+//-----------------------------------------------------------------------------
+
+class MmalShmVideoFrame : public media::MmalVideoFrame
+{
+  base::OnceClosure kill_id_;
+  int buffer_count_ = 0;
+
+  ~MmalShmVideoFrame() override
+  {
+    frame_desc_->set_id_and_kill_cb(id_, std::move(kill_id_));
+    trampoline_->free_frame(frame_desc_, buffer_count_);
+  }
+
+  using MmalVideoFrame::MmalVideoFrame;  // Args & init all the same as for base
+
+public:
+  static scoped_refptr<MmalShmVideoFrame> Create(
+      FrameDesc * const frame_desc,
+      const scoped_refptr<MmalTrampoline>& trampoline,
+      const gfx::Rect& visible_rect,
+      const gfx::Size& natural_size,
+      const base::TimeDelta timestamp = kNoTimestamp)
+  {
+    return new MmalShmVideoFrame(frame_desc, trampoline, visible_rect, natural_size, timestamp);
+  }
+
+  void inc_buffer_count()
+  {
+    ++buffer_count_;
+  }
+
+  bool SetBitmapIdAndKillCB(const gpu::Mailbox& id, base::OnceClosure kill) override {
+    kill_id_ = std::move(kill);
+    id_ = id;
+    return true;
+  }
+};
+
+// ----------------------------------------------------------------------------
+
+class MmalGPUVideoFrame : public media::MmalVideoFrame
+{
+  ~MmalGPUVideoFrame() override {}
+
+  // Create a VideoFrame and move the frame stash into it from
+  // the mmal buffer
+  MmalGPUVideoFrame(FrameDesc * const frame_desc,
+      const scoped_refptr<MmalTrampoline>& trampoline,
+      const gfx::Rect& visible_rect,
+      const gfx::Size& natural_size,
+      const base::TimeDelta timestamp) :
+      MmalVideoFrame(
+        frame_desc, trampoline,
+        visible_rect, natural_size, timestamp)
+  {
+#if TRACE_DESC
+    LOG(INFO) << __func__ << "A";
+    LOG(INFO) << __func__ << ": HasTextures: " << HasTextures() << ", this=" << (void*)this << ", desc=" << (void*)frame_desc_;
+    LOG(INFO) << __func__ << "B";
+#endif
+
+    metadata()->SetBoolean(VideoFrameMetadata::ALLOW_OVERLAY, true);
+    metadata()->SetBoolean(VideoFrameMetadata::COPY_REQUIRED, false);
+    metadata()->SetBoolean(VideoFrameMetadata::READ_LOCK_FENCES_ENABLED, true);
+  }
+
+public:
+  static scoped_refptr<MmalGPUVideoFrame> Create(FrameDesc * const frame_desc,
+      const scoped_refptr<MmalTrampoline>& trampoline,
+      const gfx::Rect& visible_rect,
+      const gfx::Size& natural_size,
+      const base::TimeDelta timestamp = kNoTimestamp)
+  {
+    return new MmalGPUVideoFrame(frame_desc, trampoline, visible_rect, natural_size, timestamp);
+  }
+
+  // Must be run in GPU thread
+  void BindAndEmit(const VideoDecoder::OutputCB& emit_cb)
+  {
+    FrameDescGPU * const gpu_desc_ = frame_desc_->as_gpu();
+
+    {
+      gpu::MailboxHolder mbh[3];
+      const int n = gpu_desc_->SetSyncImage(mbh);
+      for (int i = 0; i < n; ++i) {
+        set_mailbox_holder(i, mbh[i]);
+      }
+    }
+
+    SetReleaseMailboxCB(
+        base::BindOnce(&MmalTrampoline::MailboxHoldersReleased, trampoline_, base::Unretained(gpu_desc_)));
+
+    emit_cb.Run(this);
+  }
+};
+
+// ----------------------------------------------------------------------------
+
+
+// Pool base class - can be instantiated
+class MmalPool
+{
+  const scoped_refptr<MmalVcInit> vc_init_;
+
+public:
+  typedef base::Callback<bool(MMAL_BUFFER_HEADER_T * buffer)> MmalPoolBufferReleaseCB;
+
+private:
+  MmalPoolBufferReleaseCB pool_cb_;
+
+protected:
+  virtual bool do_pool_cb(MMAL_BUFFER_HEADER_T * const buffer)
+  {
+    return pool_cb_.Run(buffer);
+  }
+
+private:
+  static MMAL_BOOL_T static_pool_cb(MMAL_POOL_T *pool, MMAL_BUFFER_HEADER_T *buffer, void *userdata)
+  {
+    return ((MmalPool *)userdata)->do_pool_cb(buffer);
+  }
+
+protected:
+  MMAL_POOL_T * pool_;
+
+  MmalPool(const scoped_refptr<MmalVcInit>& vc_init) :
+    vc_init_(vc_init),
+    pool_(nullptr)
+  {
+  }
+
+  // Must be called as part of create if you ever want callbacks to work
+  void set_static_pool_cb()
+  {
+    mmal_pool_callback_set(pool_, static_pool_cb, this);
+  }
+
+public:
+  // N.B. Overriding classes are responsible for freeing pool_ correctly
+  virtual ~MmalPool()
+  {
+  }
+
+  virtual const char * pool_type_name() const
+  {
+    return "PoolBase";
+  }
+
+  virtual MMAL_BUFFER_HEADER_T * get_timeout(const uint32_t timeout_ms)
+  {
+    return mmal_queue_timedwait(pool_->queue, timeout_ms);
+  }
+
+  virtual MMAL_BUFFER_HEADER_T * get()
+  {
+    return mmal_queue_get(pool_->queue);
+  }
+
+  virtual void put(MMAL_BUFFER_HEADER_T * const buffer)
+  {
+    mmal_queue_put(pool_->queue, buffer);
+  }
+
+  // Do the equivalent of put then get
+  // Will refresh buffer->data if required
+  virtual MMAL_BUFFER_HEADER_T * put_get(MMAL_BUFFER_HEADER_T * const buffer)
+  {
+    return buffer;
+  }
+
+  uint32_t length() const
+  {
+    return mmal_queue_length(pool_->queue);
+  }
+
+  // Pool size (not data size)
+  uint32_t size() const
+  {
+    return pool_->headers_num;
+  }
+
+  // Thing we are servicing may have changed shape
+  // By default ignore
+  virtual int port_resized(const uint32_t num, const uint32_t buf_size, const gfx::Size& frame_size)
+  {
+    return 0;
+  }
+
+  virtual int create(const uint32_t num, const uint32_t buf_size, const gfx::Size& frame_size) = 0;
+
+  // Enable/disable aren't required fns but add helpful hints
+  // to some derived classes
+  // * Could be used to debug unexpected pool movement
+  virtual int disable()
+  {
+    pool_cb_.Reset();
+    return 0;
+  }
+
+  virtual int enable(const MmalPoolBufferReleaseCB& cb)
+  {
+    pool_cb_ = cb;
+    return 0;
+  }
+
+  // This isn't exactly part of a base pool implementation
+  // but it saves a spurious extra layer
+  virtual void set_trampoline(const scoped_refptr<MmalTrampoline>& trampoline)
+  {
+  }
+};
+
+//-----------------------------------------------------------------------------
+//
+// Pool attached to a port
+class MmalPortPool : public MmalPool
+{
+  MMAL_PORT_T * const port_;
+public:
+  MmalPortPool(const scoped_refptr<MmalVcInit>& vc_init, MMAL_PORT_T * const port) :
+    MmalPool(vc_init),
+    port_(port)
+  {
+  }
+
+  ~MmalPortPool() override
+  {
+    if (pool_) {
+      mmal_port_pool_destroy(port_, pool_);
+    }
+  }
+
+  const char * pool_type_name() const override
+  {
+    return "PoolPort";
+  }
+
+  int create(const uint32_t num, const uint32_t buf_size, const gfx::Size& frame_size) override
+  {
+    if (!(pool_ = mmal_port_pool_create(port_, num, buf_size)))
+    {
+      LOG(ERROR) << "### mmal_port_pool_create failed: " << num << "*" << buf_size;
+      return -1;
+    }
+    set_static_pool_cb();
+    return 0;
+  }
+};
+
+//-----------------------------------------------------------------------------
+//
+// Pool not attached to a port
+
+class MmalUserPool : public MmalPool
+{
+public:
+  MmalUserPool(const scoped_refptr<MmalVcInit>& vc_init) :
+    MmalPool(vc_init)
+  {
+  }
+
+  ~MmalUserPool() override
+  {
+    if (pool_) {
+      mmal_pool_destroy(pool_);
+    }
+  }
+
+  const char * pool_type_name() const override
+  {
+    return "PoolUser";
+  }
+
+  int create(const uint32_t num, const uint32_t buf_size, const gfx::Size& frame_size) override
+  {
+    if (!(pool_ = mmal_pool_create(num, buf_size)))
+    {
+      LOG(ERROR) << "### mmal_pool_create failed: " << num << "*" << buf_size;
+      return -1;
+    }
+    set_static_pool_cb();
+    return 0;
+  }
+};
+
+//-----------------------------------------------------------------------------
+//
+// Pool that has detachable frame buffers allocated by our trampoline
+// Buffers in the pool have no frame buffers attached
+// Buffers are attached on get and detached on release
+// * For a more generic version we could have callback alloc/free fns
+class MmalFramePool : public MmalUserPool
+{
+protected:
+  scoped_refptr<MmalTrampoline> trampoline_;
+  size_t buffer_size_ = 0;
+  gfx::Size frame_size_;
+  const FrameCopyMode copy_mode_;
+
+  virtual MMAL_BUFFER_HEADER_T * attach_data_buffer(MMAL_BUFFER_HEADER_T * const buffer)
+  {
+    // Ignore null
+    if (buffer != nullptr) {
+      if (buffer->data != nullptr) {
+        LOG(FATAL) << "Buffer already in use";
+      }
+
+      FrameDesc * frame;
+      if ((frame = trampoline_->alloc_frame()) == nullptr)
+      {
+        LOG(ERROR) << "### " << __func__ << ": alloc frame failed";
+        // If we cannot alloc then release buffer back to pool as we are about
+        // to lose track of it
+        buffer_release(buffer);
+        return nullptr;
+      }
+      buffer->user_data = frame;
+      buffer->data = frame->frame();
+      buffer->alloc_size = frame->size();
+    }
+    return buffer;
+  }
+
+  MMAL_BUFFER_HEADER_T * detach_data_buffer(MMAL_BUFFER_HEADER_T * const buffer)
+  {
+    if (buffer != nullptr && buffer->data != nullptr) {
+      // This is called on buffer release so should have no "in-flight" component
+      trampoline_->free_frame((FrameDesc *)buffer->user_data, 0);
+      buffer->user_data = nullptr;
+      buffer->data = nullptr;
+      buffer->alloc_size = 0;
+    }
+    return buffer;  // For convienience
+  }
+
+  bool do_pool_cb(MMAL_BUFFER_HEADER_T * const buffer) override
+  {
+    return MmalUserPool::do_pool_cb(detach_data_buffer(buffer));
+  }
+
+public:
+  MmalFramePool(const scoped_refptr<MmalVcInit>& vc_init, FrameCopyMode copy_mode) :
+    MmalUserPool(vc_init),
+    copy_mode_(copy_mode)
+  {
+  }
+
+  const char * pool_type_name() const override
+  {
+    return "PoolFrame";
+  }
+
+  int create(const uint32_t num, const uint32_t buf_size, const gfx::Size& frame_size) override
+  {
+    if (MmalUserPool::create(num, 0, frame_size) != 0) {
+      return -1;
+    }
+
+    buffer_size_ = buf_size;
+    frame_size_ = frame_size;
+    return 0;
+  }
+
+  MMAL_BUFFER_HEADER_T * get_timeout(const uint32_t timeout_ms) override
+  {
+    return attach_data_buffer(MmalUserPool::get_timeout(timeout_ms));
+  }
+
+  MMAL_BUFFER_HEADER_T * get() override
+  {
+    return attach_data_buffer(MmalUserPool::get());
+  }
+
+  void put(MMAL_BUFFER_HEADER_T * const buffer) override
+  {
+    MmalUserPool::put(detach_data_buffer(buffer));
+  }
+
+  // This is effectively a realloc to the current size and will
+  // attach a buffer if none was attached before
+  // Useful when recycling a buffer directly back into a port
+  MMAL_BUFFER_HEADER_T * put_get(MMAL_BUFFER_HEADER_T * const buffer) override
+  {
+    if (buffer->alloc_size == buffer_size_)
+      return buffer;
+
+//    LOG(INFO) << "### Realloc buffer size: " << buffer->alloc_size << "->" << buffer_size_;
+    return attach_data_buffer(detach_data_buffer(buffer));
+  }
+
+  int disable() override
+  {
+    // Avoid keeping an otherwise unused trampoline alive longer than needed
+    trampoline_.reset();
+    return MmalUserPool::disable();
+  }
+
+  int port_resized(const uint32_t num, const uint32_t buf_size, const gfx::Size& frame_size) override
+  {
+    // Remember for future allocation and that is all we want to do
+    buffer_size_ = buf_size;
+    frame_size_ = frame_size;
+    return 0;
+  }
+
+  // As this has no locking this should only be called when disabled
+  // (in most cases this means that the port we are servicing is disabled)
+  void set_trampoline(const scoped_refptr<MmalTrampoline>& trampoline) override
+  {
+    trampoline_ = trampoline;
+  }
+};
+
+class MmalFramePoolZc : public MmalFramePool
+{
+protected:
+  MMAL_BUFFER_HEADER_T * attach_data_buffer(MMAL_BUFFER_HEADER_T * const buffer) override
+  {
+    // Ignore null
+    if (buffer != nullptr) {
+      if (buffer->data != nullptr) {
+        LOG(FATAL) << "Buffer already in use";
+      }
+
+      FrameDesc * frame;
+      if ((frame = trampoline_->alloc_frame()) == nullptr)
+      {
+        LOG(ERROR) << "### " << __func__ << ": alloc frame failed";
+        // If we cannot alloc then release buffer back to pool as we are about
+        // to lose track of it
+        buffer_release(buffer);
+        return nullptr;
+      }
+      buffer->user_data = frame;
+      buffer->data = (uint8_t *)(void *)frame->vc_handle();
+      buffer->alloc_size = frame->size();
+
+      if (buffer->data == nullptr) {
+        LOG(ERROR) << "Frame has no VCSM handle";
+        buffer_release(buffer);
+        return nullptr;
+      }
+    }
+    return buffer;
+  }
+
+public:
+  using MmalFramePool::MmalFramePool;
+
+  const char * pool_type_name() const override
+  {
+    return "PoolFrameZc";
+  }
+};
+
+//=============================================================================
+//
+// Wrapper for an mmal port
+
+class MmalPort
+{
+  // Actually connection should be a subclass?
+  friend class MmalConnection;
+
+protected:
+  const scoped_refptr<MmalVcInit> vc_init_;
+
+  MMAL_PORT_T * port_;
+  bool killing_;
+
+public:
+  virtual void event_cb(MMAL_BUFFER_HEADER_T * const buffer)
+  {
+    LOG(ERROR) << "### Unexpected ES data";
+    mmal_buffer_header_release(buffer);
+  }
+
+  virtual void cmd_cb(MMAL_BUFFER_HEADER_T * const buffer)
+  {
+    if (buffer->cmd == MMAL_EVENT_ERROR) {
+      LOG(WARNING) << "### Mmal reports error " << *(uint32_t *)buffer->data;
+    } else if (buffer->cmd == MMAL_EVENT_FORMAT_CHANGED) {
+      mmal_log_dump_port(port_);
+      const MMAL_EVENT_FORMAT_CHANGED_T *const fc = mmal_event_format_changed_get(buffer);
+      LOG(INFO) << "Mmal format changed: size_min:" << fc->buffer_size_min <<
+        ", num_min:" << fc->buffer_num_min <<
+          ", size_rec:" << fc->buffer_size_recommended <<
+          ", num_rec:" << fc->buffer_num_recommended;
+      if (fc->format != nullptr) {
+        mmal_log_dump_format(fc->format);
+      }
+    } else {
+        char s[20];
+        LOG(WARNING) << "### Mmal unexpected command: " << mmal_4cc_to_string(s, sizeof(s), buffer->cmd);
+    }
+
+    // Commands are allocated from a different pool to ES data
+    // return to sender...
+    mmal_buffer_header_release(buffer);
+  }
+
+private:
+  void callback_common(MMAL_BUFFER_HEADER_T * const buffer)
+  {
+    if (buffer->cmd != 0) {
+      // Cmd buffers are not allocated from the main pool
+      cmd_cb(buffer);
+    }
+    else
+    {
+      if (killing_) {
+        // If flushing always release the buffer
+        mmal_buffer_header_release(buffer);
+      }
+      else {
+        event_cb(buffer);
+      }
+    }
+  }
+
+  static void callback(MMAL_PORT_T *port, MMAL_BUFFER_HEADER_T *buffer)
+  {
+    MmalPort *p = static_cast<MmalPort*>((void*)port->userdata);
+
+    if (p == nullptr) {
+      LOG(ERROR) << __func__ << "### Port NULL";
+    }
+    else
+    {
+      p->callback_common(buffer);
+    }
+  }
+
+public:
+  virtual int enable()
+  {
+    MMAL_STATUS_T err = MMAL_SUCCESS;
+
+    if (killing_) {
+      LOG(ERROR) << "### port enable when killed";
+      return -1;
+    }
+
+    if ((err = mmal_port_enable(port_, callback)) != MMAL_SUCCESS)
+      LOG(ERROR) << "### mmal_port_enable failed: err=" << err;
+
+    return err == MMAL_SUCCESS ? 0 : -1;
+  }
+
+  virtual int disable()
+  {
+    MMAL_STATUS_T err = MMAL_SUCCESS;
+
+    if (port_ && port_->is_enabled) {
+      err = mmal_port_disable(port_);
+    }
+
+    return err == MMAL_SUCCESS ? 0 : -1;
+  }
+
+  bool is_enabled() const
+  {
+    return port_ != nullptr && port_->is_enabled;
+  }
+
+  virtual int commit()
+  {
+    MMAL_STATUS_T err = MMAL_SUCCESS;
+
+    if ((err = mmal_port_format_commit(port_)) != MMAL_SUCCESS)
+    {
+      LOG(ERROR) << "### mmal_port_format_commit failed: err=" << err;
+      mmal_log_dump_port(port_);
+    }
+
+    return err == MMAL_SUCCESS ? 0 : -1;
+  }
+
+  // (stride_in_pixels , (padded_)height)
+  gfx::Size frame_size() const
+  {
+    // * Could have a Video sub-class and lose this test
+    return port_->format->type != MMAL_ES_TYPE_VIDEO ? gfx::Size() :
+        gfx::Size(port_->format->es->video.width, port_->format->es->video.height);
+  }
+
+  uint32_t buffer_size() const
+  {
+    return port_->buffer_size;
+  }
+
+  uint32_t buffer_num() const
+  {
+    return port_->buffer_num;
+  }
+
+  // This set of fns are overridden by MmalConnectedPort
+  // to provide max of connected ports
+  virtual uint32_t buffer_size_recommended() const
+  {
+    return port_->buffer_size_recommended;
+  }
+
+  virtual uint32_t buffer_size_min() const
+  {
+    return port_->buffer_size_recommended;
+  }
+
+  virtual uint32_t buffer_num_recommended() const
+  {
+    return port_->buffer_num_recommended;
+  }
+
+  virtual uint32_t buffer_num_min() const
+  {
+    return port_->buffer_num_min;
+  }
+
+  virtual int set_buffers(const uint32_t size, const uint32_t num)
+  {
+    port_->buffer_num = num;
+    port_->buffer_size = size;
+    return 0;
+  }
+
+  int set_buffers_recommended()
+  {
+    return set_buffers(buffer_size_recommended(), buffer_num_recommended());
+  }
+
+  int set_parameter(const uint32_t param, const uint32_t val) const
+  {
+    MMAL_STATUS_T err = MMAL_SUCCESS;
+    if ((err = mmal_port_parameter_set_uint32(port_, param, val)) != MMAL_SUCCESS)
+      LOG(ERROR) << "### mmal_port_parameter_set_uint32 failed: err=" << err;
+
+    return err == MMAL_SUCCESS ? 0 : -1;
+  }
+
+  inline int set_parameter(const uint32_t param, const int val) const
+  {
+    return set_parameter(param, (uint32_t)(val));
+  }
+
+  int set_parameter(const uint32_t param, const bool val) const
+  {
+    MMAL_STATUS_T err = MMAL_SUCCESS;
+    if ((err = mmal_port_parameter_set_boolean(port_, param, val ? MMAL_TRUE : MMAL_FALSE)) != MMAL_SUCCESS)
+      LOG(ERROR) << "### mmal_port_parameter_set_boolean failed: err=" << err;
+
+    return err == MMAL_SUCCESS ? 0 : -1;
+  }
+
+  int get_parameter(MMAL_PARAMETER_HEADER_T * const param) const
+  {
+    MMAL_STATUS_T err = MMAL_SUCCESS;
+    if ((err = mmal_port_parameter_get(port_, param)) != MMAL_SUCCESS)
+      LOG(ERROR) << "### mmal_port_parameter_get failed: err=" << err;
+
+    return err == MMAL_SUCCESS ? 0 : -1;
+  }
+
+  // class for storing the supported encodings parameter info
+  class SupportedEncodings
+  {
+    static const int max_encodings_ = 64;
+    struct {
+       MMAL_PARAMETER_HEADER_T header_;
+       MMAL_FOURCC_T encodings_[max_encodings_];
+    } supported_;
+    int n_;
+
+  public:
+    typedef const MMAL_FOURCC_T * iterator;
+
+    SupportedEncodings(const MmalPort& port) :
+      supported_({{MMAL_PARAMETER_SUPPORTED_ENCODINGS, sizeof(supported_)}, {0}}),
+      n_(-1)
+    {
+      if (port.get_parameter(&supported_.header_) == 0)
+      {
+        n_ = (supported_.header_.size - sizeof(supported_.header_)) /
+          sizeof(supported_.encodings_[0]);
+      }
+    }
+
+    virtual ~SupportedEncodings()
+    {
+    }
+
+    // Default copy is OK
+
+    iterator begin() const
+    {
+      return supported_.encodings_;
+    }
+
+    iterator end() const
+    {
+      return supported_.encodings_ + n_;
+    }
+
+    bool is_supported(const MMAL_FOURCC_T x) const
+    {
+      // If we end up doing this a lot for any reason then use a better lookup
+      for (auto &enc : *this) {
+        if (x == enc) {
+          return true;
+        }
+      }
+      return false;
+    }
+
+    std::string ToString() const
+    {
+      std::ostringstream s;
+      for (int i = 0; i < n_; ++i) {
+        char buf[8];
+        if (i != 0)
+          s << ",";
+        s << mmal_4cc_to_string(buf, sizeof(buf), supported_.encodings_[i]);
+      }
+      return s.str();
+    }
+  };
+
+  SupportedEncodings get_parameter_supported_encodings() const
+  {
+    return SupportedEncodings(*this);
+  }
+
+  int set_video_encoding(
+    const MMAL_FOURCC_T encoding,
+    const MMAL_FOURCC_T encoding_variant = MMAL_ENCODING_VARIANT_DEFAULT,
+    const uint32_t flags = 0)
+  {
+    MMAL_ES_FORMAT_T *const format = port_->format;
+
+    format->type = MMAL_ES_TYPE_VIDEO;
+    format->encoding = encoding;
+    format->encoding_variant = encoding_variant;
+    format->flags = 0;
+    format->bitrate = 0;
+    return 0;
+  }
+
+  // Fill in all of a MMAL_VIDEO_FORMAT_T
+  int set_video_format(
+      const gfx::Size& size,
+      const gfx::Rect& crop,
+      const gfx::Size& par,
+      const MMAL_FOURCC_T mmal_color_space) const
+  {
+    MMAL_ES_FORMAT_T *const format = port_->format;
+    MMAL_VIDEO_FORMAT_T *const video = &format->es->video;
+    const bool isyuv = (format->encoding == MMAL_ENCODING_I420 ||
+                        format->encoding == MMAL_ENCODING_YV12 ||
+                        format->encoding == MMAL_ENCODING_NV12);
+
+    const uint32_t w = size.width();
+    const uint32_t h = size.height();
+
+    video->width = VCOS_ALIGN_UP(w, isyuv ? 32 : 16);
+    video->height = VCOS_ALIGN_UP(h, 16);
+    video->crop.x = crop.x();
+    video->crop.y = crop.y();
+    video->crop.width = crop.width();
+    video->crop.height = crop.height();
+    video->frame_rate.num = 30000;  // Not in config - make something valid up
+    video->frame_rate.den = 1001;
+    video->par.num = par.width();
+    video->par.den = par.height();
+    video->color_space = mmal_color_space;
+    return 0;
+  }
+
+  // Disable once we forget about it
+  virtual ~MmalPort()
+  {
+    disable();
+  }
+
+  MmalPort(const scoped_refptr<MmalVcInit>& vc_init) :
+    vc_init_(vc_init),
+    port_(nullptr),
+    killing_(false)
+  {
+  }
+
+  virtual void set_port(MMAL_PORT_T * const port)
+  {
+    if (port_) {
+      LOG(ERROR) << "### Port not null";
+      return;
+    }
+
+    port->userdata = (struct MMAL_PORT_USERDATA_T *)(void *)this;
+    port_ = port;
+  }
+
+  // Submit a buffer - on failure (or kill) buffer is released
+  int submit(MMAL_BUFFER_HEADER_T * const buffer)
+  {
+    MMAL_STATUS_T err;
+
+    if (killing_ || !port_->is_enabled) {
+      mmal_buffer_header_release(buffer);
+      return 0;
+    }
+
+    if ((err = mmal_port_send_buffer(port_, buffer)) != MMAL_SUCCESS)
+    {
+      // Release buffer on error
+      mmal_buffer_header_release(buffer);
+      LOG(ERROR) << "#### mmal_send_buffer (" << buffer << ") failed: err=" << err;
+    }
+
+    return err == MMAL_SUCCESS ? 0 : -1;
+  }
+
+  virtual void kill()
+  {
+    killing_ = true;
+    disable();
+  }
+
+  void dump_video_format()
+  {
+    const MMAL_ES_FORMAT_T * const format = port_->format;
+    const MMAL_VIDEO_FORMAT_T *const video = &format->es->video;
+    char buf1[10], buf2[10];
+
+    LOG(ERROR) << port_->name << ": Encoding:" << mmal_4cc_to_string(buf1, sizeof(buf1), format->encoding) <<
+    ":" << mmal_4cc_to_string(buf2, sizeof(buf2), format->encoding_variant) <<
+        ", " << video->width << "x" << video->height <<
+        ", crop: " << video->crop.x << "," << video->crop.y <<
+        " " << video->crop.width << "x" << video->crop.height;
+  }
+
+};
+
+// ---------------------------------------------------------------------------
+
+class MmalConnection : public base::RefCountedThreadSafe<MmalConnection>
+{
+  friend MmalConnectedPort;
+
+  const scoped_refptr<MmalVcInit> vc_init_;
+
+  bool enabled_;
+  MMAL_CONNECTION_T * connection_;
+  MmalConnectedPort * src_;
+  MmalConnectedPort * dest_;
+
+  friend base::RefCountedThreadSafe<MmalConnection>;
+  virtual ~MmalConnection()
+  {
+    if (connection_) {
+      mmal_connection_destroy(connection_);
+    }
+  }
+
+  MmalConnection(const scoped_refptr<MmalVcInit>& vc_init) :
+    vc_init_(vc_init),
+    enabled_(false),
+    connection_(nullptr),
+    src_(nullptr),
+    dest_(nullptr)
+  {
+  }
+
+  void disconnect();
+  int connect(MmalConnectedPort * const src, MmalConnectedPort * const dest);
+
+  int enable()
+  {
+    MMAL_STATUS_T err;
+
+    if (enabled_) {
+      // Bad stuff (tm) seems to happen if we multiply en/disable connections
+      return 0;
+    }
+
+    if ((err = mmal_connection_enable(connection_)) != MMAL_SUCCESS) {
+      LOG(ERROR) << "### mmal_connection_enable failed: err=" << err;
+      return -1;
+    }
+
+    enabled_ = true;
+    return 0;
+  }
+
+  int disable()
+  {
+    MMAL_STATUS_T err;
+
+    if (!enabled_) {
+      // Bad stuff (tm) seems to happen if we multiply en/disable connections
+      return 0;
+    }
+
+    // Mark as disabled even if we fail as in this case I have no idea how
+    // to recover and retry is very unlikely to help
+    enabled_ = false;
+
+    if ((err = mmal_connection_disable(connection_)) != MMAL_SUCCESS) {
+      LOG(ERROR) << "### mmal_connection_disable failed: err=" << err;
+      return -1;
+    }
+
+    return 0;
+  }
+
+  uint32_t buffer_size_recommended() const;
+  uint32_t buffer_num_recommended() const;
+  uint32_t buffer_size_min() const;
+  uint32_t buffer_num_min() const;
+  int set_buffers(uint32_t s, uint32_t n);
+};
+
+// ----------------------------------------------------------------------------
+//
+// Port that we are expecting to be attached to another port by an MmalConnection
+
+class MmalConnectedPort : public MmalPort
+{
+  scoped_refptr<MmalConnection> connection_;
+
+public:
+  void set_connection(MmalConnection * connection)
+  {
+    connection_ = connection;
+  }
+
+  int disconnect()
+  {
+    if (connection_) {
+      connection_->disconnect();
+    }
+    return 0;
+  }
+
+  int enable() override
+  {
+    return connection_->enable();
+  }
+
+  int disable() override
+  {
+    return !connection_ ? 0 : connection_->disable();
+  }
+
+  void kill() override
+  {
+    MmalPort::kill();
+    disconnect();
+  }
+
+  int connect_to_src(MmalConnectedPort * const src)
+  {
+    scoped_refptr<MmalConnection> connection(new MmalConnection(vc_init_));
+    return connection->connect(src, this);
+  }
+
+  uint32_t buffer_size_recommended() const override
+  {
+    return connection_->buffer_size_recommended();
+  }
+
+  uint32_t buffer_num_recommended() const override
+  {
+    return connection_->buffer_num_recommended();
+  }
+
+  uint32_t buffer_size_min() const override
+  {
+    return connection_->buffer_size_min();
+  }
+
+  uint32_t buffer_num_min() const override
+  {
+    return connection_->buffer_num_min();
+  }
+
+  int set_buffers(const uint32_t s, const uint32_t n) override
+  {
+    return connection_->set_buffers(s, n);
+  }
+
+  MmalConnectedPort(const scoped_refptr<MmalVcInit>& vc_init) :
+    MmalPort(vc_init)
+  {
+  }
+
+  ~MmalConnectedPort() override
+  {
+    disconnect();
+  }
+};
+
+// ----------------------------------------------------------------------------
+
+class MmalPortAndPool : public MmalPort
+{
+  typedef scoped_refptr<MmalPortAndPool> AutoRef;
+
+  MmalComponent * const component_;
+
+  std::unique_ptr<MmalPool> pool_;
+
+public:
+  // These allow us to use scoped_refptr on this object
+  // They trampoline to the enclosing component
+  void AddRef();
+  void Release();
+  bool HasOneRef() const;
+  bool HasAtLeastOneRef() const;
+
+  const MmalTaskRunner& task_runner() const;
+
+protected:
+  virtual void buffer_event_cb(MMAL_BUFFER_HEADER_T * const buffer) = 0;
+
+private:
+  static bool pool_cb(scoped_refptr<MmalPortAndPool> mpp, MMAL_BUFFER_HEADER_T *buffer)
+  {
+    // As the release can cause us to commit suicide we must put the buffer
+    // back by hand before calling Release as if we try to do it afterwards
+    // the Q may have vanished and we would crash.
+    mpp->pool_->put(buffer);
+    mpp->Release();
+    return false;  // We did the put back ourselves
+  }
+
+  // Given that we now have ref counts that can hit zero when all buffers are
+  // returned to the pool ensure that we can't commit untimely suicide by
+  // holding a ref on ourselves until the callback is over.
+  // This could probably be ensured by careful coding of the overriding
+  // callbacks but this removes the possibility of unexpected surprises
+  void event_cb(MMAL_BUFFER_HEADER_T * const buffer) final
+  {
+    AutoRef(this)->buffer_event_cb(buffer);
+  }
+
+protected:
+  int set_pool(MmalPool *const pool, const uint32_t num)
+  {
+    pool_ = std::unique_ptr<MmalPool>(pool);
+    if (pool_->create(num, port_->buffer_size, frame_size()) != 0) {
+      return -1;
+    }
+    return 0;
+  }
+
+  int set_pool(MmalPool *const pool)
+  {
+    if (pool == nullptr) {
+      pool_.reset();
+      return 0;
+    }
+    return set_pool(pool, port_->buffer_num);
+  }
+
+public:
+  void task_run(base::OnceClosure cb)
+  {
+    task_runner()->PostTask(FROM_HERE, std::move(cb));
+  }
+
+  MmalPortAndPool(const scoped_refptr<MmalVcInit>& vc_init, MmalComponent * const component) :
+    MmalPort(vc_init),
+    component_(component)
+  {
+//    LOG(ERROR) << __func__;
+  }
+
+  ~MmalPortAndPool() override
+  {
+    disable();
+  }
+
+  int create_port_pool()
+  {
+    return set_pool(new MmalPortPool(vc_init_, port_));
+  }
+
+  int create_user_pool(const uint32_t buffer_num)
+  {
+    return set_pool(new MmalUserPool(vc_init_), buffer_num);
+  }
+
+  MMAL_BUFFER_HEADER_T * pool_get(const bool wait = false)
+  {
+    if (!pool_) {
+      LOG(ERROR) << "### Pool not set up\n";
+      return nullptr;
+    }
+
+    MMAL_BUFFER_HEADER_T * const header =  wait ?
+      pool_->get_timeout(5000) : pool_->get();
+
+    if (header) {
+      AddRef();
+    }
+
+    return header;
+  }
+
+  int pool_size() const
+  {
+    return pool_->size();
+  }
+
+  int queue_length() const
+  {
+    return pool_->length();
+  }
+
+  // Stuff all the pool entries into the port
+  int stuff()
+  {
+    MMAL_BUFFER_HEADER_T * buffer;
+    while ((buffer = pool_get())) {
+      // When flushing/disabling we may have left stuff with lengths in the pool
+      mmal_buffer_header_reset(buffer);
+      if (submit(buffer) != 0)
+        return -1;
+    }
+    return 0;
+  }
+
+  int stuff(int stuff_count, const bool wait = false)
+  {
+    while (--stuff_count >= 0)
+    {
+      MMAL_BUFFER_HEADER_T * buffer;
+      if (!(buffer = pool_get(wait)))
+      {
+        LOG(ERROR) << "### Unexpected pool_get_failure";
+        return -1;
+      }
+
+      // When flushing/disabling we may have left stuff with lengths in the pool
+      mmal_buffer_header_reset(buffer);
+      if (submit(buffer) != 0)
+        return -1;
+    }
+    return 0;
+  }
+
+  void recycle(MMAL_BUFFER_HEADER_T * const buffer)
+  {
+    mmal_buffer_header_reset(buffer);
+    submit(pool_->put_get(buffer));
+  }
+
+  int enable() override
+  {
+    if (pool_ == nullptr)
+    {
+      LOG(ERROR) << "MmalPoolAndPort::enable: pool NULL";
+      return -1;
+    }
+
+    if (pool_->port_resized(buffer_num(), buffer_size(), frame_size()) != 0 ||
+        pool_->enable(base::BindRepeating(MmalPortAndPool::pool_cb, scoped_refptr<MmalPortAndPool>(this))) != 0)
+      return -1;
+
+    return MmalPort::enable();
+  }
+
+  int disable_port()
+  {
+    return MmalPort::disable();
+  }
+  int disable_pool()
+  {
+    return (pool_ != nullptr && pool_->disable() != 0) ? -1 : 0;
+  }
+
+  int disable() override
+  {
+    const int rv = disable_port();
+    return (disable_pool() != 0) ? -1 : rv;
+  }
+
+  int commit() override
+  {
+    const int rv = MmalPort::commit();
+    // ** Notify pool that size may have changed
+    return rv;
+  }
+
+  void set_trampoline(scoped_refptr<MmalTrampoline>& trampoline)
+  {
+    pool_->set_trampoline(trampoline);
+  }
+};
+
+// ----------------------------------------------------------------------------
+
+class MmalVideoESPort : public MmalPortAndPool
+{
+  struct ESBufferUserData {
+    VideoDecoder::DecodeCB decode_cb_;
+
+    ESBufferUserData(VideoDecoder::DecodeCB decode_cb) :
+      decode_cb_(std::move(decode_cb))
+    {
+    }
+
+    ~ESBufferUserData() = default;
+  };
+
+  std::queue<std::unique_ptr<ESBufferHolder>> es_q_;
+
+  bool low_delay_;
+
+public:
+  MmalVideoESPort(const scoped_refptr<MmalVcInit>& vc_init, MmalComponent * const component) :
+    MmalPortAndPool(vc_init, component),
+    low_delay_(false)
+  {
+  }
+  ~MmalVideoESPort() override
+  {
+  }
+
+  void set_port(MMAL_PORT_T * const port) override
+  {
+    MmalPort::set_port(port);
+  }
+
+  // Only checks the codec type if we had to set the encoding bitmask
+  bool set_supported_video_codecs() const
+  {
+    if (supported_video_codecs != 0)
+      return false;
+
+    const MmalPort::SupportedEncodings encodings(get_parameter_supported_encodings());
+
+    // We always claim to support H264
+    unsigned int bits = 1 << VideoCodec::kCodecH264;
+
+    for (auto& enc : encodings) {
+      bits |= 1 << fourcc_to_video_codec(enc);
+    }
+
+    // Mask out unknown
+    supported_video_codecs = bits & ~(1 << VideoCodec::kUnknownVideoCodec);
+
+    LOG(INFO) << "Supported video encodings: " << encodings.ToString() << ", bits=" << std::hex << bits;
+    return true;
+  }
+
+  int config(const VideoDecoderConfig& config, const bool low_delay)
+  {
+    const VideoCodec codec = config.codec();
+
+    if (set_supported_video_codecs())
+    {
+      // We set the supported mask - check if we expect this to work...
+      // If we didn't set it then assume we have already checked
+      if ((supported_video_codecs & (1 << codec)) == 0) {
+        // return silently
+        return -1;
+      }
+    }
+
+    low_delay_ = low_delay;
+
+    const MMAL_FOURCC_T encoding = video_codec_to_fourcc(codec);
+
+    if (encoding == MMAL_ENCODING_UNKNOWN) {
+      LOG(ERROR) << "### Unexpected video codec:" << config.codec();
+      return -1;
+    }
+
+    set_video_encoding(encoding, MMAL_ENCODING_VARIANT_DEFAULT, MMAL_ES_FORMAT_FLAG_FRAMED);
+
+    set_video_format(config.coded_size(),
+        config.visible_rect(),
+        par_from_sizes(config.visible_rect().size(), config.natural_size()),
+        color_space_to_mmal(config.color_space_info()));
+
+    return 0;
+  }
+
+private:
+  int submit_data(const std::unique_ptr<ESBufferHolder>& esb)
+  {
+    uint32_t bsent = 0;
+    ESBufferUserData * user_data = nullptr;
+
+    MMAL_BUFFER_HEADER_T * const buffer = pool_get(esb->is_not_pkt());
+    if (!buffer) {
+      return 0;
+    }
+
+//    LOG(ERROR) << "-- submit len=" << len << ", pts=" << pts;
+
+    // resets length, offset, flags, pts, dts
+    mmal_buffer_header_reset(buffer);
+    buffer->user_data = nullptr;
+    buffer->cmd = 0;
+
+    if (esb->is_eos())
+    {
+      buffer->flags |= MMAL_BUFFER_HEADER_FLAG_EOS;
+      // As this is zero length avoid poking the data
+      bsent = 1; // 0 means did nothing so pick another number
+
+      esb->Consume();
+    }
+    else
+    {
+      if (esb->is_start())
+      {
+        buffer->pts = (esb->pts() == kNoTimestamp) ? MMAL_TIME_UNKNOWN : esb->pts().InMicroseconds();
+//            buffer->dts = avpkt->dts == AV_NOPTS_VALUE ? MMAL_TIME_UNKNOWN : avpkt->dts;
+        buffer->flags |= MMAL_BUFFER_HEADER_FLAG_FRAME_START | MMAL_BUFFER_HEADER_FLAG_USER0;
+      }
+
+      bsent = buffer->length = esb->length(buffer->alloc_size);
+
+      if (mmal_buffer_header_mem_lock(buffer) != MMAL_SUCCESS)
+      {
+          LOG(ERROR) << "#### Cannot lock buffer";
+          buffer_release(buffer);
+          return -1;
+      }
+
+      if (esb->is_not_pkt())
+          buffer->flags |= MMAL_BUFFER_HEADER_FLAG_CONFIG;
+
+      memcpy(buffer->data, esb->data(), buffer->length);
+      esb->Consume(bsent);
+
+      mmal_buffer_header_mem_unlock(buffer);
+
+      if (esb->is_done())
+      {
+          buffer->flags |= MMAL_BUFFER_HEADER_FLAG_FRAME_END;
+
+          VideoDecoder::DecodeCB cb(esb->take_callback());
+          if (cb) {
+            user_data = new ESBufferUserData(std::move(cb));
+            buffer->user_data = (void *)user_data;
+          }
+      }
+    }
+
+//    LOG(ERROR) << "Submit: flags=" << std::hex << buffer->flags << std::dec << ", len=" << buffer->length << ", pts=" << buffer->pts;
+
+    if (MmalPortAndPool::submit(buffer) != 0)
+    {
+      // Given ordinary port pool we have to free this ourselves on failure
+      if (user_data) {
+        delete user_data;
+      }
+      return -1;
+    }
+
+    return (int)bsent;
+  }
+
+  void submit_poll()
+  {
+    for (; !es_q_.empty(); es_q_.pop())
+    {
+      while (!es_q_.front()->is_done()) {
+        const int bsent = submit_data(es_q_.front());
+
+//        LOG(ERROR) << "es submit bsent=" << bsent << ", pql=" << queue_length();
+
+        if (bsent == 0) {
+          // Q full - give up now
+          return;
+        } else if (bsent < 0) {
+          es_q_.front()->take_callback().Run(DecodeStatus::DECODE_ERROR);
+        }
+      }
+    }
+  }
+
+  void buffer_event_cb(MMAL_BUFFER_HEADER_T * const buffer) override
+  {
+    if (buffer->user_data) {
+      std::unique_ptr<ESBufferUserData> user_data((ESBufferUserData *)buffer->user_data);
+      buffer->user_data = nullptr;
+      std::move(user_data->decode_cb_).Run(DecodeStatus::OK);  // decode_cb_ already bound to correct thread
+    }
+
+    buffer_release(buffer);
+
+    task_run(base::BindOnce(&MmalVideoESPort::submit_poll, this));
+  }
+
+
+public:
+  int submit_decoder_buffer(std::unique_ptr<ESBufferHolder> bh)
+  {
+    // * If we aren't in the same thread as task_runner_ at this point
+    //   then this lot is unsafe...
+
+    es_q_.push(std::move(bh));
+
+    submit_poll();
+    return 0;
+  }
+
+  int disable() override
+  {
+    // Get and kill any pending submit_callback
+    for (; !es_q_.empty(); es_q_.pop()) {
+      es_q_.front()->take_callback().Run(DecodeStatus::ABORTED);
+    }
+    return MmalPortAndPool::disable();
+  }
+};
+
+
+// ----------------------------------------------------------------------------
+//
+// * It might be nice to split this into ZC & Copy versions but as it stands
+//   the port is declared directly in the component which makes that tricky
+
+class MmalVideoARGBPort : public MmalPortAndPool
+{
+  GpuVideoAcceleratorFactories* const gpu_factories_;
+  scoped_refptr<base::SingleThreadTaskRunner> gpu_thread_;
+
+  FrameCopyMode copy_mode_;
+  gfx::Size req_size_;
+  unsigned int stride_ = 0;
+  VideoDecoder::OutputCB output_cb_;
+  VideoDecoder::DecodeCB eos_cb_;
+  base::Lock req_lock_;
+  bool red_pixel_;
+  scoped_refptr<MmalTrampoline> frame_trampoline_;
+  scoped_refptr<MmalShmVideoFrame> sliced_frame_;
+  int sliced_y_;
+  base::TimeDelta last_pts_;
+  bool debug_bench_;
+  bool resize_disabled_;
+  scoped_refptr<DeferredList> deferred_list_;
+  gfx::ColorSpace color_space_;
+
+  std::unique_ptr<FpS> fps_;
+
+  void inline RunInGPUThreadOnce(base::OnceClosure closure)
+  {
+    gpu_thread_->PostTask(FROM_HERE, std::move(closure));
+  }
+
+  bool inline eos_pending() const
+  {
+    return !eos_cb_.is_null();
+  }
+
+  void kill_trampoline()
+  {
+    if (frame_trampoline_)
+    {
+      frame_trampoline_->kill();
+      frame_trampoline_.reset();
+    }
+  }
+
+  // Mostly required to discard the return value
+  void posted_submit(MMAL_BUFFER_HEADER_T * const buffer)
+  {
+//    LOG(ERROR) << "--- " << __func__;
+    submit(buffer);
+  }
+
+  // Unlocks buffer & recycles it
+  // Called from trampoline on free_frame
+  // so may come from a random thread
+  void copied_frame_destruction_cb(const int buffer_count)
+  {
+    // stuff may have to wait for a buffer as the recycling
+    // cannot be protected by the trampoline lock with the current
+    // code so we have a race
+    if (stuff(buffer_count, true) == -1)
+      LOG(FATAL) << "No buffers to back up recycle request";
+  }
+
+  void resize_posted()
+  {
+    gfx::Size req_size;
+
+    {
+      base::AutoLock lock(req_lock_);
+
+      // Take consistent copy inside lock (no blocking ops inside this lock)
+      req_size = req_size_;
+
+      // ?? and likely the same size
+
+      if (req_size == size())
+        return;
+
+      // Must avoid disable/enable if
+      //   (a) Already disabled
+      //   (b) EOS pending (will confuse the process)
+
+      if (eos_pending()) {
+        LOG(INFO) << __func__ << ": abort due to EOS";
+        // If EOS pending then do nothing - we shouldn't get more stream
+        // until at least a reset
+        // Reset req_size to whatever we are so we will get recalled if needed
+        // * Locking ??
+        req_size_ = size();
+        return;
+      }
+    }
+
+    LOG(INFO) << "Resize to " << req_size.ToString();
+
+    const bool was_enabled = is_enabled();
+
+    if (was_enabled) {
+      disable();
+    }
+
+    set_size(req_size);
+    commit();
+
+    // *** Pool resize for new frame size
+    //     Mucky!
+    if (copy_mode_ != FrameCopyMode::SLICE) {
+      set_buffers(buffer_size_recommended(), buffer_num());
+      if (copy_mode_.port_has_pool()) {
+        // In this case the allocation is done by mmal so we need to recreate the
+        set_pool(nullptr);  // Kill before realloc so we never have 2 sets alloce
+        create_port_pool();
+      }
+    }
+
+    if (was_enabled)
+      enable();
+  }
+
+public:
+  void reset_reqs()
+  {
+    base::AutoLock lock(req_lock_);
+    req_size_ = gfx::Size(port_->format->es->video.crop.width, port_->format->es->video.crop.height);
+  }
+
+  void resize_cb(const gfx::Size& size)
+  {
+    {
+      base::AutoLock lock(req_lock_);
+
+      if (size == req_size_ || resize_disabled_) {
+        return;
+      }
+      req_size_ = size;
+    }
+
+    // Avoid running in the callback - run on our own thread
+    task_run(base::BindOnce(&MmalVideoARGBPort::resize_posted, this));
+  }
+
+  gfx::Size size() const
+  {
+    return gfx::Size(port_->format->es->video.crop.width, port_->format->es->video.crop.height);
+  }
+
+  gfx::Rect visible_rect() const
+  {
+    return gfx::Rect(
+        port_->format->es->video.crop.x, port_->format->es->video.crop.y,
+        port_->format->es->video.crop.width, port_->format->es->video.crop.height);
+  }
+
+  gfx::Size coded_size() const
+  {
+    return gfx::Size(port_->format->es->video.width, port_->format->es->video.height);
+  }
+
+  gfx::Size natural_size() const
+  {
+    const unsigned int par_n = port_->format->es->video.par.num;
+    const unsigned int par_d = port_->format->es->video.par.den;
+    const unsigned int width = port_->format->es->video.crop.width;
+    const unsigned int height = port_->format->es->video.crop.height;
+
+    if (par_n == 0 || par_d == 0)
+      return gfx::Size(width, height);
+
+    return gfx::Size((width * par_n + par_d / 2) / par_d, height);
+  }
+
+  size_t stride() const
+  {
+    return stride_;
+  }
+
+private:
+
+  // Recycles buffer too
+  void mov_frame_block(const scoped_refptr<MmalShmVideoFrame>& frame,
+      MMAL_BUFFER_HEADER_T * const buffer,
+      const size_t width,
+      const size_t start_y,
+      const int lines)
+  {
+    MMAL_STATUS_T err;
+
+    if ((err = mmal_buffer_header_mem_lock(buffer)) != MMAL_SUCCESS)
+    {
+      LOG(ERROR) << "### Unable to lock buffer; err=" << err;
+      return;
+    }
+
+    const uint8_t * s = buffer->data + buffer->type->video.offset[0];
+    const size_t s_stride = buffer->type->video.pitch[0];
+    const size_t d_stride = frame->stride(0);
+    uint8_t * d = frame->data(0) + start_y * d_stride;
+    const size_t line_size = width * 4;
+
+    for (int i = 0; i < lines; ++i, s += s_stride, d += d_stride)
+      memcpy(d, s, line_size);
+
+    // Unlock & recycles
+    mmal_buffer_header_mem_unlock(buffer);
+
+    // Count buffers used by this frame
+    frame->inc_buffer_count();
+
+    if (frame_trampoline_->recycle_buffer_in_flight(buffer)) {
+      recycle(buffer);
+    }
+  }
+
+  // Do final ops for all sync output
+  void emit_copied_frame(const scoped_refptr<VideoFrame>& frame, MMAL_BUFFER_HEADER_T * const buffer)
+  {
+    frame->set_color_space(color_space_);
+
+    if (buffer && frame_trampoline_->recycle_buffer_in_flight(buffer)) {
+      recycle(buffer);
+    }
+
+    if (frame->timestamp() != kNoTimestamp)
+      last_pts_ = frame->timestamp();
+
+    if (debug_bench_) {
+      // In bench mode just drop the frame on the floor
+      return;
+    }
+    if (red_pixel_) {
+      // Mark our frames with happy red pixels
+      uint8_t * d = frame->data(0);
+      const size_t d_stride = frame->stride(0);
+
+      for (int i = 0; i != 8; ++i, d += d_stride) {
+          for (int j = 0; j != 8 * 4; j += 4) {
+              d[j+0] = 0;
+              d[j+1] = 0;
+              d[j+2] = 0xff;
+              d[j+3] = 0xff;
+          }
+      }
+    }
+
+    // Kick the output cb onto another thread so we can return from here ASAP
+    // to free up the MMAL CB thread
+    task_run(base::BindOnce(output_cb_, frame));
+  }
+
+  void deferred_gpu_buffer(std::unique_ptr<DeferredBuffer> dbuf,
+                           const base::TimeDelta pts)
+  {
+    MMAL_BUFFER_HEADER_T * const buffer = dbuf->ExtractAndLock();
+
+    // Buffer will be null if our port has been disabled between
+    // task scheduling & now
+    if (!buffer)
+      return;
+
+    const bool is_copy = copy_mode_.port_copy() == PortCopy::Copy;
+    FrameDesc * const frame_desc = is_copy ?
+      frame_trampoline_->alloc_frame() :
+      FrameDesc::Extract(buffer);
+
+    // Copy on our side...
+    scoped_refptr<MmalGPUVideoFrame> frame(MmalGPUVideoFrame::Create(
+        frame_desc,
+        frame_trampoline_,
+        visible_rect(), natural_size(),
+        pts));
+
+    // Set colour unless YUV-VCSM as that is bust (colours go all wrong)
+    if (copy_mode_.get() != FrameCopyMode::FRAME_GPU_YUV_VCSM)
+      frame->set_color_space(color_space_);
+
+    if (is_copy)
+      frame->copy_buffer(buffer);
+
+    if (frame_trampoline_->recycle_buffer_in_flight(buffer)) {
+      recycle(buffer);
+    }
+
+    dbuf.reset();  // Done with buffer
+
+    frame->BindAndEmit(output_cb_);
+  }
+
+protected:
+  void buffer_event_cb(MMAL_BUFFER_HEADER_T * const buffer) override
+  {
+    // Halfway recent firmwares now set buffer->type->video.pitch[0]
+    // Older ones had zeros but that is old enough to ignore now
+    const gfx::Size cur_size = size();
+
+//    const base::TimeDelta pts(kNoTimestamp);
+
+    const base::TimeDelta pts(buffer->pts == MMAL_TIME_UNKNOWN ?
+        kNoTimestamp :
+        base::TimeDelta::FromMicroseconds(buffer->pts));
+
+#if TRACE_BUFFER_EVENT
+    if ((buffer->flags & MMAL_BUFFER_HEADER_FLAG_FRAME_END) != 0) {
+      LOG(INFO) << "-- Got frame from resizer: copy_mode=" << copy_mode_ << ", len=" << buffer->length <<
+          ", size = " << port_->format->es->video.width << "x" << port_->format->es->video.height << ", req=" << cur_size.ToString() <<
+          ", rec size=" << port_->buffer_size_recommended << ", cur_size=" << port_->buffer_size <<
+          ", stride=" << buffer->type->video.pitch[0] << "/" << stride() << ", pts=" << buffer->pts <<
+          ", flags=" << std::hex << buffer->flags << std::dec << ", enabled=" << port_->is_enabled <<
+          ", pts_delta=" << (pts - last_pts_).InMicroseconds() << ", user=" << (void *)buffer->user_data;
+        ;
+    }
+#endif
+
+    if ((buffer->flags & MMAL_BUFFER_HEADER_FLAG_EOS) != 0) {
+      LOG(INFO) << ">>> EOS";
+      if (fps_ != nullptr) {
+        LOG(ERROR) << "@@@@ EOS: fps=" << fps_->ToString();
+      }
+      // Finally call the decode CB
+      if (eos_pending()) {
+        std::move(eos_cb_).Run(DecodeStatus::OK);
+      }
+      // Remember to recycle the buffer!
+      recycle(buffer);
+      return;
+    }
+
+    if (buffer->length == 0 || !is_enabled()) {
+      // Flushing or empty buffer
+      recycle(buffer);
+      return;
+    }
+
+    switch (copy_mode_.get()) {
+      case FrameCopyMode::unset:
+        LOG(ERROR) << "### copy mode unset";
+        recycle(buffer);
+        break;
+
+      case FrameCopyMode::FRAME_NV12:
+      case FrameCopyMode::FRAME_I420:
+      case FrameCopyMode::FRAME_ARGB_DMA:
+      case FrameCopyMode::FRAME_ARGB_COPY:
+      {
+        const bool is_copy = copy_mode_.port_copy() == PortCopy::Copy;
+        FrameDesc * const frame_desc = is_copy ?
+          frame_trampoline_->alloc_frame() :
+          FrameDesc::Extract(buffer);
+
+        scoped_refptr<MmalShmVideoFrame> frame(MmalShmVideoFrame::Create(
+          frame_desc,
+          frame_trampoline_,
+          visible_rect(), natural_size(),
+          pts));
+
+        if (is_copy)
+          frame->copy_buffer(buffer);
+
+        frame->inc_buffer_count();
+
+        emit_copied_frame(frame, buffer);
+        break;
+      }
+
+      case FrameCopyMode::FRAME_GPU_ARGB_VCSM:   // DMA processing is good enough
+      case FrameCopyMode::FRAME_GPU_ARGB_DMA:
+      case FrameCopyMode::FRAME_GPU_YUV_VCSM:
+      case FrameCopyMode::FRAME_GPU_YUV_COPY:
+      {
+        // Needs to run on GPU thread so kick over
+        // Any op that changes frame sizes will disable the port
+        // which in turn will reclaim the bufer from the deferred list
+        // so sizes etc. will still be valid in the callback if we have a
+        // buffer (and if we don't then we give up early)
+
+        std::unique_ptr<DeferredBuffer> dbuf(deferred_list_->AddBuffer(buffer));
+
+        if (!dbuf)
+          recycle(buffer);
+        else
+          RunInGPUThreadOnce(base::BindOnce(&MmalVideoARGBPort::deferred_gpu_buffer, this, std::move(dbuf), pts));
+        break;
+      }
+
+      case FrameCopyMode::SLICE:
+      {
+        // Remember end of frame flag as we kill the buffer before using it
+        const bool eof = (buffer->flags & MMAL_BUFFER_HEADER_FLAG_FRAME_END) != 0;
+
+        if (!sliced_frame_) {
+          sliced_y_ = 0;
+          // pts only correct at eof
+          sliced_frame_ = MmalShmVideoFrame::Create(
+              frame_trampoline_->alloc_frame(),
+              frame_trampoline_,
+              visible_rect(), natural_size());
+        }
+
+        mov_frame_block(sliced_frame_, buffer, cur_size.width(), sliced_y_,
+            std::min(MMAL_SLICE_HEIGHT, sliced_frame_->rows(0) - sliced_y_));
+
+        if ((sliced_y_ += MMAL_SLICE_HEIGHT) < sliced_frame_->rows(0))
+        {
+          // Partial - stop now
+          if (eof) {
+            // Partial frame - discard
+            sliced_frame_.reset();
+            LOG(WARNING) << "### frame underrun";
+          }
+          return;
+        }
+        if (!eof) {
+          // Overrun
+          LOG(WARNING) << "### frame overrun";
+        }
+        sliced_frame_->set_timestamp(pts);
+
+        // Make sure sliced_frame_ is NULL before we do output callbacks
+        // that might cause us to look at it
+        emit_copied_frame(std::move(sliced_frame_), nullptr);
+        break;
+      }
+    }
+
+    if (fps_ != nullptr) {
+      fps_->inc_frames();
+      if (fps_->period_expired(1000000))
+      {
+        LOG(ERROR) << "--- fps = " << fps_->ToString();
+      }
+    }
+  }
+
+public:
+  MmalVideoARGBPort(const scoped_refptr<MmalVcInit>& vc_init, MmalComponent * const component, GpuVideoAcceleratorFactories* const gpu_factories) :
+    MmalPortAndPool(vc_init, component),
+    gpu_factories_(gpu_factories),
+    red_pixel_(false),
+    last_pts_(kNoTimestamp),
+    debug_bench_(false),
+    resize_disabled_(false),
+    deferred_list_(new DeferredList())
+  {
+    if (gpu_factories)
+      gpu_thread_ = gpu_factories->GetTaskRunner();
+  }
+
+  ~MmalVideoARGBPort() override
+  {
+    kill_trampoline();
+  }
+
+  int create_frame_pool(const bool zc)
+  {
+    return set_pool(zc ? new MmalFramePoolZc(vc_init_, copy_mode_) : new MmalFramePool(vc_init_, copy_mode_));
+  }
+
+  void set_port(MMAL_PORT_T * const port) override
+  {
+    MmalPort::set_port(port);
+
+    port_->format->type = MMAL_ES_TYPE_VIDEO;
+  }
+
+  void set_copy_mode(const FrameCopyMode copy_mode, const VideoColorSpace& video_color_space)
+  {
+    copy_mode_ = copy_mode;
+
+    //??? probably should refactor this lot for req/cur s.t. everything happens on commit
+    port_->format->encoding = copy_mode_.mmal_encoding();
+    port_->format->encoding_variant = MMAL_ENCODING_VARIANT_DEFAULT;
+
+    if (copy_mode_.is_yuv()) {
+      color_space_ = video_color_space.ToGfxColorSpace();
+      port_->format->es->video.color_space = color_space_to_mmal(video_color_space);
+    }
+    else {
+      color_space_ = gfx::ColorSpace::CreateSRGB();
+      port_->format->es->video.color_space = MMAL_COLOR_SPACE_UNKNOWN;
+    }
+  }
+
+  int set_size(const gfx::Size& req_size)
+  {
+    set_video_format(req_size, gfx::Rect(req_size), gfx::Size(), port_->format->es->video.color_space);
+    stride_ = mmal_encoding_width_to_stride(port_->format->encoding, port_->format->es->video.width);
+    return 0;
+  }
+
+  void set_eos_cb(VideoDecoder::DecodeCB eos_cb)
+  {
+    eos_cb_ = std::move(eos_cb);
+  }
+
+  int set_debug_bench(const bool enable_bench, const bool enable_fps)
+  {
+    debug_bench_ = enable_bench;
+    fps_ = std::unique_ptr<FpS>(!enable_fps ? nullptr : new FpS());
+    return 0;
+  }
+
+  int set_resize_disabled(const bool disable)
+  {
+    resize_disabled_ = disable;
+    return 0;
+  }
+
+  void set_red_pixel(const bool red)
+  {
+    red_pixel_ = red;
+  }
+
+public:
+  int enable() override
+  {
+    if (is_enabled()) {
+      LOG(INFO) << "Already enabled";
+    }
+    DCHECK(!is_enabled());
+
+    kill_trampoline();  // Shouldn't be needed but good to make sure
+
+    const int buffers_per_frame = !copy_mode_.is_slice() ? 1 :
+        (port_->format->es->video.crop.height + MMAL_SLICE_HEIGHT - 1) / MMAL_SLICE_HEIGHT;
+
+    frame_trampoline_ = new MmalTrampoline(vc_init_, gpu_factories_,
+        buffer_size() * buffers_per_frame, frame_size(),
+        copy_mode_, color_space_,
+        buffers_per_frame * MAX_COPY_FRAMES_IN_FLIGHT,
+        base::BindRepeating(&MmalVideoARGBPort::copied_frame_destruction_cb, this));
+
+    set_trampoline(frame_trampoline_);
+
+    if (MmalPortAndPool::enable() != 0)
+      return  -1;
+
+    if (fps_ != nullptr) {
+      fps_->start();
+    }
+
+    return stuff();
+  }
+
+  int enable(const VideoDecoder::OutputCB& output_cb)
+  {
+    output_cb_ = output_cb;
+    return enable();
+  }
+
+  int disable() override
+  {
+    int rv;
+
+    {
+      DeferredReclaim reclaim(deferred_list_);
+
+      // Nothing should be added to the deferred list after ReclaimStart
+      MMAL_BUFFER_HEADER_T * buffer;
+      while ((buffer = reclaim.Extract()) != nullptr) {
+        recycle(buffer);
+      }
+
+      rv = MmalPortAndPool::disable();
+
+      // ReclaimFinish
+    }
+
+    // Worry about class status vars after disable to avoid race conditions
+    kill_trampoline();
+
+    sliced_frame_.reset();  // Forget any partial frame info
+
+    if (eos_pending()) {
+      LOG(INFO) << ">>> EOS (abort)";
+      std::move(eos_cb_).Run(DecodeStatus::ABORTED);
+    }
+//    LOG(ERROR) << "@@@@ disable: fps=" << fps.ToString();
+
+    return rv;
+  }
+
+  bool is_stalling() const
+  {
+    // If trampoline is null for some reason e.g. decoder reset
+    // then assume that in_flight is 0 as it will be when we regenerate the
+    // trampoline
+    return frame_trampoline_ != nullptr && frame_trampoline_->is_stalling();
+  }
+};
+
+  // ---------------------------------------------------------------------------
+
+class MmalComponent : public base::RefCountedThreadSafe<MmalComponent>
+{
+  const scoped_refptr<MmalVcInit> vc_init_;
+
+protected:
+  MMAL_COMPONENT_T * component_;
+private:
+  MmalTaskRunner task_runner_;
+
+protected:
+  int create_by_name(const char * const name)
+  {
+    MMAL_STATUS_T err;
+    if ((err = mmal_component_create(name, &component_)) != MMAL_SUCCESS)
+      LOG(ERROR) << "### mmal_component_create(" << name << ") failed: err=" << err;
+
+    return err == MMAL_SUCCESS ? 0 : -1;
+  }
+
+  friend class base::RefCountedThreadSafe<MmalComponent>;
+  virtual ~MmalComponent()
+  {
+    if (component_) {
+      mmal_component_release(component_);
+    }
+  }
+
+  virtual MmalConnectedPort * input_port() = 0;
+  virtual MmalConnectedPort * output_port() = 0;
+
+public:
+  MmalComponent(const scoped_refptr<MmalVcInit>& vc_init) :
+    vc_init_(vc_init),
+    component_(nullptr),
+//    task_runner_(base::ThreadTaskRunnerHandle::Get())
+    task_runner_(base::SequencedTaskRunnerHandle::Get())
+  {
+  }
+
+  const MmalTaskRunner& task_runner() const
+  {
+    return task_runner_;
+  }
+
+  virtual const char * name() const = 0;
+
+  int connect_to_output(scoped_refptr<MmalComponent> src)
+  {
+    MmalConnectedPort * const dest = input_port();
+    if (dest->connect_to_src(src->output_port()) != 0)
+      return -1;
+    if (dest->enable() != 0) {
+      dest->disconnect();
+      return -1;
+    }
+    return 0;
+  }
+
+  int enable()
+  {
+    MMAL_STATUS_T err;
+
+    if ((err = mmal_component_enable(component_)) != MMAL_SUCCESS)
+      LOG(ERROR) << "### mmal_component_enable failed: err=" << err;
+
+    return err == MMAL_SUCCESS ? 0 : -1;
+  }
+
+  int disable()
+  {
+    MMAL_STATUS_T err;
+    if ((err = mmal_component_disable(component_)) != MMAL_SUCCESS)
+      LOG(ERROR) << "### mmal_component_disable failed: err=" << err;
+
+    return err == MMAL_SUCCESS ? 0 : -1;
+  }
+
+  // Shut this component down
+  // Reclaim all resources as they return & attempt to zero our internal
+  // ref count so we will die when the decoder derefs us.
+  // The reclaim process may be async so we may die some time later
+  virtual void kill() = 0;
+};
+
+// ---------------------------------------------------------------------------
+
+class MmalVideoDecoderComponent : public MmalComponent
+{
+  MmalVideoESPort port_in_;
+  MmalConnectedPort port_out_;
+  MmalPort port_ctrl_;
+
+protected:
+  ~MmalVideoDecoderComponent() override
+  {
+#if TRACE_COMPONENT_CREATION
+    LOG(INFO) << "@@@ ~MmalVideoDecoderComponent";
+#endif
+  }
+
+  MmalConnectedPort * input_port() override
+  {
+    return nullptr;
+  }
+
+  MmalConnectedPort * output_port() override
+  {
+    return &port_out_;
+  }
+
+
+public:
+  MmalVideoDecoderComponent(const scoped_refptr<MmalVcInit>& vc_init) :
+    MmalComponent(vc_init),
+    port_in_(vc_init, this),
+    port_out_(vc_init),
+    port_ctrl_(vc_init)
+  {
+#if TRACE_COMPONENT_CREATION
+    LOG(INFO) << "@@@ MmalVideoDecoderComponent";
+#endif
+  }
+
+  const char * name() const override
+  {
+    return "VideoDecoder";
+  }
+
+  int create(const MmalVideoDecoder::Options& opt, const VideoDecoderConfig& config, const bool low_delay)
+  {
+    if (create_by_name(MMAL_COMPONENT_DEFAULT_VIDEO_DECODER) != 0) {
+      return -1;
+    }
+
+    // Attach control structures to ports
+    port_in_.set_port(component_->input[0]);
+    port_out_.set_port(component_->output[0]);
+    port_ctrl_.set_port(component_->control);
+
+    if (
+        port_ctrl_.enable() != 0 ||
+
+        port_in_.set_parameter(MMAL_PARAMETER_VIDEO_MAX_NUM_CALLBACKS, low_delay ? -5 : -10) != 0 ||
+//        port_in_.set_parameter(MMAL_PARAMETER_VIDEO_MAX_NUM_CALLBACKS, -3) != 0 ||
+        port_in_.config(config, low_delay) != 0 ||
+        port_in_.commit() != 0 ||
+
+//        port_out_.set_parameter(MMAL_PARAMETER_EXTRA_BUFFERS, 6) != 0 ||
+        port_out_.set_parameter(MMAL_PARAMETER_VIDEO_INTERPOLATE_TIMESTAMPS, false) != 0 ||
+        port_out_.set_video_encoding(opt.decoder_out_encoding()) != 0 ||
+        port_out_.set_video_format(config.coded_size(),
+            config.visible_rect(),
+            par_from_sizes(config.visible_rect().size(), config.natural_size()),
+            color_space_to_mmal(config.color_space_info())) != 0 ||
+        port_out_.commit() != 0 ||
+
+        port_in_.set_buffers(0x10000, 8) != 0 ||
+        port_in_.set_parameter(MMAL_PARAMETER_ZERO_COPY, false) != 0 ||  // ### Z-Copy is bust here
+        port_in_.create_port_pool() != 0 ||
+
+        port_in_.enable() != 0)
+    {
+      goto fail;
+    }
+
+    return 0;
+
+fail:
+    return -1;
+  }
+
+  void kill() override
+  {
+    port_in_.kill();
+    port_out_.kill();
+  }
+
+  void reset1()
+  {
+    port_in_.disable();
+    port_out_.disable();
+  }
+
+  void reset2()
+  {
+    port_out_.enable();
+    port_in_.enable();
+  }
+
+
+  int submit(std::unique_ptr<ESBufferHolder> bh)
+  {
+    return port_in_.submit_decoder_buffer(std::move(bh));
+  }
+};
+
+// ---------------------------------------------------------------------------
+
+class MmalVideoResizerComponent : public MmalComponent
+{
+  FrameCopyMode copy_mode_;
+  gfx::Size cur_size_;
+  MmalConnectedPort port_in_;
+  MmalVideoARGBPort port_out_;
+  MmalPort port_ctrl_;
+
+protected:
+  ~MmalVideoResizerComponent() override
+  {
+#if TRACE_COMPONENT_CREATION
+    LOG(INFO) << "@@@ ~MmalVideoResizerComponent";
+#endif
+  }
+
+  MmalConnectedPort * input_port() override
+  {
+    return &port_in_;
+  }
+
+  MmalConnectedPort * output_port() override
+  {
+    return nullptr;
+  }
+
+
+public:
+  MmalVideoResizerComponent(const scoped_refptr<MmalVcInit>& vc_init, GpuVideoAcceleratorFactories* const gpu_factories) :
+    MmalComponent(vc_init),
+    copy_mode_(FrameCopyMode::unset),
+    port_in_(vc_init),
+    port_out_(vc_init, this, gpu_factories),
+    port_ctrl_(vc_init)
+  {
+#if TRACE_COMPONENT_CREATION
+    LOG(INFO) << "@@@ MmalVideoResizerComponent";
+#endif
+  }
+
+  const char * name() const override
+  {
+    return "Resizer";
+  }
+
+  int create(const MmalVideoDecoder::Options& opt)
+  {
+    if (create_by_name(opt.resizer_component_name()) != 0) {
+      return -1;
+    }
+
+    // Attach control structures to ports
+    port_in_.set_port(component_->input[0]);
+    port_out_.set_port(component_->output[0]);
+    port_ctrl_.set_port(component_->control);
+    return 0;
+  }
+
+  bool is_copy_mode_supported(const FrameCopyMode mode) const
+  {
+    return port_out_.get_parameter_supported_encodings().is_supported(mode.mmal_encoding());
+  }
+
+  // output_cb - always offloaded from the mmal cb thread so no point
+  //  in having it bound to current thread before calling.
+  int configure(const MmalVideoDecoder::Options& opt,
+      const VideoDecoderConfig& config, const VideoDecoder::OutputCB& output_cb)
+  {
+    const gfx::Size& size = config.natural_size();
+
+    copy_mode_ = opt.frame_copy_mode(is_copy_mode_supported(FrameCopyMode::SLICE));
+
+    port_out_.set_copy_mode(copy_mode_, config.color_space_info());
+
+    if (port_ctrl_.enable() != 0 ||
+        port_out_.set_size(opt.debug_fixed_size_set() ? opt.debug_fixed_size() : size) != 0 ||
+        port_out_.set_resize_disabled(opt.debug_fixed_size_set()) != 0 ||
+        port_out_.set_debug_bench(opt.debug_bench(), opt.debug_fps()) != 0 ||
+        port_out_.commit() != 0)
+    {
+      goto fail;
+    }
+
+    // Set req values to current values
+    port_out_.reset_reqs();
+
+    switch (copy_mode_.get()) {
+      case FrameCopyMode::SLICE:
+        if (port_out_.set_buffers(MMAL_SLICE_HEIGHT * MMAL_LIMIT_WIDTH * 4, opt.frame_buffers(copy_mode_)) != 0 ||
+          port_out_.set_parameter(MMAL_PARAMETER_ZERO_COPY, true) != 0 ||
+          port_out_.create_port_pool() != 0)
+        {
+          goto fail;
+        }
+        break;
+
+      case FrameCopyMode::FRAME_GPU_YUV_VCSM:
+      case FrameCopyMode::FRAME_GPU_ARGB_VCSM:
+        // Zero copy into provided VCSM buffers
+        if (port_out_.set_buffers(port_out_.buffer_size_recommended(), opt.frame_buffers(copy_mode_)) != 0 ||
+          port_out_.set_parameter(MMAL_PARAMETER_ZERO_COPY, true) != 0 ||
+          port_out_.create_frame_pool(true) != 0)
+        {
+          goto fail;
+        }
+        break;
+
+      case FrameCopyMode::FRAME_I420:
+      case FrameCopyMode::FRAME_NV12:
+      case FrameCopyMode::FRAME_ARGB_DMA:
+      case FrameCopyMode::FRAME_GPU_ARGB_DMA:
+        // Firmware-side frame copy
+        if (port_out_.set_buffers(port_out_.buffer_size_recommended(), opt.frame_buffers(copy_mode_)) != 0 ||
+          port_out_.set_parameter(MMAL_PARAMETER_ZERO_COPY, false) != 0 ||
+          port_out_.create_frame_pool(false) != 0)
+        {
+          goto fail;
+        }
+        break;
+
+      case FrameCopyMode::FRAME_GPU_YUV_COPY:
+      case FrameCopyMode::FRAME_ARGB_COPY:
+        if (port_out_.set_buffers(port_out_.buffer_size_recommended(), opt.frame_buffers(copy_mode_)) != 0 ||
+          port_out_.set_parameter(MMAL_PARAMETER_ZERO_COPY, true) != 0 ||
+          port_out_.create_port_pool() != 0)
+        {
+          goto fail;
+        }
+        break;
+
+      case FrameCopyMode::unset:
+        goto fail;
+    }
+
+    if (port_out_.enable(output_cb) != 0)
+      goto fail;
+
+    cur_size_ = size;
+    return 0;
+
+fail:
+    return -1;
+  }
+
+  void kill() override
+  {
+    port_in_.kill();
+    port_out_.kill();
+  }
+
+  void reset1()
+  {
+    port_in_.disable();
+    port_out_.disable();
+  }
+
+  void reset2()
+  {
+    port_out_.enable();
+    port_in_.enable();
+  }
+
+  void set_eos_cb(VideoDecoder::DecodeCB eos_cb)
+  {
+    port_out_.set_eos_cb(std::move(eos_cb));
+  }
+
+  void set_red_pixel(const bool red)
+  {
+    port_out_.set_red_pixel(red);
+  }
+
+  bool is_output_stalling() const
+  {
+    return port_out_.is_stalling();
+  }
+
+  void resize(const gfx::Size& new_size)
+  {
+    port_out_.resize_cb(new_size);
+  }
+};
+
+
+// ---------------------------------------------------------------------------
+
+void MmalConnection::disconnect()
+{
+  if (!src_ || !dest_) {
+    LOG(ERROR) << "#### src or dest NULL";
+    return;
+  }
+
+  disable();
+
+  // Commit suicide by killing our refs
+  // Both ends should still exist as the destruction of either
+  // should call this fn
+  src_->set_connection(nullptr);
+  dest_->set_connection(nullptr);
+}
+
+int MmalConnection::connect(MmalConnectedPort * const src, MmalConnectedPort * const dest)
+{
+  MMAL_STATUS_T err;
+
+  // MMAL_CONNECTION_FLAG_KEEP_BUFFER_REQUIREMENTS means
+  // that enable will actually observe the buffer_num
+  // and size fields - otherwise it will always ignore
+  // them
+  if ((err = mmal_connection_create(&connection_, src->port_, dest->port_,
+      MMAL_CONNECTION_FLAG_KEEP_BUFFER_REQUIREMENTS | MMAL_CONNECTION_FLAG_TUNNELLING)) != MMAL_SUCCESS) {
+    LOG(ERROR) << "### mmal_connection_create failed: err=" << err;
+    connection_ = nullptr;  // Just in case
+    return -1;
+  }
+
+  src->set_connection(this);
+  dest->set_connection(this);
+
+  src_ = src;
+  dest_ = dest;
+
+  // As we have asked for our choices to be respected we should make sure they
+  // are set to something sensible
+  set_buffers(buffer_size_recommended(), buffer_num_recommended());
+
+  mmal_log_dump_port(src->port_);
+  mmal_log_dump_port(dest->port_);
+  return 0;
+}
+
+uint32_t MmalConnection::buffer_size_recommended() const
+{
+  return std::max(src_->MmalPort::buffer_size_recommended(), dest_->MmalPort::buffer_size_recommended());
+}
+
+uint32_t MmalConnection::buffer_num_recommended() const
+{
+  return std::max(src_->MmalPort::buffer_num_recommended(), dest_->MmalPort::buffer_num_recommended());
+}
+
+uint32_t MmalConnection::buffer_size_min() const
+{
+  return std::max(src_->MmalPort::buffer_size_min(), dest_->MmalPort::buffer_size_min());
+}
+
+uint32_t MmalConnection::buffer_num_min() const
+{
+  return std::max(src_->MmalPort::buffer_num_min(), dest_->MmalPort::buffer_num_min());
+}
+
+int MmalConnection::set_buffers(uint32_t s, uint32_t n)
+{
+  src_->MmalPort::set_buffers(s, n);
+  dest_->MmalPort::set_buffers(s, n);
+  return 0;
+}
+
+
+// ---------------------------------------------------------------------------
+
+// Any refs required are applied to our enclosing object
+void MmalPortAndPool::AddRef()
+{
+  component_->AddRef();
+}
+
+// Any refs required are applied to our enclosing object
+void MmalPortAndPool::Release()
+{
+  component_->Release();
+}
+
+bool MmalPortAndPool::HasOneRef() const
+{
+  return component_->HasOneRef();
+}
+
+bool MmalPortAndPool::HasAtLeastOneRef() const
+{
+  return component_->HasAtLeastOneRef();
+}
+
+const MmalTaskRunner& MmalPortAndPool::task_runner() const
+{
+  return component_->task_runner();
+}
+
+// ---------------------------------------------------------------------------
+
+// static
+bool MmalVideoDecoder::IsCodecSupported(VideoCodec codec) {
+//  LOG(ERROR) << "Test codec: " << codec;
+  // If we have checked what we can do then use that otherwise press on
+  // if we have any chance (i.e. can find a valid 4cc)
+  return (supported_video_codecs & (1 << codec)) != 0 ||
+         (supported_video_codecs == 0 && video_codec_to_fourcc(codec) != MMAL_ENCODING_UNKNOWN);
+}
+
+bool MmalVideoDecoder::IsSizeSupported(const gfx::Size& size)
+{
+  return size.width() <= MMAL_LIMIT_WIDTH &&
+    size.height() <= MMAL_LIMIT_HEIGHT &&
+    size.width() >= 32 &&
+    size.height() >= 32;
+}
+
+// Resizer can deal with larger values than the limits we want on the decoder
+// Pick limits that might not kill us (at least till Pi4)
+static bool IsResizeSizeSupported(const gfx::Size& size)
+{
+  return size.width() <= 2048 &&
+    size.height() <= 1280 &&
+    size.width() >= 32 &&
+    size.height() >= 32;
+}
+
+MmalVideoDecoder::MmalVideoDecoder(GpuVideoAcceleratorFactories* gpu_factories) :
+  gpu_factories_(gpu_factories && gpu_factories->ShouldUseGpuMemoryBuffersForVideoFrames(false) ? gpu_factories : nullptr),
+  state_(MmalDecoderState::kNew),
+  counted_(false),
+  wants_extra_data_(false),
+  opt_(Options::Create()),
+  vc_init_(MmalVcInit::Init(opt_->single_process(), bool(gpu_factories_))),  // ****** Want better cma choice
+  weak_factory_(this)
+{
+#if TRACE_COMPONENT_CREATION
+  LOG(INFO) << "@@@ Create Decoder pid=" << getpid() << ", ppid=" << getppid() << ", gpu=" << (void *)gpu_factories <<
+    ", use_gpu:" << (bool)gpu_factories_;
+#endif
+
+  if (!vc_init_) {
+    state_ = MmalDecoderState::kFatal;
+    return;
+  }
+
+  opt_->set_firmware_date(vc_init_->firmware_date());
+  opt_->set_gpu_mem(vc_init_->gpu_mem());
+  opt_->set_gpu_frames((bool)gpu_factories_); // ***** VCSM/copied GPU?
+
+  if (gpu_factories_)
+  {
+    // Select YUV copy if we don't have tex import
+    // * Really should have better logic downstream s.t. stuff all works but
+    //   for now this will fix the crash
+    scoped_refptr<viz::RasterContextProvider> context_provider(gpu_factories_->GetMediaContextProvider());
+    const gpu::Capabilities& capabilities = context_provider->ContextCapabilities();
+    // tex_import false if unset
+    opt_->set_tex_import(capabilities.egl_image_external);
+  }
+
+  LOG(INFO) << opt_->ToString();
+  LOG(INFO) << opt_->OptString();
+
+  state_ = MmalDecoderState::kUninitialised;
+  return;
+}
+
+MmalVideoDecoder::~MmalVideoDecoder() {
+#if TRACE_COMPONENT_CREATION
+  LOG(INFO) << "@@@ Destroy Decoder";
+#endif
+
+  uninitialise();
+
+  if (counted_) {
+    base::subtle::NoBarrier_AtomicIncrement(&decoder_count, -1);
+  }
+}
+
+
+
+std::string MmalVideoDecoder::GetDisplayName() const {
+  return "MmalVideoDecoder";
+}
+
+
+void MmalVideoDecoder::uninitialise(const MmalDecoderState new_state)
+{
+  if (decoder_) {
+    decoder_->kill();
+    decoder_.reset();
+  }
+  if (resizer_) {
+    resizer_->kill();
+    resizer_.reset();
+  }
+
+  extra_data_.reset();
+  wants_extra_data_ = false;
+
+  state_ = new_state;
+}
+
+// EOS callback - accessed via WeakPtr so if we are destroyed
+// whilst EOS is still pending this won't happen
+//
+// We call Reset on EOS.  This has a couple of benefits
+// 1) It reclaims memory as soon as possible (there's a decent chance we
+//    are done with this decoder now)
+// 2) It should allow us to go <decode> <eos> <decode> which is defined to
+//    work in the Decode spec (even if it doesn't seem to happen in reality)
+
+void MmalVideoDecoder::eos_cb(DecodeCB decode_cb, DecodeStatus status)
+{
+//  LOG(ERROR) << "+++ EOS(" << status << ")";
+  Reset(base::BindOnce(std::move(decode_cb), status));
+}
+
+// Initializes a VideoDecoder with the given |config|, executing the
+// |init_cb| upon completion. |output_cb| is called for each output frame
+// decoded by Decode().
+//
+// If |low_delay| is true then the decoder is not allowed to queue frames,
+// except for out-of-order frames, i.e. if the next frame can be returned it
+// must be returned without waiting for Decode() to be called again.
+// Initialization should fail if |low_delay| is true and the decoder cannot
+// satisfy the requirements above.
+//
+// |cdm_context| can be used to handle encrypted buffers. May be null if the
+// stream is not encrypted.
+//
+// |waiting_cb| is called whenever the decoder is stalled waiting for
+// something, e.g. decryption key. May be called at any time after
+// Initialize().
+//
+// Note:
+// 1) The VideoDecoder will be reinitialized if it was initialized before.
+//    Upon reinitialization, all internal buffered frames will be dropped.
+// 2) This method should not be called during pending decode or reset.
+// 3) No VideoDecoder calls should be made before |init_cb| is executed.
+// 4) VideoDecoders should take care to run |output_cb| as soon as the frame
+// is ready (i.e. w/o thread trampolining) since it can strongly affect frame
+// delivery times with high-frame-rate material.  See Decode() for additional
+// notes.
+// 5) |init_cb| may be called before this returns.
+void MmalVideoDecoder::Initialize(const VideoDecoderConfig& config,
+                        bool low_delay,
+                        CdmContext* cdm_context,
+                        InitCB init_cb,
+                        const OutputCB& output_cb,
+                        const WaitingCB& waiting_cb)
+{
+  base::AutoLock lock(lock_);
+  Status fail_status(StatusCode::kDecoderFailedInitialization);
+
+  LOG(INFO) << "Mmal Init: low_delay=" << low_delay << ", config=" << config.AsHumanReadableString();
+
+  DCHECK(config.IsValidConfig());
+  DCHECK(!output_cb.is_null());
+
+  InitCB bound_init_cb(BindToCurrentLoop(std::move(init_cb)));
+
+  // If dead - give up now
+  if (state_ <= MmalDecoderState::kFatal) {
+    LOG(ERROR) << __func__ << ": FATAL";
+    std::move(bound_init_cb).Run(fail_status);
+    return;
+  }
+
+  // If already inited (or failed) then kill
+  if (state_ != kUninitialised) {
+    // * This is unsubtle in the extreme
+    // and we would really prefer to wait for the kill ops to finish
+    // before continuing so we don't have an overlap where we have
+    // two sets of resizer buffers ... or preserve the resizer...
+    // or something...
+    uninitialise();
+  }
+
+  if (state_ != kUninitialised) {
+    LOG(ERROR) << __func__ << ": Unexpected state: " << state_;
+    goto fail;
+  }
+
+  // Do we support this?
+  if (config.is_encrypted()) {
+    fail_status = Status(StatusCode::kEncryptedContentUnsupported);
+    goto fail;
+  }
+  if (!IsCodecSupported(config.codec())) {
+    fail_status = Status(StatusCode::kDecoderUnsupportedCodec);
+    goto fail;
+  }
+  if (!IsSizeSupported(config.coded_size())) {
+    fail_status = Status(StatusCode::kDecoderUnsupportedConfig);
+    goto fail;
+  }
+
+  // Check count
+  // 0 will effectively turn off mmal decode
+  if (!counted_)
+  {
+    const int n = (int)base::subtle::NoBarrier_AtomicIncrement(&decoder_count, 1);
+    const int max_dec = (int)opt_->max_decoders();
+    counted_ = true;
+    if (n > max_dec) {
+      LOG(WARNING) << __func__ << ": Exceeded decoder limit: " << n << "/" << max_dec;
+      goto fail;
+    }
+  }
+
+  LOG(INFO) << "Decoder count:" << decoder_count << "/" << opt_->max_decoders();
+
+  // Stash for later reset
+  decoder_config_ = config;
+  low_delay_ = opt_->low_delay(low_delay);
+
+  if (config.extra_data().size() != 0)
+  {
+    extra_data_ = DecoderBuffer::CopyFrom(&config.extra_data()[0], config.extra_data().size());
+    wants_extra_data_ = true;
+  }
+
+  decoder_ = new MmalVideoDecoderComponent(vc_init_);
+  if (decoder_->create(*opt_, config, low_delay_) != 0)
+    goto fail;
+  if (decoder_->enable() != 0)
+    goto fail;
+
+  resizer_ = new MmalVideoResizerComponent(vc_init_,
+    opt_->frame_copy_mode(false).is_gpu() ? gpu_factories_ : nullptr);
+
+  if (resizer_->create(*opt_) != 0)
+    goto fail;
+
+  if (resizer_->configure(*opt_, config, output_cb) != 0)
+    goto fail;
+
+  resizer_->set_red_pixel(opt_->red_pixel());
+  if (resizer_->enable() != 0)
+    goto fail;
+
+  if (resizer_->connect_to_output(decoder_) != 0)
+    goto fail;
+
+  state_ = MmalDecoderState::kInitialised;
+
+  // Success!
+  std::move(bound_init_cb).Run(OkStatus());
+  LOG(INFO) << __func__ << ": OK";
+  return;
+
+
+fail:
+  LOG(INFO) << __func__ << ": FAILED";
+  uninitialise(std::min(state_, MmalDecoderState::kFail));
+  if (counted_) {
+    counted_ = false;
+    base::subtle::NoBarrier_AtomicIncrement(&decoder_count, -1);
+  }
+  std::move(bound_init_cb).Run(fail_status);
+}
+
+// Requests a |buffer| to be decoded. The status of the decoder and decoded
+// frame are returned via the provided callback. Some decoders may allow
+// decoding multiple buffers in parallel. Callers should call
+// GetMaxDecodeRequests() to get number of buffers that may be decoded in
+// parallel.
+//
+// Implementations guarantee that the |decode_cb| will not be called from
+// within this method, and that it will be called even if Decode() is never
+// called again.
+//
+// After decoding is finished the decoder calls |output_cb| specified in
+// Initialize() for each decoded frame. |output_cb| may be called before or
+// after |decode_cb|, including before Decode() returns.
+//
+// If |buffer| is an EOS buffer then the decoder must be flushed, i.e.
+// |output_cb| must be called for each frame pending in the queue and
+// |decode_cb| must be called after that. Callers will not call Decode()
+// again until after the flush completes.
+void MmalVideoDecoder::Decode(scoped_refptr<DecoderBuffer> buffer,
+                    DecodeCB decode_cb)
+{
+  DCHECK(buffer.get());
+  DCHECK(!decode_cb.is_null());
+
+  const bool eos_req = buffer->end_of_stream();
+
+  // If we are in any state except running (reset, never sent data, eos)
+  // then EOS won't propagate and we should ack here & now
+  if (eos_req && state_ != MmalDecoderState::kRunning) {
+    LOG(INFO) << "<<< >>> EOS";
+    BindToCurrentLoop(std::move(decode_cb)).Run(DecodeStatus::OK);
+    return;
+  }
+
+  if (state_ == MmalDecoderState::kResetEOS) {
+    // * Really we should be able to do half this work
+    //   and drop into ResetRun but the enables don't currently work
+    //   correctly for that
+
+    decoder_ = new MmalVideoDecoderComponent(vc_init_);
+    if (decoder_->create(*opt_, decoder_config_, low_delay_) != 0)
+      goto fail;
+    if (decoder_->enable() != 0)
+      goto fail;
+
+    if (resizer_->connect_to_output(decoder_) != 0)
+      goto fail;
+
+    resizer_->reset2();
+
+    wants_extra_data_ = bool(extra_data_);
+
+    state_ = MmalDecoderState::kInitialised;
+  }
+  else if (state_ == MmalDecoderState::kResetRun) {
+    resizer_->reset2();
+    decoder_->reset2();
+    wants_extra_data_ = (extra_data_ != NULL);
+    state_ = MmalDecoderState::kInitialised;
+  }
+
+  if (state_ < MmalDecoderState::kInitialised)
+  {
+    LOG(ERROR) << "### Decode in bad state: " << state_;
+    goto fail;
+  }
+
+  if (wants_extra_data_) {
+    if (!extra_data_) {
+      LOG(ERROR) << "### extra_data_ NULL";
+      goto fail;
+    }
+
+    wants_extra_data_ = false;
+    if (decoder_->submit(ESBufferHolder::CreateExtra(extra_data_)) < 0)
+      goto fail;
+  }
+
+  if (eos_req) {
+    LOG(INFO) << "<<< EOS";
+    // eos_cb must be called on the current thread
+    resizer_->set_eos_cb(BindToCurrentLoop(
+        base::BindOnce(&MmalVideoDecoder::eos_cb, GetWeakPtr(), std::move(decode_cb))));
+
+    if (decoder_->submit(ESBufferHolder::Create(buffer)) < 0)
+      goto fail;
+
+    state_ = MmalDecoderState::kEOS;
+  }
+  else
+  {
+    if (decoder_->submit(ESBufferHolder::Create(buffer, BindToCurrentLoop(std::move(decode_cb)))) < 0)
+      goto fail;
+
+    state_ = MmalDecoderState::kRunning;
+  }
+
+//  LOG(ERROR) << ">>> Decode";
+  return;
+
+fail:
+  LOG(WARNING) << ">>> Decode: FAIL";
+  BindToCurrentLoop(std::move(decode_cb)).Run(DecodeStatus::DECODE_ERROR);
+}
+
+// Resets decoder state. All pending Decode() requests will be finished or
+// aborted before |closure| is called.
+// Note: No VideoDecoder calls should be made before |closure| is executed.
+//
+// This fn shuts stuff down - restart is managed at the beginning of Decode
+
+void MmalVideoDecoder::Reset(base::OnceClosure closure) {
+  switch (state_) {
+    case MmalDecoderState::kRunning:
+      LOG(INFO) << "--- Reset (running)";
+      decoder_->reset1();
+      resizer_->reset1();
+      state_ = MmalDecoderState::kResetRun;
+      break;
+
+    case MmalDecoderState::kEOS:
+      LOG(INFO) << "--- Reset (EOS)";
+      decoder_->kill();
+      decoder_.reset();
+      resizer_->reset1();
+      state_ = MmalDecoderState::kResetEOS;
+      break;
+
+    default:
+      LOG(INFO) << "--- Reset (null)";
+      break;
+  }
+
+  // Ensure the closure is scheduled after any callbacks triggered by
+  // the reset sequence
+  base::SequencedTaskRunnerHandle::Get()->PostTask(FROM_HERE, std::move(closure));
+  LOG(INFO) << ">>> Reset";
+  return;
+}
+
+bool MmalVideoDecoder::CanReadWithoutStalling() const
+{
+  return resizer_ == nullptr || !resizer_->is_output_stalling();
+}
+
+int MmalVideoDecoder::GetMaxDecodeRequests() const
+{
+  // We can run with overlap or not - pick 2 in case it helps whatever is feeding us
+  return 2;
+}
+
+// There is the theoretical possibility of race here if this is called
+// whilst a reinitialise is running.  However the calling code in
+// video_renderer_impl already has a lock that should prevent that.
+void MmalVideoDecoder::TryResizeFrame(uint32_t width, uint32_t height)
+{
+  base::AutoLock lock(lock_);
+
+  gfx::Size size_req(width, height);
+
+//  LOG(INFO) << __func__ << ": " << decoder_config_.visible_rect().ToString() << " -> " << size_req.ToString() << ", mode=" << int(opt_->resize_mode());
+
+  switch (opt_->resize_mode()) {
+    case ResizeMode::Smaller:
+      if (int(width * height) >= decoder_config_.visible_rect().width() * decoder_config_.visible_rect().height())
+        return;
+      FALLTHROUGH;
+    case ResizeMode::Always:
+      if (!IsResizeSizeSupported(size_req))
+        size_req = decoder_config_.coded_size();
+      break;
+
+    default:  // Never
+      // If never then size was set to native at init & cannot change
+      return;
+  }
+
+  resizer_->resize(size_req);
+}
+
+}  // namespace media
+
+
+
--- /dev/null
+++ b/src/media/filters/mmal_video_decoder.h
@@ -0,0 +1,121 @@
+// Copyright (c) 2012 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MEDIA_FILTERS_MMAL_VIDEO_DECODER_H_
+#define MEDIA_FILTERS_MMAL_VIDEO_DECODER_H_
+
+#include <list>
+
+#include "base/callback.h"
+#include "base/macros.h"
+#include "base/memory/weak_ptr.h"
+#include "base/threading/thread_checker.h"
+#include "media/base/video_decoder.h"
+#include "media/base/video_decoder_config.h"
+#include "media/base/video_frame_pool.h"
+#include "base/command_line.h"
+#include "base/strings/string_number_conversions.h"
+
+
+
+struct AVCodecContext;
+struct AVFrame;
+
+namespace base {
+class SingleThreadTaskRunner;
+}
+
+namespace media {
+
+class DecoderBuffer;
+class MmalVideoDecoderComponent;
+class MmalVideoResizerComponent;
+class MmalVcInit;
+class GpuVideoAcceleratorFactories;
+
+class MEDIA_EXPORT MmalVideoDecoder : public VideoDecoder {
+public:
+  class Options;
+
+private:
+  enum MmalDecoderState {
+      kFatal = -2,
+      kFail = -1,
+      kNew = 0,
+      kUninitialised,
+      kReseting,
+      kResetEOS,     // Reset from EOS
+      kResetRun,     // Reset from running
+      kInitialised,  // Init but no decode yet
+      kRunning,      // Have successful decode
+      kEOS           // EOS rxed
+  };
+
+  base::Lock lock_;
+
+  GpuVideoAcceleratorFactories* const gpu_factories_;
+
+  MmalDecoderState state_;
+
+  // Have we counted this decoder (for decoder count limits) yet?
+  bool counted_;
+
+  scoped_refptr<DecoderBuffer> extra_data_;
+  bool wants_extra_data_;
+
+  scoped_refptr<MmalVideoDecoderComponent> decoder_;
+  // Resizer may persist after VideoDecoder dies if it maintains frames
+  // with shared VC memory
+  scoped_refptr<MmalVideoResizerComponent> resizer_;
+
+  VideoDecoderConfig decoder_config_;
+  bool low_delay_;
+
+  const std::unique_ptr<Options> opt_;
+  scoped_refptr<MmalVcInit> vc_init_;
+
+  void uninitialise(const MmalDecoderState new_state = kUninitialised);
+  void eos_cb(const DecodeCB decode_cb, DecodeStatus status);
+  void format_req_cb(VideoPixelFormat pixel_format);
+
+ public:
+  static bool IsCodecSupported(VideoCodec codec);
+  static bool IsSizeSupported(const gfx::Size& size);
+
+  MmalVideoDecoder(GpuVideoAcceleratorFactories* gpu_factories);
+  ~MmalVideoDecoder() override;
+
+  // VideoDecoder implementation.
+  std::string GetDisplayName() const override;
+
+  void Initialize(const VideoDecoderConfig& config,
+                          bool low_delay,
+                          CdmContext* cdm_context,
+                          InitCB init_cb,
+                          const OutputCB& output_cb,
+                          const WaitingCB& waiting_cb) override;
+
+  void Decode(scoped_refptr<DecoderBuffer> buffer,
+                      DecodeCB decode_cb) override;
+
+  void Reset(base::OnceClosure closure) override;
+
+  bool CanReadWithoutStalling() const override;
+  int GetMaxDecodeRequests() const override;
+  void TryResizeFrame(uint32_t width, uint32_t height) override;
+
+  inline base::WeakPtr<MmalVideoDecoder> GetWeakPtr() {
+    return weak_factory_.GetWeakPtr();
+  }
+
+ private:
+  DISALLOW_COPY_AND_ASSIGN(MmalVideoDecoder);
+  base::WeakPtrFactory<MmalVideoDecoder> weak_factory_;
+};
+
+}  // namespace media
+
+#endif  // MEDIA_FILTERS_MMAL_VIDEO_DECODER_H_
+
+
--- a/src/media/renderers/default_decoder_factory.cc
+++ b/src/media/renderers/default_decoder_factory.cc
@@ -52,6 +52,10 @@
 #include "media/filters/gav1_video_decoder.h"
 #endif
 
+#ifdef __ARM_ARCH
+#include "media/filters/mmal_video_decoder.h"
+#endif
+
 namespace media {
 
 DefaultDecoderFactory::DefaultDecoderFactory(
@@ -146,6 +150,10 @@ void DefaultDecoderFactory::CreateVideoD
   }
 #endif
 
+#ifdef __ARM_ARCH
+  video_decoders->push_back(std::make_unique<MmalVideoDecoder>(gpu_factories));
+#endif
+
 #if BUILDFLAG(ENABLE_LIBVPX)
   video_decoders->push_back(std::make_unique<OffloadingVpxVideoDecoder>());
 #endif
--- a/src/media/renderers/paint_canvas_video_renderer.cc
+++ b/src/media/renderers/paint_canvas_video_renderer.cc
@@ -793,6 +793,7 @@ void PaintCanvasVideoRenderer::Paint(
   // frame has an unexpected format.
   if (!video_frame.get() || video_frame->natural_size().IsEmpty() ||
       !(media::IsYuvPlanar(video_frame->format()) ||
+        video_frame->format() == media::PIXEL_FORMAT_MMAL_BUFFER ||
         video_frame->format() == media::PIXEL_FORMAT_Y16 ||
         video_frame->HasTextures())) {
     cc::PaintFlags black_with_alpha_flags;
--- a/src/media/renderers/video_renderer_impl.cc
+++ b/src/media/renderers/video_renderer_impl.cc
@@ -283,6 +283,12 @@ base::TimeDelta VideoRendererImpl::GetPr
   return algorithm_->average_frame_duration();
 }
 
+void VideoRendererImpl::TryResizeFrame(uint32_t width, uint32_t height)
+{
+  base::AutoLock auto_lock(lock_);
+  video_decoder_stream_->TryResizeFrame(width, height);
+}
+
 void VideoRendererImpl::OnVideoDecoderStreamInitialized(bool success) {
   DCHECK(task_runner_->BelongsToCurrentThread());
   base::AutoLock auto_lock(lock_);
--- a/src/media/renderers/video_renderer_impl.h
+++ b/src/media/renderers/video_renderer_impl.h
@@ -89,6 +89,7 @@ class MEDIA_EXPORT VideoRendererImpl
                                    bool background_rendering) override;
   void OnFrameDropped() override;
   base::TimeDelta GetPreferredRenderInterval() override;
+  void TryResizeFrame(uint32_t width, uint32_t height) override;
 
  private:
   // Callback for |video_decoder_stream_| initialization.
--- a/src/media/renderers/video_resource_updater.cc
+++ b/src/media/renderers/video_resource_updater.cc
@@ -40,9 +40,11 @@
 #include "gpu/command_buffer/client/shared_image_interface.h"
 #include "gpu/command_buffer/common/shared_image_trace_utils.h"
 #include "gpu/command_buffer/common/shared_image_usage.h"
+#include "media/base/bind_to_current_loop.h"
 #include "media/base/video_frame.h"
 #include "media/renderers/paint_canvas_video_renderer.h"
 #include "media/video/half_float_maker.h"
+#include "mojo/public/cpp/system/platform_handle.h"
 #include "third_party/khronos/GLES2/gl2.h"
 #include "third_party/khronos/GLES2/gl2ext.h"
 #include "third_party/libyuv/include/libyuv.h"
@@ -99,6 +101,12 @@ VideoFrameResourceType ExternalResourceT
                               : gfx::BufferFormat::RGBA_1010102;
       return VideoFrameResourceType::RGB;
     case PIXEL_FORMAT_I420:
+      if (num_textures == 1 && target == GL_TEXTURE_EXTERNAL_OES)
+      {
+        buffer_formats[0] = gfx::BufferFormat::YVU_420;
+        return VideoFrameResourceType::STREAM_TEXTURE;
+      }
+
       DCHECK_EQ(num_textures, 3);
       buffer_formats[0] = gfx::BufferFormat::R_8;
       buffer_formats[1] = gfx::BufferFormat::R_8;
@@ -125,6 +133,9 @@ VideoFrameResourceType ExternalResourceT
       NOTREACHED();
       FALLTHROUGH;
     case PIXEL_FORMAT_YV12:
+      if (num_textures == 1 && target == GL_TEXTURE_EXTERNAL_OES)
+        return VideoFrameResourceType::STREAM_TEXTURE;
+      break;
     case PIXEL_FORMAT_I422:
     case PIXEL_FORMAT_I444:
     case PIXEL_FORMAT_I420A:
@@ -229,6 +240,7 @@ class VideoResourceUpdater::PlaneResourc
 
   // Casts |this| to SoftwarePlaneResource for software compositing.
   SoftwarePlaneResource* AsSoftware();
+  SoftwarePlaneVideoFrameResource* AsVideoFrame();
 
   // Casts |this| to HardwarePlaneResource for GPU compositing.
   HardwarePlaneResource* AsHardware();
@@ -243,12 +255,17 @@ class VideoResourceUpdater::PlaneResourc
   // Sets the unique identifiers for this resource, may only be called when
   // there is a single reference to the resource (i.e. |ref_count_| == 1).
   void SetUniqueId(int unique_frame_id, size_t plane_index) {
-    DCHECK_EQ(ref_count_, 1);
+// Is called in child constructor when ref_count == 0
+//    DCHECK_EQ(ref_count_, 1);
     plane_index_ = plane_index;
     unique_frame_id_ = unique_frame_id;
     has_unique_frame_id_and_plane_index_ = true;
   }
 
+  virtual bool kill_me() const {  // Recycle wanted ASAP - VideoFrames want to be kiled when refs hit zero
+    return false;
+  }
+
   // Accessors for resource identifiers provided at construction time.
   uint32_t plane_resource_id() const { return plane_resource_id_; }
   const gfx::Size& resource_size() const { return resource_size_; }
@@ -259,6 +276,8 @@ class VideoResourceUpdater::PlaneResourc
   void remove_ref() { --ref_count_; }
   void clear_refs() { ref_count_ = 0; }
   bool has_refs() const { return ref_count_ != 0; }
+  virtual bool overlay_candidate() const { return false; }
+  virtual uint32_t stride() const { return 0; }
 
  private:
   const uint32_t plane_resource_id_;
@@ -282,16 +301,43 @@ class VideoResourceUpdater::PlaneResourc
 
 class VideoResourceUpdater::SoftwarePlaneResource
     : public VideoResourceUpdater::PlaneResource {
+ protected:
+  viz::SharedBitmapReporter* const shared_bitmap_reporter_;
+  const viz::SharedBitmapId shared_bitmap_id_;
+
  public:
   SoftwarePlaneResource(uint32_t plane_resource_id,
+                const gfx::Size& resource_size,
+                const viz::SharedBitmapId& shared_bitmap,
+                viz::SharedBitmapReporter* const shared_bitmap_reporter)
+      : PlaneResource(plane_resource_id, resource_size, viz::ResourceFormat::RGBA_8888, true),
+        shared_bitmap_reporter_(shared_bitmap_reporter),
+        shared_bitmap_id_(shared_bitmap)
+  {
+  }
+
+  ~SoftwarePlaneResource() override {
+  }
+
+  const viz::SharedBitmapId& shared_bitmap_id() const {
+    return shared_bitmap_id_;
+  }
+
+  virtual void* pixels() = 0;
+
+  // Returns a memory dump GUID consistent across processes.
+  virtual base::UnguessableToken GetSharedMemoryGuid() const = 0;
+};
+
+class VideoResourceUpdater::SoftwarePlaneBitmapResource
+    : public VideoResourceUpdater::SoftwarePlaneResource {
+ public:
+  SoftwarePlaneBitmapResource(uint32_t plane_resource_id,
                         const gfx::Size& size,
                         viz::SharedBitmapReporter* shared_bitmap_reporter)
-      : PlaneResource(plane_resource_id,
-                      size,
-                      viz::ResourceFormat::RGBA_8888,
-                      /*is_software=*/true),
-        shared_bitmap_reporter_(shared_bitmap_reporter),
-        shared_bitmap_id_(viz::SharedBitmap::GenerateId()) {
+      : SoftwarePlaneResource(plane_resource_id, size,
+                              viz::SharedBitmap::GenerateId(), shared_bitmap_reporter)
+  {
     DCHECK(shared_bitmap_reporter_);
 
     // Allocate SharedMemory and notify display compositor of the allocation.
@@ -302,28 +348,91 @@ class VideoResourceUpdater::SoftwarePlan
     shared_bitmap_reporter_->DidAllocateSharedBitmap(std::move(shm.region),
                                                      shared_bitmap_id_);
   }
-  ~SoftwarePlaneResource() override {
+
+  ~SoftwarePlaneBitmapResource() override {
     shared_bitmap_reporter_->DidDeleteSharedBitmap(shared_bitmap_id_);
   }
 
   const viz::SharedBitmapId& shared_bitmap_id() const {
     return shared_bitmap_id_;
   }
-  void* pixels() { return shared_mapping_.memory(); }
+  void* pixels() override { return shared_mapping_.memory(); }
 
   // Returns a memory dump GUID consistent across processes.
-  base::UnguessableToken GetSharedMemoryGuid() const {
+  base::UnguessableToken GetSharedMemoryGuid() const override {
     return shared_mapping_.guid();
   }
 
  private:
-  viz::SharedBitmapReporter* const shared_bitmap_reporter_;
-  const viz::SharedBitmapId shared_bitmap_id_;
   base::WritableSharedMemoryMapping shared_mapping_;
 
-  DISALLOW_COPY_AND_ASSIGN(SoftwarePlaneResource);
+  DISALLOW_COPY_AND_ASSIGN(SoftwarePlaneBitmapResource);
 };
 
+class VideoResourceUpdater::SoftwarePlaneVideoFrameResource
+    : public VideoResourceUpdater::SoftwarePlaneResource {
+
+  scoped_refptr<VideoFrame> video_frame_;
+
+  static viz::SharedBitmapId make_nz_id(const viz::SharedBitmapId& id) {
+    if (!id.IsZero())
+      return id;
+    return viz::SharedBitmap::GenerateId();
+  }
+
+ public:
+  SoftwarePlaneVideoFrameResource(uint32_t plane_resource_id,
+                        scoped_refptr<VideoFrame> video_frame,
+                        VideoResourceUpdater * const video_resource_updater)
+      : SoftwarePlaneResource(plane_resource_id, video_frame->coded_size(),
+                              make_nz_id(video_frame->GetBitmapId()),
+                              video_resource_updater->shared_bitmap_reporter_),
+        video_frame_(video_frame)
+  {
+    DCHECK(shared_bitmap_reporter_);
+
+    SetUniqueId(video_frame_->unique_id(), 0);
+
+    if (!video_frame->GetBitmapId().IsZero()) {
+      return;
+    }
+
+    // There are native shared memory video frames but those have unsafe
+    // regions and we need an ro region here
+    shared_bitmap_reporter_->DidAllocateSharedBitmap(video_frame_->ro_shm_region()->Duplicate(),
+                                                     shared_bitmap_id_);
+
+    // The updater has a weak pointer factory so use that for generating
+    // the kill closure.
+    // Must however only use weak ptrs on src thread so attach appropriately
+    video_frame_->SetBitmapIdAndKillCB(shared_bitmap_id_,
+                                       BindToCurrentLoop(base::BindOnce(
+                                           &VideoResourceUpdater::DidDeleteSharedBitmap,
+                                           video_resource_updater->weak_ptr_factory_.GetWeakPtr(),
+                                           shared_bitmap_id_)));
+  }
+
+  ~SoftwarePlaneVideoFrameResource() override {}
+
+  void* pixels() override { return video_frame_->data(0); }
+
+  // Returns a memory dump GUID consistent across processes.
+  base::UnguessableToken GetSharedMemoryGuid() const override {
+    return video_frame_->shm_region()->GetGUID();
+  }
+
+  bool kill_me() const override {
+    return !has_refs();
+  }
+
+  bool overlay_candidate() const override { return true; }
+
+  uint32_t stride() const override { return video_frame_->stride(0); }
+
+  DISALLOW_COPY_AND_ASSIGN(SoftwarePlaneVideoFrameResource);
+};
+
+
 class VideoResourceUpdater::HardwarePlaneResource
     : public VideoResourceUpdater::PlaneResource {
  public:
@@ -394,7 +503,7 @@ class VideoResourceUpdater::HardwarePlan
   const gpu::Mailbox& mailbox() const { return mailbox_; }
 
   GLenum texture_target() const { return texture_target_; }
-  bool overlay_candidate() const { return overlay_candidate_; }
+  bool overlay_candidate() const override { return overlay_candidate_; }
 
  private:
   gpu::SharedImageInterface* SharedImageInterface() {
@@ -731,7 +840,7 @@ VideoResourceUpdater::PlaneResource* Vid
   if (software_compositor()) {
     DCHECK_EQ(format, viz::ResourceFormat::RGBA_8888);
 
-    all_resources_.push_back(std::make_unique<SoftwarePlaneResource>(
+    all_resources_.push_back(std::make_unique<SoftwarePlaneBitmapResource>(
         plane_resource_id, plane_size, shared_bitmap_reporter_));
   } else {
     all_resources_.push_back(std::make_unique<HardwarePlaneResource>(
@@ -880,6 +989,12 @@ VideoFrameExternalResources VideoResourc
   return external_resources;
 }
 
+static bool is_mmal_frame(const scoped_refptr<VideoFrame>& video_frame)
+{
+  return video_frame->format() == PIXEL_FORMAT_MMAL_BUFFER &&
+      video_frame->ro_shm_region() != nullptr;
+}
+
 VideoFrameExternalResources VideoResourceUpdater::CreateForSoftwarePlanes(
     scoped_refptr<VideoFrame> video_frame) {
   TRACE_EVENT0("cc", "VideoResourceUpdater::CreateForSoftwarePlanes");
@@ -889,6 +1004,7 @@ VideoFrameExternalResources VideoResourc
 
   // Only YUV and Y16 software video frames are supported.
   DCHECK(IsYuvPlanar(input_frame_format) ||
+         input_frame_format == PIXEL_FORMAT_MMAL_BUFFER ||
          input_frame_format == PIXEL_FORMAT_Y16);
 
   viz::ResourceFormat output_resource_format;
@@ -952,6 +1068,7 @@ VideoFrameExternalResources VideoResourc
           return false;
 
         return resource->resource_format() != output_resource_format ||
+               resource->kill_me() ||
                !base::Contains(outplane_plane_sizes, resource->resource_size());
       };
   base::EraseIf(all_resources_, can_delete_resource_fn);
@@ -959,11 +1076,37 @@ VideoFrameExternalResources VideoResourc
   // Recycle or allocate resources for each video plane.
   std::vector<PlaneResource*> plane_resources;
   plane_resources.reserve(output_plane_count);
-  for (size_t i = 0; i < output_plane_count; ++i) {
-    plane_resources.push_back(RecycleOrAllocateResource(
-        outplane_plane_sizes[i], output_resource_format, output_color_space,
-        video_frame->unique_id(), i));
-    plane_resources.back()->add_ref();
+  if (software_compositor() &&
+      is_mmal_frame(video_frame))
+  {
+//    LOG(INFO) << "Looking for id " << video_frame->unique_id();
+
+    // Check we don't already have unique_id.... Reuse if we do
+    PlaneResource* vf_resource = nullptr;
+    for (auto& resource : all_resources_) {
+      if (resource->Matches(video_frame->unique_id(), 0)) {
+        vf_resource = resource.get();
+        break;
+      }
+    }
+    // Build a new one if we don't
+    if (vf_resource == nullptr) {
+      all_resources_.push_back(std::make_unique<SoftwarePlaneVideoFrameResource>(
+         next_plane_resource_id_++, video_frame, this));
+      vf_resource = all_resources_.back().get();
+    }
+
+    plane_resources.push_back(vf_resource);
+    vf_resource->add_ref();
+  }
+  else
+  {
+    for (size_t i = 0; i < output_plane_count; ++i) {
+      plane_resources.push_back(RecycleOrAllocateResource(
+          outplane_plane_sizes[i], output_resource_format, output_color_space,
+          video_frame->unique_id(), i));
+      plane_resources.back()->add_ref();
+    }
   }
 
   VideoFrameExternalResources external_resources;
@@ -997,19 +1140,30 @@ VideoFrameExternalResources VideoResourc
         video_renderer_->Copy(video_frame, &canvas, nullptr);
       } else {
         HardwarePlaneResource* hardware_resource = plane_resource->AsHardware();
-        size_t bytes_per_row = viz::ResourceSizes::CheckedWidthInBytes<size_t>(
-            video_frame->coded_size().width(), viz::ResourceFormat::RGBA_8888);
-        size_t needed_size = bytes_per_row * video_frame->coded_size().height();
-        if (upload_pixels_size_ < needed_size) {
-          // Free the existing data first so that the memory can be reused,
-          // if possible. Note that the new array is purposely not initialized.
-          upload_pixels_.reset();
-          upload_pixels_.reset(new uint8_t[needed_size]);
-          upload_pixels_size_ = needed_size;
-        }
+        uint8_t * pixel_data;
+
+        // No point in converting if already ARGB
+        if (video_frame->format() != PIXEL_FORMAT_ARGB) {
+          size_t bytes_per_row = viz::ResourceSizes::CheckedWidthInBytes<size_t>(
+              video_frame->coded_size().width(), viz::ResourceFormat::RGBA_8888);
+          size_t needed_size = bytes_per_row * video_frame->coded_size().height();
+          if (upload_pixels_size_ < needed_size) {
+            // Free the existing data first so that the memory can be reused,
+            // if possible. Note that the new array is purposely not initialized.
+            upload_pixels_.reset();
+            upload_pixels_.reset(new uint8_t[needed_size]);
+            upload_pixels_size_ = needed_size;
 
-        PaintCanvasVideoRenderer::ConvertVideoFrameToRGBPixels(
-            video_frame.get(), upload_pixels_.get(), bytes_per_row);
+            pixel_data = upload_pixels_.get();
+          }
+
+          PaintCanvasVideoRenderer::ConvertVideoFrameToRGBPixels(
+              video_frame.get(), upload_pixels_.get(), bytes_per_row);
+        }
+        else
+        {
+          pixel_data = video_frame->data(0);
+        }
 
         // Copy pixels into texture.
         auto* gl = raster_context_provider_
@@ -1024,7 +1178,7 @@ VideoFrameExternalResources VideoResourc
           gl->TexSubImage2D(
               hardware_resource->texture_target(), 0, 0, 0, plane_size.width(),
               plane_size.height(), GLDataFormat(viz::ResourceFormat::RGBA_8888),
-              GLDataType(viz::ResourceFormat::RGBA_8888), upload_pixels_.get());
+              GLDataType(viz::ResourceFormat::RGBA_8888), pixel_data);
         }
       }
       plane_resource->SetUniqueId(video_frame->unique_id(), 0);
@@ -1038,6 +1192,8 @@ VideoFrameExternalResources VideoResourc
           software_resource->shared_bitmap_id(),
           software_resource->resource_size(),
           plane_resource->resource_format());
+      transferable_resource.is_overlay_candidate = software_resource->overlay_candidate();
+      transferable_resource.stride = software_resource->stride();
     } else {
       HardwarePlaneResource* hardware_resource = plane_resource->AsHardware();
       external_resources.type = VideoFrameResourceType::RGBA;
@@ -1230,6 +1386,11 @@ void VideoResourceUpdater::ReturnTexture
   video_frame->UpdateReleaseSyncToken(&client);
 }
 
+// Shim to reporter - useful for callback generation
+void VideoResourceUpdater::DidDeleteSharedBitmap(const viz::SharedBitmapId& id) const {
+  shared_bitmap_reporter_->DidDeleteSharedBitmap(id);
+}
+
 void VideoResourceUpdater::RecycleResource(uint32_t plane_resource_id,
                                            const gpu::SyncToken& sync_token,
                                            bool lost_resource) {
--- a/src/media/renderers/video_resource_updater.h
+++ b/src/media/renderers/video_resource_updater.h
@@ -132,6 +132,8 @@ class MEDIA_EXPORT VideoResourceUpdater
   class PlaneResource;
   class HardwarePlaneResource;
   class SoftwarePlaneResource;
+  class SoftwarePlaneBitmapResource;
+  class SoftwarePlaneVideoFrameResource;
 
   // A resource that will be embedded in a DrawQuad in the next CompositorFrame.
   // Each video plane will correspond to one FrameResource.
@@ -189,6 +191,8 @@ class MEDIA_EXPORT VideoResourceUpdater
                      const gpu::SyncToken& sync_token,
                      bool lost_resource);
 
+  void DidDeleteSharedBitmap(const viz::SharedBitmapId& id) const;
+
   // base::trace_event::MemoryDumpProvider implementation.
   bool OnMemoryDump(const base::trace_event::MemoryDumpArgs& args,
                     base::trace_event::ProcessMemoryDump* pmd) override;
--- a/src/media/video/gpu_memory_buffer_video_frame_pool.cc
+++ b/src/media/video/gpu_memory_buffer_video_frame_pool.cc
@@ -577,6 +577,11 @@ void GpuMemoryBufferVideoFramePool::Pool
 #endif
 
   bool passthrough = false;
+
+  // Copy isn't going to work if frame not mappable!
+  if (!video_frame->IsMappable())
+    passthrough = true;
+
 #if defined(OS_MACOSX)
   if (!IOSurfaceCanSetColorSpace(video_frame->ColorSpace()))
     passthrough = true;
--- /dev/null
+++ b/src/pi-util/BUILD.txt
@@ -0,0 +1,242 @@
+Build notes (cross compile from Ubuntu)
+=======================================
+
+Build from a patch
+------------------
+
+# Pick somewhere to put this
+cd ~
+mkdir chromium
+cd chromium
+# Get the build tools & put on path
+# You may want to add the path in .bashrc
+git clone https://chromium.googlesource.com/chromium/tools/depot_tools
+export PATH=$PATH:`pwd`/depot_tools
+# Get the main tree
+fetch chromium
+cd src
+# Checkout the version you want
+# * Fix version number
+git checkout 55.0.2883.99
+# Fix up any missing dependancies on the build m/c
+# * may well be unnecessary if you have built any other chrome
+./build/install-build-deps.sh
+./build/install-build-deps.sh --arm
+# Fetch & pull the other bits of the tree to sync.
+# As we are checking out a tag the --with_branch_heads is important
+gclient sync --with_branch_heads
+# Patch - should be completely clean if everything matchs
+# * Fix patch file to correct name / location
+cd ..
+patch -p1 < v55.0.2883.99.patch
+cd src
+# * Get a sysroot from somewhere and put it in build/linux/raspian_jessie_pi1-sysroot
+# * Example below is only if you have got an appropriate one lying around
+# * Otherwise follow sysroot instructions further down
+rsync -rl previous_location/raspian_jessie_pi1-sysroot build/linux/
+# Build output directories (out/armv6, out/armv7)
+# * This script currently assumes a sysroot of build/linux/raspian_jessie_pi1-sysroot
+#   so may need editing if you have put it elsewhere
+pi-util/gngen.py
+# Build chrome
+ninja -C out/armv6 chrome chrome_sandbox
+# Build armv7 ffmpeg
+ninja -C out/armv7 third_party/ffmpeg
+
+
+To run on a Pi
+--------------
+
+This requires a little installation.  The sandbox and ffmpeg shared libs
+need to be copied to the pi.  As neither is being tweaked much by me these
+steps should only be required if the underlying Chrome changes.  Otherwise
+you can just run out of the build directory (src/out/armv6)
+
+Assuming you can mount the build dir from the pi.
+
+# On the Pi NOT the build machine
+cd <path to build env>/src
+# Copy the ffmpeg libs
+pi-util/cplibs.sh
+# Copy the sandbox. BUILDTYPE tells the script where to get it from
+# This doesn't seem to be needed anymore with linux 4.9 and chrome 55
+BUILDTYPE=armv6 build/update-linux-sandbox.sh
+# Run chrome
+cd out/armv6
+./chrome
+
+
+Rebuilds
+--------
+
+In most cases a simple "ninja -C out/armv6 chrome" is all that is needed
+and the pi can run from out/armv6.
+
+To clean build "rm -rf out" and follow the build instructions from gngen.py
+
+
+Updating chromium from git
+--------------------------
+
+There is no script for this as the merges are prone to conflicts and it
+is much easier to sort them if you are doing stuff manually.
+
+If updating between major versions then mergeing tends to fail horribly
+so something along the lines of:
+
+# Remember where we are
+cat pi-util/pipaths.py
+OLDTAG=84...
+
+# Look for where we are going
+git tag -l "85.*"
+TAG=85...
+
+# * Make sure there are no updates required and no untracked files
+pi-util/gitscan.py status
+# Set rename limit to huge as files are moved around frequently and getting
+# git to track them is much easier than trying to do it ourselves
+git config diff.renameLimit 1000000
+
+# Tag source & make a patch file - patch file is useful when files are moved
+# as then git goes all unhelpful
+pi-util/settag.py -p mmal_3.29
+# As git stash will reset the brnch switch to a temp branch 1st
+pi-util/gitscan.py checkout -b stash/84/base
+pi-util/gitscan.py --gitscan-no-src reset {BASE}
+pi-util/gitscan.py --gitscan-no-src stash -u
+pi-util/gitscan.py --gitscan-no-src checkout {BASE}
+
+# Need to do src separately as the stash will lose pi-utils
+cat pi-util/pipaths.py
+git reset $OLDTAG
+git stash -u
+
+git checkout $TAG -b test/85/mmal_3
+
+# Clean out old objects
+rm -rf obj
+# Beware that git clean might kill our sub-repos so so don't do it unless we
+# are sure it won't
+# git clean -dxf
+
+### Do the "get environment" stages of a new build
+./build/install-build-deps.sh
+./build/install-build-deps.sh --arm
+# Fetch & pull the other bits of the tree to sync.
+# As we are checking out a tag the --with_branch_heads is important
+gclient sync -D --with_branch_heads
+
+# Start rebuild
+git stash pop
+
+# Fix pipaths & make new branches (now so we don't forget later)
+sed "s/src_commit=.*/src_commit=\"$TAG\"/" pi-util/pipaths.py | tee t
+mv t pi-util/pipaths.py && git add pi-util/pipaths.py
+chmod 0755 pi-util/*.py pi-util/*.sh
+pi-util/gitscan.py --gitscan-no-src checkout -b test/85/mmal_3
+
+### Fix conflicts (there will be some)
+
+# If building a separated ffmpeg .so (we are not not currrently) then
+# fix chrome major version for ffmpeg .so in pi-util/cplibs.sh and third_party//ffmpeg/BUILD.gn
+
+git commit
+### run through all other dirs we care about doing the same
+### Probably need to fix exec perms on pi-util scripts
+pi-util/syncroot.py <sysroot-ip>:
+pi-util/gngen.py
+### Fix up any new libpackage-dev that we need
+ninja ...
+### Fix up build disasters
+
+
+If updating within a major version mergeing seems to work reliably so my
+preferred method for achieving this goes:
+
+# Make sure everything is committed
+pi-util/gitscan.py status
+# Revert to base chromium checkout for old checkout
+pi-util/gitscan.py --gitscan-no-src checkout {BASE}
+# Merge new version into current base
+git fetch --all
+TAG=<new_tag>
+git merge $TAG
+# Fix conflicts - DEPS always seems to conflict
+git checkout $TAG -- DEPS
+# Update pi-util/pipaths.py to contain the new tag
+# Either commit now or later
+sed "s/src_commit=.*/src_commit=\"$TAG\"/" pi-util/pipaths.py | tee t
+mv t pi-util/pipaths.py && git add pi-util/pipaths.py
+git commit --no-edit
+# Get the rest of the tree
+gclient sync --with_branch_heads
+# Checkout our tree and merge the new base into it
+pi-util/gitscan.py --gitscan-no-src checkout test/83/mmal_3
+pi-util/gitscan.py --gitscan-no-src merge --no-edit {BASE}
+
+and we should be good to go.  At this point you can either clean build or
+not.  Chromes dependancy checks seem remarkably good so a simple build
+works nearly all the time.
+
+# Rebuild gn (clean)
+rm -rf out
+pi-util/gngen.py
+# Build release armv7 chrome (and any other targets you feel like)
+ninja -C out/armv7-rel chrome
+
+
+Sysroots (one time only)
+------------------------
+
+1st you will need to get the dev files for a bunch of libs on your pi (or
+if you can get the right files by magic on your cross-compile m/c then
+that is good too).  In src/pi-util there is a shell script
+pi-install-dev.sh which lists all the libs I think are needed along with a
+helpful apt-get install so all you should need to do is run it on an
+appropriate pi.
+
+Next the appropriate bits need to be copied to
+build/linux/<sysroot-name>-sysroot. We use raspian_stretch_pi1 as the
+sysroot name in these instructions and in the example script files so you
+might well find it easiest to use the same name too
+
+The script pi-util/syncroot.sh that will copy the needed bits of a root to
+the right place and then fix the full path symlinks to be relative.  It
+uses rsync to copy the files so the src can contain a machine name
+
+pi-util/syncroot.sh my-pi: raspian_stretch_pi1
+
+The "raspian_stretch_pi1" can be omitted and syncroot will choose the current
+default sysroot name.
+
+Beware that there are ~8 rsync statements so if the rsync is operating
+over ssh then you may need to type your password 8 times...  Note also
+that the script appends -sysroot to the given name so don't add that
+yourself!
+
+If the pi root is updated then this script can / should be rerun to update
+the sysroot.
+
+
+
+Other notes on the tree
+-----------------------
+
+The definitive list of expected repos is in pi-util/pipaths.py
+
+The script pi-util/gitscan.py will perform the same git op on all the
+repos that are in use in the current patch set.  It has substitutions
+of {PATH} and {BASE} for the path to the current repo and the chromium
+commit on which the current branch is based
+
+The current dev branch is test/57/mmal_2
+
+Status of optional neon by build file:
+skia/BUILD.gn:                     yes
+build/secondary/third_party/libjpeg_turbo/BUILD.gn: yes
+third_party/libwebp/BUILD.gn:      yes
+third_party/openmax_dl/dl/BUILD.gn unused
+third_party/libyuv/BUILD.gn:       yes
+third_party/libyuv/libyuv.gni:     yes
+third_party/pdfium/skia/BUILD.gn:  unused
--- /dev/null
+++ b/src/pi-util/README.txt
@@ -0,0 +1,118 @@
+Release notes
+=============
+
+This version should run with gpu-mem=64 with the default switches. Having
+said that this will only allow for 1 stream.  If you are playing >1 stream
+(even transiently) then you will need more (say gpu_mem=128) and you will
+need to set the --mmal-decoders option to the desired max number. The code
+should give up cleanly if it cannot allocate a h/w video decoder and give
+the stream to old-style ffmpeg decode, but as it stands in many cases it
+thinks it has allocated a decoder cleanly only to find that it fails when
+it tries to use it.
+
+Needs a current (buster 2019-06-07+) firmware/userland
+
+There are a few command-line switches - in general you shouldn't use
+them!
+
+
+Decode and resizer options
+--------------------------
+
+--mmal-decode-opaque     Set the decoder to use opaque frames between
+decoder and resizer.  This should be faster than i420 but doesn't work
+with old firmware.  This is the default with newer firmware (>=
+2016-11-01). (see --mmal-decode-i420)
+
+--mmal-decode-i420       Set the decoder to use I420 frames between
+decoder and resizer.  This generates an unnecessary conversion but works
+with all firmware.  This is the default with older firmware (<
+2016-11-01). (see --mmal-decode-opaque)
+
+--mmal-low-delay         Force "low-delay" mode on the decoder pipe.  This
+reduces the number of buffered ES frames before the decoder.  It isn't
+exactly low-delay but is definitely lower than otherwise.  May have a
+slight performance penalty and increase the risk of stuttering.  This mode
+will be automatically set by Chrome for some streams.
+
+--mmal-resize-isp        Use ISP resize rather than resizer.  Is noticably
+faster but requires --mmal-frame-copy or --mmal-zero-copy and newer
+firmware.  This is the default with newer firmware  (>= 2016-11-01) and
+enough gpu memory to support --mmal-frame-copy.
+
+--mmal-resize-resizer    Use resizer rather than ISP. Slower than ISP
+resize but supports older firmware and --mmal-slice-copy which may be
+needed if GPU memory is very limited (as will be the case on a Pi1 with a
+default setup).
+
+--mmal-resize-mode=NEVER|ALWAYS|SMALLER
+Sets resize behaviour.
+  NEVER    Output is the native size of the video
+  ALWAYS   Output allways attempts to match the size of the displayed picture
+           This is normally the fastest mode for SHM-RGB copy
+  SMALLER  Resize to smaller of native & display. This saves memory and is
+           the fastest for EGL output
+
+
+Copy-modes
+----------
+
+--mmal-copy-mode=<copy mode>
+
+This sets the output frame type & mmal->chrome copy mode. Current values
+for <copy mode> are:
+
+slice                   slowest - uses only a small amount of memory
+                        in the resizer
+
+<alloc>-<format>-<copy>
+  <alloc>
+    SHM      Frame allocated from shared memory
+    GPU      Frame allocated from gpu memory
+  <format>
+    YUV      3-plane I420
+    YC       2-plane I420 e.g. NV12
+    RGB      1-plane 4-byte RGBX
+  <copy>
+    COPY     Data copied on the ARM.  This should be slower than DMA but
+             sometimes give more performance at the expense of slightly
+	     higher ARM CPU usage
+    DMA      Data copied by firmware DMA to ARM buffers.
+    ZC       Data put directly into GPU buffer.  Fastest - only works
+             with EGL (needs vcsm-cma).
+
+Currently valid combinations are:
+
+SHM-YUV-DMA
+SHM-YC-DMA
+SHM-RGB-DMA
+SHM-RGB-COPY  Default for non-gpu operation
+GPU-RGB-DMA
+GPU-RGB-ZC
+GPU-YUV-COPY
+GPU-YUV-ZC    Default for EGL operation
+
+
+Misc options
+------------
+
+--enable-logging=stderr This is a standard option for chrome but worth
+noting as the mmal code will print out its interpretation of the command
+line options passed to it along with how much GPU memory it has detected
+and the firmware date.
+
+--pi-patch-version       Print out the versions of Chromium and Pi
+patches.  Chrome will then terminate
+
+--mmal-decoders=<n>      Set the number of mmal decoders we wil try to
+create simultainiously. Default=1. If this number is exceeded then decoder
+init will fail and chrome will fallback to ffmpeg decode.  There is no
+panalty for setting this to a large number if you wish to have "unlimited"
+decoders.  However if it is set too big and there isn't the gpu mem to
+satisfy the requirements of the decode it may fail cleanly and revert to
+software (ffmpeg) decode or init may appear to succeed and decode then
+fails in an undefined manner.
+
+--mmal-frame-buffers=<n> Set the number of gpu "frame" buffers.
+Change with care.
+
--- /dev/null
+++ b/src/pi-util/cplibs.sh
@@ -0,0 +1,19 @@
+set -e
+
+FFNAME=libffmpeg_chrome.so.66
+LIBROOT=/usr/lib/arm-linux-gnueabihf
+
+if [ ! -d $LIBROOT ]; then
+  echo Can\'t find $LIBROOT
+  echo Are you sure you are running this on a Pi?
+  exit 1
+fi
+
+echo Copying $FFNAME from armv6/7 to $LIBROOT/...
+
+cp out/armv7/$FFNAME /tmp
+sudo cp /tmp/$FFNAME $LIBROOT/neon/vfp
+cp out/armv6/$FFNAME /tmp
+sudo cp /tmp/$FFNAME $LIBROOT
+
+
--- /dev/null
+++ b/src/pi-util/defargs_armv6.gn
@@ -0,0 +1,32 @@
+# See "gn args <out_dir> --list" for available build arguments.
+target_cpu = "arm"
+target_os = "linux"
+
+arm_float_abi = "hard"
+arm_use_neon = false
+arm_optionally_use_neon = false
+arm_version = 6
+arm_use_thumb = false
+arm_arch = "armv6z"
+
+# Separate out so we can have both arm v6 & v7 versions
+#is_component_ffmpeg = true
+
+# tcmalloc doesn't like armv6 by default
+#use_allocator = "none"
+
+# Pulse deprecated on Pi
+use_pulseaudio = false
+rtc_use_pipewire = false
+
+# Could use system libjpeg but go with chromiums version
+# use_system_libjpeg = true
+#use_libjpeg_turbo = true
+
+# We want H.264 in ffmpeg
+ffmpeg_branding = "Chrome"
+proprietary_codecs = true
+
+# This crashes the compiler!
+rtc_use_h264 = false
+
--- /dev/null
+++ b/src/pi-util/defargs_armv7.gn
@@ -0,0 +1,24 @@
+# Build arguments go here. Examples:
+#   is_component_build = true
+#   is_debug = false
+# See "gn args <out_dir> --list" for available build arguments.
+target_cpu = "arm"
+target_os = "linux"
+
+arm_float_abi = "hard"
+arm_use_neon = true
+# We have lib issues if we enable thumb
+arm_use_thumb = false
+arm_optionally_use_neon = false
+arm_version = 7
+arm_arch = "armv7-a"
+
+# Pulse deprecated on Pi
+use_pulseaudio = false
+#rtc_use_pipewire = false
+
+#is_component_ffmpeg = true
+# tcmalloc doesn't like armv6 by default
+#use_allocator = "none"
+ffmpeg_branding = "Chrome"
+proprietary_codecs = true
--- /dev/null
+++ b/src/pi-util/dodiff.py
@@ -0,0 +1,35 @@
+#!/usr/bin/env python
+
+import os, sys, string, subprocess
+
+# Local
+import gitscan, pipaths
+
+def doscan(outfile = sys.stdout):
+    revdict = gitscan.revdict()
+
+    cpath = gitscan.basepath()
+
+    for p in pipaths.pipaths:
+        os.chdir(os.path.join(cpath, p))
+        diff = subprocess.check_output(["git", "diff", revdict[p]])
+
+        header = False
+        lines = diff.split("\n")
+        # Remove terminal blank line
+        if lines[-1] == "":
+            lines.pop()
+        for line in lines:
+            if line.startswith("diff --git "):
+                header = True
+            if header:
+                line = string.replace(line, " a/", " a/" + p + "/")
+                line = string.replace(line, " b/", " b/" + p + "/")
+            if line.startswith("+++ "):
+                header = False
+            print >> outfile, line
+
+
+if __name__ == '__main__':
+    doscan()
+
--- /dev/null
+++ b/src/pi-util/gitscan.py
@@ -0,0 +1,69 @@
+#!/usr/bin/env python
+
+import os, string, subprocess, sys
+
+# Local
+import pipaths
+
+def revdict():
+    revdict = {'src':pipaths.src_commit}
+    stuff = subprocess.check_output(["gclient", "revinfo"])
+    for line in stuff.split("\n"):
+        pathn = line.find(":")
+        commitn = line.rfind("@")
+        if pathn != -1 and commitn != -1 :
+             revdict[line[:pathn]] = line[commitn+1:]
+    return revdict
+
+def basepath():
+    cpath = os.getcwd()
+    if not cpath.endswith("/src"):
+        raise "CWD doesn't end with /src"
+
+    return cpath[:-4]
+
+def gitscan(args, nosrc = False, quiet=False):
+    rv = 0
+
+    oldcwd = os.getcwd()
+    rdict = revdict()
+    cpath = basepath()
+
+    for p in pipaths.pipaths:
+        if nosrc and p == "src":
+            continue
+
+        os.chdir(os.path.join(cpath, p))
+
+        gitargs = [string.replace(string.replace(a, "{PATH}", p), "{BASE}", rdict[p]) for a in args]
+        gitargs[0:0] = ["git"]
+
+        if not quiet:
+            print ">>>", p
+
+        rv = subprocess.call(gitargs)
+        if rv != 0:
+            if not quiet:
+                print "Git returned non-zero error code", rv, "\ncwd =", os.getcwd(), "\ncmd =", gitargs
+            break
+
+    os.chdir(oldcwd)
+    return rv
+
+
+if __name__ == '__main__':
+
+    if len(sys.argv) < 2:
+        print "Usage: gitscan [--gitscan-no-src] <git cmd>"
+        print "  substitutes {PATH} and {BASE}"
+        exit(0)
+
+    nosrc = False
+
+    if sys.argv[1] == "--gitscan-no-src":
+        nosrc = True
+        del sys.argv[1]
+
+    gitscan(sys.argv[1:], nosrc)
+
+
--- /dev/null
+++ b/src/pi-util/gngen.py
@@ -0,0 +1,69 @@
+#!/usr/bin/env python
+
+import os, ast, fileinput, subprocess, sys
+
+def docopy(name, vars, is_debug=False, is_ozone=False):
+    dir_suffix = ""
+    deb_str = "false"
+
+    if is_ozone:
+        ozone_str = "true"
+        dir_suffix = dir_suffix + "-ozone"
+    else:
+        ozone_str = "false"
+
+    if is_debug:
+        deb_str = "true"
+        dir_suffix = dir_suffix + "-deb"
+    else:
+        deb_str = "false"
+        dir_suffix = dir_suffix + "-rel"
+
+
+    dest_dir = os.path.join("out", name + dir_suffix)
+    src_file = os.path.join("pi-util", "defargs_" + name + ".gn")
+
+    # Ignore any errors making dir (in particular it already exists)
+    try:
+        os.makedirs(dest_dir)
+    except:
+        pass
+
+    dargs = open(os.path.join(dest_dir, "args.gn"), "wt")
+    dargs.write('# -- copied from: ' + src_file + '\n')
+
+    for line in fileinput.input(src_file):
+        dargs.write(line)
+
+    dargs.write('# -- created by ' + sys.argv[0] + '\n')
+    dargs.write('is_debug = ' + deb_str + '\n')
+    dargs.write('use_ozone = ' + ozone_str + '\n')
+    if is_ozone:
+        dargs.write('ozone_platform_x11 = true\n')
+    dargs.write('target_sysroot = "' + vars["target_sysroot"] + '"\n')
+    dargs.write('google_api_key = "' + vars["google_api_key"] + '"\n')
+    dargs.write('google_default_client_id = "' + vars["google_default_client_id"] + '"\n')
+    dargs.write('google_default_client_secret = "' + vars["google_default_client_secret"] + '"\n')
+
+    dargs.close()
+
+    subprocess.check_call(["gn", "gen", dest_dir])
+
+
+if __name__ == '__main__':
+    gyp_vars = {}
+    gypi = os.path.join(os.environ["HOME"], ".gyp", "include.gypi")
+    if os.path.isfile(gypi):
+        print "Importing from:", gypi
+        gyps = open(gypi).read(-1)
+        gyp_vars = ast.literal_eval(gyps)["variables"]
+
+    gyp_vars["target_sysroot"] = os.path.abspath("build/linux/raspian_stretch_pi1-sysroot")
+
+    docopy("armv6", gyp_vars)
+    docopy("armv7", gyp_vars)
+    docopy("armv7", gyp_vars, is_debug=True)
+    docopy("armv7", gyp_vars, is_ozone=True)
+
+
+
--- /dev/null
+++ b/src/pi-util/pi-install-dev.sh
@@ -0,0 +1,50 @@
+# Install set to build appropriate root on a clean pi
+
+APT=aptitude
+#APT=apt-get
+
+sudo $APT install \
+comerr-dev \
+libasound2-dev \
+libatk1.0-dev \
+libatk-bridge2.0-dev \
+libcap-dev \
+libcups2-dev \
+libexif-dev \
+libffi-dev \
+libgconf2-dev \
+libgl1-mesa-dev \
+libgtk-3-dev \
+libjpeg-dev \
+libkrb5-dev \
+libnspr4-dev \
+libnss3-dev \
+libpam0g-dev \
+libpango1.0-dev \
+libpci-dev \
+libpcre3-dev \
+libpipewire-0.2-dev \
+libssl-dev \
+libudev-dev \
+libxcb1-dev \
+libxcb-dri3-dev \
+libxcb-shm0-dev \
+libxcb-image0-dev \
+libxss-dev \
+libxt-dev \
+libxtst-dev \
+mesa-common-dev \
+python-xcbgen \
+uuid-dev \
+xcb-proto
+
+echo Also need python-xcbgen on host
+
+# Pulse (hopefully) disabled
+# libpulse-dev \
+
+# Obviously replace paths appropriately below
+# Now run pi-util/syncroot.sh on the compile m/c to grab the appropriate
+# bits of the root and fix up the paths.
+# e.g. ON COMPILE M/C in src dir:
+# pi-util/syncroot.sh my-pi: raspian_jessie_pi1
--- /dev/null
+++ b/src/pi-util/pipaths.py
@@ -0,0 +1,10 @@
+pipaths=[
+    "src",
+    "src/native_client",
+    "src/third_party/ffmpeg",
+    "src/third_party/libjpeg_turbo",
+    "src/third_party/libyuv",
+    "src/third_party/skia"]
+
+# Our base tag or commit no
+src_commit="84.0.4147.141"
--- /dev/null
+++ b/src/pi-util/pipewire_utils_h.patch
@@ -0,0 +1,11 @@
+--- a/build/linux/raspian_stretch_pi1-sysroot/usr/include/pipewire/utils.h
++++ b/build/linux/raspian_stretch_pi1-sysroot/usr/include/pipewire/utils.h
+@@ -52,7 +52,7 @@ static inline struct spa_pod *
+ pw_spa_pod_copy(const struct spa_pod *pod)
+ {
+ 	size_t size;
+-	struct spa_pod *c;
++	void *c;
+ 
+ 	if (pod == NULL)
+ 		return NULL;
--- /dev/null
+++ b/src/pi-util/rebase_liblinks.py
@@ -0,0 +1,37 @@
+#!/usr/bin/env python
+
+import os, sys
+from stat import *
+
+def walktree(top, callback, n, prefix):
+    '''recursively descend the directory tree rooted at top,
+       calling the callback function for each regular file'''
+
+    for f in os.listdir(top):
+        pathname = os.path.join(top, f)
+        mode = os.lstat(pathname).st_mode
+        if S_ISDIR(mode):
+            # It's a directory, recurse into it
+            walktree(pathname, callback, n+1, prefix)
+        elif S_ISLNK(mode):
+            # It's a file, call the callback function
+            callback(pathname, os.readlink(pathname), n, prefix)
+
+def visitfile(file, linkname, n, prefix):
+    if (linkname.startswith(prefix + 'lib/')):
+        newlink = "../" * n + linkname[len(prefix):]
+        print 'relinking', file, "->", newlink
+        os.remove(file)
+        os.symlink(newlink, file)
+
+if __name__ == '__main__':
+    argc = len(sys.argv)
+    if argc == 2:
+        walktree(sys.argv[1], visitfile, 0, "/")
+    elif argc == 3:
+        walktree(sys.argv[1], visitfile, 0, sys.argv[2])
+    else:
+        print "rebase_liblinks.py <local root> [<old sysroot>]"
+
+
+
--- /dev/null
+++ b/src/pi-util/settag.py
@@ -0,0 +1,60 @@
+#!/usr/bin/env python
+
+import sys, os, subprocess
+
+# Local
+import pipaths
+import gitscan
+import dodiff
+import argparse
+
+def set_version(verstr):
+    pathname = "components/version_info/pi_patch_version_values.h"
+
+    with open(pathname, "wt") as f:
+        f.write("// Pi patch version - generated by pi-util/settag.py\n")
+        f.write('#define PI_PATCH_VERSION_STRING "' + verstr + '"\n')
+
+    subprocess.check_call(["git", "add", pathname])
+    subprocess.check_call(["git", "commit", "-m", "Update pi patch version to " + verstr])
+
+
+def set_tag(verstr):
+    newtag = "pi/" + pipaths.src_commit + "/" + verstr
+    print "Setting tag: " + newtag
+    if gitscan.gitscan(["tag", newtag], quiet=True) != 0:
+        print "Tagging failed"
+        sys.exit(1)
+
+def set_tag_and_version(verstr):
+    set_version(verstr)
+    set_tag(verstr)
+
+if __name__ == '__main__':
+    argp = argparse.ArgumentParser(
+        description="Sets version info in pi_patch_version_values & tags source tree with it")
+    argp.add_argument("-p", action='store_true', help="Generate patch file")
+    argp.add_argument("verstr", help="Pi patch version string")
+    args = argp.parse_args()
+
+    patchpath = os.path.join("..", "v" + pipaths.src_commit + "_" + args.verstr + ".patch")
+
+    if args.p and os.path.exists(patchpath):
+        print "Patchfile", patchpath, "already exists"
+        sys.exit(1)
+
+    print "-- Checking all committed"
+    if gitscan.gitscan(["diff", "--name-status", "--exit-code"], quiet=True) != 0:
+        print "Status check failed - commit everything and try again"
+        sys.exit(1)
+
+    print "-- Generating & committing pi_patch_version_values.h"
+    set_version(args.verstr)
+    print "-- Generating tags"
+    set_tag(args.verstr)
+
+    if args.p:
+        print "-- Generating patch file: ", patchpath
+        with open(patchpath, "wt") as f:
+            dodiff.doscan(f)
+
--- /dev/null
+++ b/src/pi-util/syncroot.sh
@@ -0,0 +1,54 @@
+set -e
+
+if [ "$1" == "" ]; then
+  echo Usage: $0 \<src_dir\> [\<rootname\>]
+  echo src_dir is a source for rsync so may contain m/c name.
+  echo rootname will be set to \"raspian_stretch_pi1\" if missing
+  echo e.g.: pi-util/syncroot.sh my-pi: raspian_stretch_pi1
+  exit 1
+fi
+
+SYSROOT_NAME=$2
+if [ "$SYSROOT_NAME" == "" ]; then
+  SYSROOT_NAME=raspian_stretch_pi1
+fi
+
+DST_ROOT=`gclient root`
+DST=$DST_ROOT/src/build/linux/$SYSROOT_NAME-sysroot
+SRC=$1
+
+if [ ! -d $DST_ROOT/src/build/linux ]; then
+  echo We don\'t appear to be in a Chrome build tree
+  exit 1
+fi
+
+echo Sync src:  $SRC
+echo Sync dest: $DST
+
+mkdir -p $DST/lib
+mkdir -p $DST/opt/vc/include
+mkdir -p $DST/usr/lib/pkgconfig
+mkdir -p $DST/usr/bin
+mkdir -p $DST/usr/share
+
+#### MUST NOT include /opt/vc/include/*GL*
+# Creates conflicts with GL includes inside Chrome
+
+rsync -rl $SRC/lib/arm-linux-gnueabihf $DST/lib
+rsync -rl $SRC/opt/vc/lib $DST/opt/vc
+rsync -rl $SRC/opt/vc/include/interface $DST/opt/vc/include
+rsync -rl $SRC/usr/lib/arm-linux-gnueabihf $DST/usr/lib
+rsync -rl $SRC/usr/lib/gcc $DST/usr/lib
+rsync -rl $SRC/usr/include $DST/usr
+rsync -rl $SRC/usr/share/pkgconfig $DST/usr/share
+rsync -rl $SRC/usr/share/xcb $DST/usr/share
+#rsync -rl $SRC/usr/bin/cups-config $DST/usr/bin
+
+# Fix up pipewire issue
+sed 's/struct spa_pod \*c/void \* c/' < $DST/usr/include/pipewire/utils.h > u.h
+mv u.h $DST/usr/include/pipewire/utils.h
+
+cd $DST/usr/lib/pkgconfig
+ln -sf ../arm-linux-gnueabihf/pkgconfig/* .
+cd ../../../../../..
+pi-util/rebase_liblinks.py $DST
--- a/src/services/service_manager/sandbox/linux/bpf_gpu_policy_linux.cc
+++ b/src/services/service_manager/sandbox/linux/bpf_gpu_policy_linux.cc
@@ -58,6 +58,19 @@ ResultExpr GpuProcessPolicy::EvaluateSys
     // (MAP_LOCKED | MAP_EXECUTABLE | MAP_32BIT)
     case __NR_mmap:
 #endif
+#ifdef USE_X11
+    // Wanted for shm generation for ImageX11
+    case __NR_memfd_create:
+
+    // Wanted for MESA to fire up happily
+    // *** Should almost certainly arrange for the offending setup
+    //     to happen before sandbox is applied but I can't work out
+    //     what is needed
+    // Alternatively --in-process-gpu fixes the issue
+    case __NR_readlink:  // 85
+    case __NR_stat64:    // 195
+    case __NR_openat:    // 322 --- This one is clearly bad!
+#endif
     // We also hit this on the linux_chromeos bot but don't yet know what
     // weird flags were involved.
     case __NR_mprotect:
--- a/src/services/service_manager/sandbox/linux/bpf_renderer_policy_linux.cc
+++ b/src/services/service_manager/sandbox/linux/bpf_renderer_policy_linux.cc
@@ -27,6 +27,8 @@ struct local_dma_buf_sync {
   _IOW(LOCAL_DMA_BUF_BASE, 0, struct local_dma_buf_sync)
 
 using sandbox::SyscallSets;
+using sandbox::bpf_dsl::If;
+using sandbox::bpf_dsl::AnyOf;
 using sandbox::bpf_dsl::Allow;
 using sandbox::bpf_dsl::Arg;
 using sandbox::bpf_dsl::Error;
@@ -36,14 +38,18 @@ namespace service_manager {
 
 namespace {
 
+#define ISMAGIC(r, x) (((r) & (_IOC_TYPEMASK << _IOC_TYPESHIFT)) == ((x) << _IOC_TYPESHIFT))
+
 ResultExpr RestrictIoctl() {
   const Arg<unsigned long> request(1);
-  return Switch(request)
+  // Pi - allow all VCHIQ ioctls and the VMCS_SM ioctls and VCSM ioctls too
+  return If(AnyOf(ISMAGIC(request, 0xc4), ISMAGIC(request, 'I'), ISMAGIC(request, 'J')), Allow()).Else(
+    Switch(request)
       .SANDBOX_BPF_DSL_CASES((static_cast<unsigned long>(TCGETS), FIONREAD),
                              Allow())
       .SANDBOX_BPF_DSL_CASES(
           (static_cast<unsigned long>(LOCAL_DMA_BUF_IOCTL_SYNC)), Allow())
-      .Default(sandbox::CrashSIGSYSIoctl());
+      .Default(sandbox::CrashSIGSYSIoctl()));
 }
 
 }  // namespace
--- a/src/services/service_manager/sandbox/linux/sandbox_linux.h
+++ b/src/services/service_manager/sandbox/linux/sandbox_linux.h
@@ -61,6 +61,8 @@ class SERVICE_MANAGER_SANDBOX_EXPORT San
     DEPRECATED_METHOD_GET_STYLE_FOR_STRIKE,
     METHOD_MAKE_SHARED_MEMORY_SEGMENT,
     DEPRECATED_METHOD_MATCH_WITH_FALLBACK,
+    METHOD_OPEN_DEV_VCHIQ,
+    METHOD_OPEN_DEV_VCSM,
   };
 
   // These form a bitmask which describes the conditions of the Linux sandbox.
--- a/src/services/viz/public/cpp/compositing/transferable_resource_mojom_traits.cc
+++ b/src/services/viz/public/cpp/compositing/transferable_resource_mojom_traits.cc
@@ -33,6 +33,7 @@ bool StructTraits<viz::mojom::Transferab
   out->is_backed_by_surface_texture = data.is_backed_by_surface_texture();
   out->wants_promotion_hint = data.wants_promotion_hint();
 #endif
+  out->stride = data.stride();
   return true;
 }
 
--- a/src/services/viz/public/cpp/compositing/transferable_resource_mojom_traits.h
+++ b/src/services/viz/public/cpp/compositing/transferable_resource_mojom_traits.h
@@ -82,6 +82,9 @@ struct StructTraits<viz::mojom::Transfer
       const viz::TransferableResource& resource) {
     return resource.ycbcr_info;
   }
+  static uint32_t stride(const viz::TransferableResource& resource) {
+    return resource.stride;
+  }
 
   static bool Read(viz::mojom::TransferableResourceDataView data,
                    viz::TransferableResource* out);
--- a/src/services/viz/public/mojom/compositing/compositor_frame_sink.mojom
+++ b/src/services/viz/public/mojom/compositing/compositor_frame_sink.mojom
@@ -112,4 +112,8 @@ interface CompositorFrameSinkClient {
 
   // Returns resources sent to SubmitCompositorFrame to be reused or freed.
   ReclaimResources(array<ReturnedResource> resources);
+
+  // Frame resized - if we can resize the video to this we should get away
+  // without later resizing
+  DidStretchFrame(uint32 width, uint32 height);
 };
--- a/src/services/viz/public/mojom/compositing/transferable_resource.mojom
+++ b/src/services/viz/public/mojom/compositing/transferable_resource.mojom
@@ -48,4 +48,5 @@ struct TransferableResource {
   bool wants_promotion_hint;
   gfx.mojom.ColorSpace color_space;
   gpu.mojom.VulkanYCbCrInfo ? ycbcr_info;
+  uint32 stride;
 };
--- a/src/third_party/blink/renderer/platform/graphics/begin_frame_provider.h
+++ b/src/third_party/blink/renderer/platform/graphics/begin_frame_provider.h
@@ -58,6 +58,7 @@ class PLATFORM_EXPORT BeginFrameProvider
       const WTF::Vector<viz::ReturnedResource>& resources) final {
     NOTIMPLEMENTED();
   }
+  void DidStretchFrame(uint32_t width, uint32_t height) override {}
 
   // viz::mojom::blink::EmbeddedFrameSinkClient implementation.
   void BindSurfaceEmbedder(
--- a/src/third_party/blink/renderer/platform/graphics/canvas_resource_dispatcher.h
+++ b/src/third_party/blink/renderer/platform/graphics/canvas_resource_dispatcher.h
@@ -79,6 +79,7 @@ class PLATFORM_EXPORT CanvasResourceDisp
   void OnBeginFramePausedChanged(bool paused) final {}
   void ReclaimResources(
       const WTF::Vector<viz::ReturnedResource>& resources) final;
+  void DidStretchFrame(uint32_t width, uint32_t height) override {}
 
   void DidAllocateSharedBitmap(base::ReadOnlySharedMemoryRegion region,
                                const gpu::Mailbox& id);
--- a/src/third_party/blink/renderer/platform/graphics/video_frame_submitter.cc
+++ b/src/third_party/blink/renderer/platform/graphics/video_frame_submitter.cc
@@ -288,6 +288,11 @@ void VideoFrameSubmitter::DidDeleteShare
   compositor_frame_sink_->DidDeleteSharedBitmap(id);
 }
 
+void VideoFrameSubmitter::DidStretchFrame(uint32_t width, uint32_t height) {
+  if (video_frame_provider_)
+    video_frame_provider_->DidStretchFrame(width, height);
+}
+
 void VideoFrameSubmitter::OnReceivedContextProvider(
     bool use_gpu_compositing,
     scoped_refptr<viz::RasterContextProvider> context_provider) {
--- a/src/third_party/blink/renderer/platform/graphics/video_frame_submitter.h
+++ b/src/third_party/blink/renderer/platform/graphics/video_frame_submitter.h
@@ -80,6 +80,7 @@ class PLATFORM_EXPORT VideoFrameSubmitte
   void OnBeginFramePausedChanged(bool paused) override {}
   void ReclaimResources(
       const WTF::Vector<viz::ReturnedResource>& resources) override;
+  void DidStretchFrame(uint32_t width, uint32_t height) override;
 
   // viz::SharedBitmapReporter implementation.
   void DidAllocateSharedBitmap(base::ReadOnlySharedMemoryRegion,
--- a/src/third_party/libdrm/BUILD.gn
+++ b/src/third_party/libdrm/BUILD.gn
@@ -52,6 +52,7 @@ static_library("libdrm") {
     # glibc-2.24.  This causes a build error when using the Debian
     # Stretch sysroot.
     "-Wno-deprecated-declarations",
+    "-DMAJOR_IN_SYSMACROS=1",
   ]
 
   public_configs = [ ":libdrm_config" ]
--- a/src/ui/accessibility/platform/ax_platform_node_auralinux.cc
+++ b/src/ui/accessibility/platform/ax_platform_node_auralinux.cc
@@ -190,9 +190,11 @@ bool SupportsAtkComponentScrollingInterf
   return dlsym(RTLD_DEFAULT, "atk_component_scroll_to_point");
 }
 
+#if 0
 bool SupportsAtkTextScrollingInterface() {
   return dlsym(RTLD_DEFAULT, "atk_text_scroll_substring_to_point");
 }
+#endif
 
 AtkObject* FindAtkObjectParentFrame(AtkObject* atk_object) {
   AXPlatformNodeAuraLinux* node =
--- a/src/ui/android/delegated_frame_host_android.h
+++ b/src/ui/android/delegated_frame_host_android.h
@@ -121,6 +121,8 @@ class UI_ANDROID_EXPORT DelegatedFrameHo
   void SetTopControlsVisibleHeight(float height);
 
  private:
+  void DidStretchFrame(uint32_t width, uint32_t height) override {}
+
   // viz::HostFrameSinkClient implementation.
   void OnFirstSurfaceActivation(const viz::SurfaceInfo& surface_info) override;
   void OnFrameTokenChanged(uint32_t frame_token) override;
--- a/src/ui/base/x/x11_software_bitmap_presenter.h
+++ b/src/ui/base/x/x11_software_bitmap_presenter.h
@@ -40,6 +40,9 @@ class COMPONENT_EXPORT(UI_BASE_X) X11Sof
   void EndPaint(const gfx::Rect& damage_rect);
   void OnSwapBuffers(SwapBuffersCallback swap_ack_callback);
   int MaxFramesPending() const;
+  gfx::AcceleratedWidget GetAcceleratedWidget() const {
+    return widget_;
+  }
 
  private:
   // Draw |data| over |widget|'s parent-relative background, and write the
--- a/src/ui/gfx/BUILD.gn
+++ b/src/ui/gfx/BUILD.gn
@@ -3,6 +3,7 @@
 # found in the LICENSE file.
 
 import("//build/config/jumbo.gni")
+import("//build/config/sysroot.gni")
 import("//build/config/ui.gni")
 import("//device/vr/buildflags/buildflags.gni")
 import("//testing/libfuzzer/fuzzer_test.gni")
@@ -578,6 +579,21 @@ jumbo_source_set("memory_buffer_sources"
     ]
 
     deps += [ "//build/config/linux/libdrm" ]
+
+    # Really should have some sort of global enable_mmal switch
+    if (current_cpu == "arm") {
+      sources += [
+        "linux/native_pixmap_vcsm.cc",
+        "linux/native_pixmap_vcsm.h"
+      ]
+
+      include_dirs = [
+        "$target_sysroot/opt/vc/include",
+        "$target_sysroot/opt/vc/include/interface/vcos/pthreads",
+        "$target_sysroot/opt/vc/include/interface/vmcs_host/linux",
+      ]
+      public_configs = [ "//build/config/linux:use_mmal" ]
+    }
   }
 
   if (is_linux || is_android) {
--- /dev/null
+++ b/src/ui/gfx/linux/native_pixmap_vcsm.cc
@@ -0,0 +1,324 @@
+#include "ui/gfx/linux/native_pixmap_vcsm.h"
+
+#include "base/posix/eintr_wrapper.h"
+#include "ui/gfx/buffer_format_util.h"
+
+extern "C" {
+#include <fcntl.h>
+#include <interface/vcsm/user-vcsm.h>
+}
+
+#if RPI_PIXMAP_VCSM
+
+namespace gfx {
+
+class NativePixmapVCSM : public NativePixmap
+{
+  static std::vector<NativePixmapPlane>
+  BuildPlanes(const gfx::Size& size, gfx::BufferFormat format, base::ScopedFD fd)
+  {
+    std::vector<NativePixmapPlane> npp;
+
+    // Make sure that our geometry matches what the rest of the world is
+    // expecting - so use common util functions for info
+    // Build planes to keep a copy
+    const size_t plane_count = NumberOfPlanesForLinearBufferFormat(format);
+    size_t offset = 0;
+
+    for (size_t i = 0; i != plane_count; ++i) {
+      size_t pitch = RowSizeForBufferFormat(size.width(), format, i);
+      size_t next_offset = i + 1 >= plane_count ?
+        BufferSizeForBufferFormat(size, format) :
+        BufferOffsetForBufferFormat(size, format, i + 1);
+
+      npp.emplace_back(
+          pitch, offset, next_offset - offset, i == 0 ? std::move(fd) : base::ScopedFD());
+
+      offset = next_offset;
+    }
+    return npp;
+  }
+
+public:
+  NativePixmapVCSM(const gfx::Size& size,
+                     gfx::BufferFormat format,
+                     uint64_t modifier,
+                     base::ScopedFD fd) :
+    size_(size),
+    format_(format),
+    modifier_(modifier),
+    planes_(BuildPlanes(size, format, std::move(fd)))
+  {
+  }
+
+  // Assume that this is an import of a handle we exported
+  NativePixmapVCSM(const gfx::Size& size,
+                     gfx::BufferFormat format,
+                     uint64_t modifier,
+                     gfx::NativePixmapHandle&& handle) :
+    size_(size),
+    format_(format),
+    modifier_(modifier),
+    planes_(BuildPlanes(size, format, std::move(handle.planes.front().fd)))
+  {
+  }
+
+  // NativePixmap:
+  bool AreDmaBufFdsValid() const override
+  {
+    if (planes_.empty())
+      return false;
+
+    // Must have a good fd on plane 0
+    if (!planes_.front().fd.is_valid())
+      return false;
+    return true;
+  }
+
+  int GetDmaBufFd(size_t plane) const override {
+    return planes_.front().fd.get();
+  }
+
+  uint32_t GetDmaBufPitch(size_t plane) const override {
+    DCHECK_LT(plane, planes_.size());
+    return planes_[plane].stride;
+  }
+
+  size_t GetDmaBufOffset(size_t plane) const override {
+    DCHECK_LT(plane, planes_.size());
+    return planes_[plane].offset;
+  }
+
+  size_t GetDmaBufPlaneSize(size_t plane) const override {
+    DCHECK_LT(plane, planes_.size());
+    return planes_[plane].size;
+  }
+
+  // Return the number of non-interleaved "color" planes.
+  size_t GetNumberOfPlanes() const override {
+    return planes_.size();
+  }
+
+  gfx::BufferFormat GetBufferFormat() const override {
+    return format_;
+  }
+
+  uint64_t GetBufferFormatModifier() const override {
+    // ***** What no plane?
+    return modifier_;
+  }
+
+  gfx::Size GetBufferSize() const override {
+    return size_;
+  }
+
+  uint32_t GetUniqueId() const override {
+    LOG(INFO) << __func__;
+    return 0;
+  }
+
+  bool ScheduleOverlayPlane(gfx::AcceleratedWidget widget,
+                            int plane_z_order,
+                            gfx::OverlayTransform plane_transform,
+                            const gfx::Rect& display_bounds,
+                            const gfx::RectF& crop_rect,
+                            bool enable_blend,
+                            std::unique_ptr<gfx::GpuFence> gpu_fence) override {
+    return false;
+  }
+
+  gfx::NativePixmapHandle ExportHandle() override
+  {
+    gfx::NativePixmapHandle ph;
+    // The rest of the pixmap handle code is expecting a valid fd on every plane
+    // so we have to generate dups for all planes.  This is much simpler than
+    // trying to make the rest of the code cope with fewer fds
+    ph.modifier = modifier_;
+    for (const auto& plane : planes_) {
+      ph.planes.emplace_back(plane.stride,
+                             plane.offset,
+                             plane.size,
+                             base::ScopedFD(HANDLE_EINTR(dup(planes_.front().fd.get()))));
+    }
+
+    return ph;
+  }
+
+  std::string ToString() const
+  {
+    std::ostringstream s;
+    s << "format:" << gfx::BufferFormatToString(format_) <<
+        ", size:" << size_.ToString() << ", modifier:" << modifier_ <<
+        ", planes: ";
+
+    if (planes_.empty()) {
+      s << "EMPTY";
+    }
+    else
+    {
+      int n = 0;
+      for (const auto& plane : planes_) {
+        if (n++ != 0)
+          s << "; ";
+        s << "[" << n << "] stride:" << plane.stride << ", offset:" << plane.offset << ", size:" << plane.size << ", fd:" << plane.fd.get();
+      }
+    }
+
+    return s.str();
+  }
+
+
+ protected:
+  ~NativePixmapVCSM() override {}
+
+ private:
+  const gfx::Size size_;
+  const gfx::BufferFormat format_;
+  const uint64_t modifier_;
+  const std::vector<gfx::NativePixmapPlane> planes_;
+
+  DISALLOW_COPY_AND_ASSIGN(NativePixmapVCSM);
+};
+
+
+// It appears that the GPU process has some sort of sandboxing as we can't
+// open /dev/vcsm* in CreatePixmap, but the sandboxing isn't set up at static
+// init time - so open the file then and init when needed
+//
+// There are two reasons for not initing at static init
+//  1) This file seems to be included in many processes and we don't need/want
+//     a vcsm context in all of them
+//  2) We also seem to be included in the decode process and we must avoid
+//     locking vcsm into the wrong mode
+//
+// We just have to live with the spurious file open in processes that don't
+// want it
+
+// With this OPT set we make no attempt to clean up on unload - this really
+// shouldn't matter in the slightest as process death should clean everything
+// automatically.
+// When compiled here we get errors if we have on-exit destructors
+#define OPT_LEAK 1
+
+#if OPT_LEAK
+class VcsmCmaInit {
+  bool init_done_ok_ = false;
+  bool init_attempted_ = false;
+  int fd_;
+public:
+  VcsmCmaInit() :
+    fd_(IGNORE_EINTR(open("/dev/vcsm-cma", O_RDWR)))
+  {
+  }
+
+  ~VcsmCmaInit() = default;
+
+  bool InitOnce()
+  {
+    if (!init_attempted_)
+    {
+      init_attempted_ = true;
+      if (fd_ != -1) {
+        init_done_ok_ = (vcsm_init_ex(1, fd_) == 0);
+        if (!init_done_ok_) {
+          LOG(WARNING) << "Failed to init VCSM for CMA";
+        }
+        close(fd_);
+        fd_ = -1;
+      }
+    }
+    return init_done_ok_;
+  }
+
+  operator bool() const
+  {
+    return init_done_ok_;
+  }
+};
+#else
+class VcsmCmaInit {
+  bool init_done_ok_ = false;
+  bool init_attempted_ = false;
+  base::ScopedFD fd_;
+public:
+  VcsmCmaInit() :
+    fd_(IGNORE_EINTR(open("/dev/vcsm-cma", O_RDWR)))
+  {
+  }
+
+  ~VcsmCmaInit()
+  {
+    if (init_done_ok_)
+      vcsm_exit();
+  }
+
+  bool InitOnce()
+  {
+    if (!init_attempted_)
+    {
+      init_attempted_ = true;
+      if (fd_.is_valid()) {
+        init_done_ok_ = (vcsm_init_ex(1, fd_.get()) == 0);
+        if (!init_done_ok_) {
+          LOG(WARNING) << "Failed to init VCSM for CMA";
+        }
+        fd_.reset();
+      }
+    }
+    return init_done_ok_;
+  }
+
+  operator bool() const
+  {
+    return init_done_ok_;
+  }
+};
+#endif
+
+static VcsmCmaInit vcsm_cma_init;
+
+scoped_refptr<gfx::NativePixmap>
+CreateVCSMPixmap(const gfx::Size& size, const gfx::BufferFormat format)
+{
+  if (!vcsm_cma_init.InitOnce()) {
+    return scoped_refptr<gfx::NativePixmap>();
+  }
+
+  const uint64_t modifier = NativePixmapHandle::kNoModifier;
+  const uint32_t total_size = BufferSizeForBufferFormat(size, format);
+
+  if (total_size == 0)
+    return scoped_refptr<gfx::NativePixmapVCSM>();
+
+  const unsigned int vcsm_handle = vcsm_malloc(total_size, "ChromeBuf");
+  if (vcsm_handle == 0) {
+    LOG(WARNING) << "VCSM alloc failed";
+    return scoped_refptr<gfx::NativePixmapVCSM>();
+  }
+
+  base::ScopedFD fd(vcsm_export_dmabuf(vcsm_handle));
+
+  // We don't need this anymore!
+  // Arguably this is a somewhat silly way of allocating a dmabuf as I don't
+  // care about the vcsm handle here, but all the methods seem mostly daft.
+  vcsm_free(vcsm_handle);
+
+  if (!fd.is_valid()) {
+    LOG(WARNING) << "VCSM export failed";
+    return scoped_refptr<gfx::NativePixmapVCSM>();
+  }
+
+  return base::MakeRefCounted<NativePixmapVCSM>(size, format, modifier, std::move(fd));
+}
+
+scoped_refptr<gfx::NativePixmap>
+CreateVCSMPixmapFromHandle(const gfx::Size& size, const gfx::BufferFormat format, gfx::NativePixmapHandle&& handle)
+{
+  const uint64_t modifier = NativePixmapHandle::kNoModifier;
+  return base::MakeRefCounted<NativePixmapVCSM>(size, format, modifier, std::move(handle));
+}
+
+}  // namespace gfx
+
+#endif
+
--- /dev/null
+++ b/src/ui/gfx/linux/native_pixmap_vcsm.h
@@ -0,0 +1,32 @@
+// Copyright 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef UI_GFX_LINUX_NATIVE_PIXMAP_VCSM_H_
+#define UI_GFX_LINUX_NATIVE_PIXMAP_VCSM_H_
+
+#include <stdint.h>
+
+#include <memory>
+
+#include "base/files/scoped_file.h"
+#include "base/macros.h"
+#include "base/memory/ref_counted.h"
+#include "ui/gfx/client_native_pixmap.h"
+#include "ui/gfx/geometry/size.h"
+#include "ui/gfx/native_pixmap.h"
+
+#define RPI_PIXMAP_VCSM 1
+
+namespace gfx {
+
+GFX_EXPORT scoped_refptr<gfx::NativePixmap>
+CreateVCSMPixmap(const gfx::Size& size, const gfx::BufferFormat format);
+
+GFX_EXPORT scoped_refptr<gfx::NativePixmap>
+CreateVCSMPixmapFromHandle(const gfx::Size& size, const gfx::BufferFormat format, gfx::NativePixmapHandle&& handle);
+
+}  // namespace gfx
+
+#endif  // UI_GFX_LINUX_NATIVE_PIXMAP_VCSM_H_
+
--- a/src/ui/gl/init/gl_factory.cc
+++ b/src/ui/gl/init/gl_factory.cc
@@ -71,6 +71,15 @@ GLImplementation GetRequestedGLImplement
     return kGLImplementationNone;
   }
 
+  // RPI: We always want EGL as our preferred render
+  // Easiest to simply add here - angle + GLES +/- EGL crashes
+  // so add here after the angle add.
+  //
+  // BEWARE: falling back from EGL to anything else with --in-process-gpu
+  // set produces a segfault when we exit so ideally we would only do this
+  // on Pi4/(F)KMS?
+  allowed_impls.insert(allowed_impls.begin(), kGLImplementationEGLGLES2);
+
   // The default implementation is always the first one in list.
   GLImplementation impl = allowed_impls[0];
   *fallback_to_software_gl = false;
--- a/src/native_client/src/include/concurrency_ops.h
+++ b/src/native_client/src/include/concurrency_ops.h
@@ -32,14 +32,13 @@ static INLINE void NaClWriteMemoryBarrie
 #elif NACL_ARCH(NACL_BUILD_ARCH) == NACL_arm
 
 static INLINE void NaClWriteMemoryBarrier(void) {
+#if __ARM_ARCH >= 7
   /* Note that this depends on ARMv7. */
   __asm__ __volatile__("dsb");
-
-  /*
-   * We could support ARMv6 by instead using:
-   * __asm__ __volatile__("mcr p15, 0, %0, c7, c10, 5"
-   *                      : : "r" (0) : "memory");
-   */
+#else
+ __asm__ __volatile__("mcr p15, 0, %0, c7, c10, 5"
+                      : : "r" (0) : "memory");
+#endif
 }
 
 #elif NACL_ARCH(NACL_BUILD_ARCH) == NACL_mips
--- a/src/third_party/ffmpeg/chromium/config/Chrome/linux/arm/config.h
+++ b/src/third_party/ffmpeg/chromium/config/Chrome/linux/arm/config.h
@@ -40,7 +40,7 @@
 #define ARCH_X86_64 0
 #define HAVE_ARMV5TE 1
 #define HAVE_ARMV6 1
-#define HAVE_ARMV6T2 1
+#define HAVE_ARMV6T2 0
 #define HAVE_ARMV8 0
 #define HAVE_NEON 0
 #define HAVE_VFP 1
@@ -86,7 +86,7 @@
 #define HAVE_MMI 0
 #define HAVE_ARMV5TE_EXTERNAL 1
 #define HAVE_ARMV6_EXTERNAL 1
-#define HAVE_ARMV6T2_EXTERNAL 1
+#define HAVE_ARMV6T2_EXTERNAL 0
 #define HAVE_ARMV8_EXTERNAL 0
 #define HAVE_NEON_EXTERNAL 0
 #define HAVE_VFP_EXTERNAL 1
@@ -132,7 +132,7 @@
 #define HAVE_MMI_EXTERNAL 0
 #define HAVE_ARMV5TE_INLINE 1
 #define HAVE_ARMV6_INLINE 1
-#define HAVE_ARMV6T2_INLINE 1
+#define HAVE_ARMV6T2_INLINE 0
 #define HAVE_ARMV8_INLINE 0
 #define HAVE_NEON_INLINE 0
 #define HAVE_VFP_INLINE 1
@@ -589,7 +589,7 @@
 #define CONFIG_NEON_CLOBBER_TEST 0
 #define CONFIG_OSSFUZZ 0
 #define CONFIG_PIC 1
-#define CONFIG_THUMB 1
+#define CONFIG_THUMB 0
 #define CONFIG_VALGRIND_BACKTRACE 0
 #define CONFIG_XMM_CLOBBER_TEST 0
 #define CONFIG_BSFS 1
--- a/src/third_party/libjpeg_turbo/simd/arm/arm/jsimd_neon.S
+++ b/src/third_party/libjpeg_turbo/simd/arm/arm/jsimd_neon.S
@@ -31,8 +31,8 @@
 #endif
 
 .text
-.fpu neon
-.arch armv7a
+.arch armv7-a
+.fpu neon-vfpv4
 .object_arch armv4
 .arm
 .syntax unified
--- a/src/third_party/libyuv/BUILD.gn
+++ b/src/third_party/libyuv/BUILD.gn
@@ -210,6 +210,11 @@ if (libyuv_use_neon) {
 
     if (current_cpu != "arm64") {
       configs -= [ "//build/config/compiler:compiler_arm_fpu" ]
+      if (arm_version < 7) {
+        configs += [
+          "//build/config/compiler:force_march_armv7",
+        ]
+      }
       cflags = [ "-mfpu=neon" ]
     }
   }
--- a/src/third_party/libyuv/source/cpu_id.cc
+++ b/src/third_party/libyuv/source/cpu_id.cc
@@ -133,6 +133,18 @@ int GetXCR0() {
 #pragma optimize("g", on)
 #endif
 
+#ifdef __ARMEL__
+// This is (a) simpler and (b) works in sandbox vs the /proc/cpuinfo method
+#include <sys/auxv.h>
+
+int ArmCpuCaps(const char* cpuinfo_name) {
+  const unsigned long auxval = getauxval(AT_HWCAP);
+
+  // Documentation suggests that getauxval(AT_HWCAP) should return a pointer
+  // to a bit array, but evidence suggests it returns a simple bit field
+  return ((auxval & HWCAP_ARM_NEON) != 0 ? kCpuHasNEON : 0);
+}
+#else
 // based on libvpx arm_cpudetect.c
 // For Arm, but public to allow testing on any CPU
 LIBYUV_API SAFEBUFFERS int ArmCpuCaps(const char* cpuinfo_name) {
@@ -161,6 +173,7 @@ LIBYUV_API SAFEBUFFERS int ArmCpuCaps(co
   fclose(f);
   return 0;
 }
+#endif
 
 // TODO(fbarchard): Consider read_msa_ir().
 // TODO(fbarchard): Add unittest.
--- a/src/third_party/skia/src/core/SkBitmapProcState.cpp
+++ b/src/third_party/skia/src/core/SkBitmapProcState.cpp
@@ -18,6 +18,7 @@
 #include "src/core/SkResourceCache.h"
 #include "src/core/SkUtils.h"
 
+#if !defined(SK_ARM_HAS_NEON) || defined(__ARM_64BIT_STATE)
 // One-stop-shop shader for,
 //   - nearest-neighbor sampling (_nofilter_),
 //   - clamp tiling in X and Y both (Clamp_),
@@ -73,6 +74,201 @@ static void Clamp_S32_opaque_D32_nofilte
         }
     }
 }
+#endif
+
+// We define two variants of this: one for 32-bit ARM NEON, and one generic C:
+
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+static inline void Clamp_S32_opaque_D32_nofilter_DX_shaderproc_core_neon(SkPMColor* __restrict__ &dst, const SkPMColor* __restrict__ src, int core, SkFractionalInt fx, const SkFractionalInt dx)
+{
+    const SkPMColor*p = src + (int32_t)(fx >> 32);
+    uint32_t accum = (uint32_t) fx;
+    const SkPMColor *p2;
+    __asm__ volatile (
+            "cmp     %[core], #0           \n\t"
+            "it      ne                    \n\t"
+            "tstne   %[dst], #0xc          \n\t"
+            "beq     2f                    \n\t"
+            "1:                            \n\t"
+            "vldr    s0, [%[p]]            \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p], %[inc1]         \n\t"
+            "addcs   %[p], %[inc2]         \n\t"
+            "vstm    %[dst]!, {s0}         \n\t"
+            "subs    %[core], #1           \n\t"
+            "it      ne                    \n\t"
+            "tstne   %[dst], #0xc          \n\t"
+            "bne     1b                    \n\t"
+            "2:                            \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p2], %[p], %[inc1]  \n\t"
+            "addcs   %[p2], %[p], %[inc2]  \n\t"
+            "subs    %[core], #4           \n\t"
+            "bcc     4f                    \n\t"
+            "3:                            \n\t"
+            "vldr    s0, [%[p]]            \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p], %[p2], %[inc1]  \n\t"
+            "addcs   %[p], %[p2], %[inc2]  \n\t"
+            "vldr    s1, [%[p2]]           \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p2], %[p], %[inc1]  \n\t"
+            "addcs   %[p2], %[p], %[inc2]  \n\t"
+            "vldr    s2, [%[p]]            \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p], %[p2], %[inc1]  \n\t"
+            "addcs   %[p], %[p2], %[inc2]  \n\t"
+            "vldr    s3, [%[p2]]           \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p2], %[p], %[inc1]  \n\t"
+            "addcs   %[p2], %[p], %[inc2]  \n\t"
+            "vst1.32 {q0}, [%[dst] :128]!  \n\t"
+            "subs    %[core], #4           \n\t"
+            "bcs     3b                    \n\t"
+            "4:                            \n\t"
+            "adds    %[core], #4           \n\t"
+            "beq     6f                    \n\t"
+            "5:                            \n\t"
+            "vldr    s0, [%[p]]            \n\t"
+            "mov     %[p], %[p2]           \n\t"
+            "adds    %[accum], %[dx]       \n\t"
+            "ite     cc                    \n\t"
+            "addcc   %[p2], %[p], %[inc1]  \n\t"
+            "addcs   %[p2], %[p], %[inc2]  \n\t"
+            "vstm    %[dst]!, {s0}         \n\t"
+            "subs    %[core], #1           \n\t"
+            "bne     5b                    \n\t"
+            "6:                            \n\t"
+    : // Outputs
+            [accum]"+r"(accum),
+             [core]"+r"(core),
+              [dst]"+r"(dst),
+                [p]"+r"(p),
+               [p2]"=&r"(p2)
+    : // Inputs
+              [dx]"r"((int32_t) dx),
+            [inc1]"r"((int32_t)(dx >> 32) * 4),
+            [inc2]"r"(((int32_t)(dx >> 32) + 1) * 4)
+    : // Clobbers
+            "cc", "memory"
+    );
+}
+#endif
+
+#if 0
+static inline void Clamp_S32_opaque_D32_nofilter_DX_shaderproc_core(SkPMColor* __restrict__ &dst, const SkPMColor* __restrict__ src, int core, SkFractionalInt fx, const SkFractionalInt dx)
+{
+    const SkPMColor*p = src + (int32_t)(fx >> 32);
+    uint32_t accum = (uint32_t) fx;
+    for (; core > 0; --core) {
+        *dst++ = *p;
+        uint32_t prev_accum = accum;
+        accum += (int32_t) dx;
+        if (accum < prev_accum) /* i.e. carry set */
+            p += (int32_t)(dx >> 32) + 1;
+        else
+            p += (int32_t)(dx >> 32);
+    }
+}
+#endif
+
+#define Clamp_S32_opaque_D32_nofilter_DX_shaderproc_template(SUFFIX)                               \
+static void Clamp_S32_opaque_D32_nofilter_DX_shaderproc(const void* sIn, int x, int y,             \
+                                                        SkPMColor* SK_RESTRICT dst,  int count) {  \
+    const SkBitmapProcState& s = *static_cast<const SkBitmapProcState*>(sIn);                      \
+    SkASSERT((s.fInvType & ~(SkMatrix::kTranslate_Mask |                                           \
+                             SkMatrix::kScale_Mask)) == 0);                                        \
+    SkASSERT(s.fAlphaScale == 256);                                                                \
+                                                                                                   \
+    const unsigned maxX = s.fPixmap.width() - 1;                                                   \
+    SkFractionalInt fx;                                                                            \
+    int dstY;                                                                                      \
+    {                                                                                              \
+        const SkBitmapProcStateAutoMapper mapper(s, x, y);                                         \
+        const unsigned maxY = s.fPixmap.height() - 1;                                              \
+        dstY = SkTPin(mapper.intY(), 0, (int)maxY);                                                    \
+        fx = mapper.fractionalIntX();                                                              \
+    }                                                                                              \
+                                                                                                   \
+    const SkPMColor* SK_RESTRICT src = s.fPixmap.addr32(0, dstY);                                  \
+    const SkFractionalInt dx = s.fInvSxFractionalInt;                                              \
+                                                                                                   \
+    int core;                                                                                      \
+                                                                                                   \
+    /* The unscaled case is easily common enough to be worth special-casing.                       \
+     * The system memcpy() is typically already heavily optimized, so just use that.               \
+     */                                                                                            \
+    if (dx == 0x100000000ll) {                                                                     \
+        int32_t fx_integer = fx >> 32;                                                             \
+        if (fx_integer < 0) {                                                                      \
+            int left = std::min(-fx_integer, count);                                                \
+            fx_integer += left;                                                                    \
+            count -= left;                                                                         \
+            for (; left > 0; --left)                                                               \
+                *dst++ = src[0];                                                                   \
+        }                                                                                          \
+        if (fx_integer < (int)maxX) {                                                              \
+            core = std::min((int)maxX + 1 - fx_integer, count);                                     \
+            memcpy(dst, src + fx_integer, core * sizeof (uint32_t));                               \
+            dst += core;                                                                           \
+            count -= core;                                                                         \
+        }                                                                                          \
+        for (; count > 0; --count) {                                                               \
+            *dst++ = src[maxX];                                                                    \
+        }                                                                                          \
+    }                                                                                              \
+                                                                                                   \
+    /* Handle other non-reflected scale factors. */                                                \
+    else if (dx >= 0) {                                                                            \
+        for (; fx < 0 && count > 0; --count) {                                                     \
+            *dst++ = src[0];                                                                       \
+            fx += dx;                                                                              \
+        }                                                                                          \
+        if ((int32_t)(fx >> 32) > (int)maxX)                                                       \
+            core = 0;                                                                              \
+        else if ((int32_t)((fx + (count - 1) * dx) >> 32) <= (int)maxX)                            \
+            core = count;                                                                          \
+        else                                                                                       \
+            core = (int32_t)(((((SkFractionalInt) maxX) << 32) + 0xffffffff - fx) / dx) + 1;       \
+        Clamp_S32_opaque_D32_nofilter_DX_shaderproc_core##SUFFIX(dst, src, core, fx, dx);          \
+        count -= core;                                                                             \
+        for (; count > 0; --count) {                                                               \
+            *dst++ = src[maxX];                                                                    \
+        }                                                                                          \
+    }                                                                                              \
+                                                                                                   \
+    /* It's not clear if reflection is used, but it's a relatively                                 \
+     * simple variation on the non-reflected case. */                                              \
+    else                                                                                           \
+    {                                                                                              \
+        for (; (int32_t)(fx >> 32) > (int)maxX && count > 0; --count) {                            \
+            *dst++ = src[maxX];                                                                    \
+            fx += dx;                                                                              \
+        }                                                                                          \
+        if (fx < 0)                                                                                \
+            core = 0;                                                                              \
+        else if (fx + (count - 1) * dx >= 0)                                                       \
+            core = count;                                                                          \
+        else                                                                                       \
+            core = (int32_t)(fx / -dx) + 1;                                                        \
+        Clamp_S32_opaque_D32_nofilter_DX_shaderproc_core##SUFFIX(dst, src, core, fx, dx);          \
+        count -= core;                                                                             \
+        for (; count > 0; --count) {                                                               \
+            *dst++ = src[0];                                                                       \
+        }                                                                                          \
+    }                                                                                              \
+}
+
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+Clamp_S32_opaque_D32_nofilter_DX_shaderproc_template(_neon)
+#endif
+
 
 static void S32_alpha_D32_nofilter_DX(const SkBitmapProcState& s,
                                       const uint32_t* xy, int count, SkPMColor* colors) {
@@ -278,7 +474,11 @@ bool SkBitmapProcState::chooseProcs() {
 
     const bool filter = fFilterQuality > kNone_SkFilterQuality;
     if (fInvMatrix.isScaleTranslate()) {
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+        fSampleProc32 = filter ? (fAlphaScale == 256 ? SkOpts::S32_opaque_D32_filter_DX : SkOpts::S32_alpha_D32_filter_DX)   : S32_alpha_D32_nofilter_DX  ;
+#else
         fSampleProc32 = filter ? SkOpts::S32_alpha_D32_filter_DX   : S32_alpha_D32_nofilter_DX  ;
+#endif
     } else {
         fSampleProc32 = filter ? SkOpts::S32_alpha_D32_filter_DXDY : S32_alpha_D32_nofilter_DXDY;
     }
--- a/src/third_party/skia/src/core/SkBitmapProcState_matrixProcs.cpp
+++ b/src/third_party/skia/src/core/SkBitmapProcState_matrixProcs.cpp
@@ -246,6 +246,535 @@ static unsigned clamp(SkFixed fx, int ma
     return SkTPin(fx >> 16, 0, max);
 }
 
+// Clamp/Clamp and Repeat/Repeat have NEON or portable implementations.
+#if defined(SK_ARM_HAS_NEON)
+    #include <arm_neon.h>
+
+    // TODO: this is a fine drop-in for decal_nofilter_scale() generally.
+    static void decal_nofilter_scale_neon(uint32_t dst[], SkFixed fx, SkFixed dx, int count) {
+        if (count >= 8) {
+            // SkFixed is 16.16 fixed point
+            SkFixed dx8 = dx * 8;
+            int32x4_t vdx8 = vdupq_n_s32(dx8);
+
+            // setup lbase and hbase
+            int32x4_t lbase, hbase;
+            lbase = vdupq_n_s32(fx);
+            lbase = vsetq_lane_s32(fx + dx, lbase, 1);
+            lbase = vsetq_lane_s32(fx + dx + dx, lbase, 2);
+            lbase = vsetq_lane_s32(fx + dx + dx + dx, lbase, 3);
+            hbase = lbase + vdupq_n_s32(4 * dx);
+
+            do {
+                // store the upper 16 bits
+                vst1q_u32(dst, vreinterpretq_u32_s16(
+                    vuzpq_s16(vreinterpretq_s16_s32(lbase), vreinterpretq_s16_s32(hbase)).val[1]
+                ));
+
+                // on to the next group of 8
+                lbase += vdx8;
+                hbase += vdx8;
+                dst += 4; // we did 8 elements but the result is twice smaller
+                count -= 8;
+                fx += dx8;
+            } while (count >= 8);
+        }
+
+        uint16_t* xx = (uint16_t*)dst;
+        for (int i = count; i > 0; --i) {
+            *xx++ = SkToU16(fx >> 16); fx += dx;
+        }
+    }
+
+    static void decal_filter_scale_neon(uint32_t dst[], SkFixed fx, SkFixed dx, int count) {
+#ifndef __ARM_64BIT_STATE
+        SkASSERT(((fx + (count-1) * dx) >> (16 + 14)) == 0);
+        fx = (fx << 2) + 1;
+        dx <<= 2;
+        while (((uintptr_t) dst & 0xf) && --count >= 0) {
+            *dst++ = (fx & 0xffffc001) + (fx >> 18);
+            fx += dx;
+        }
+        if ((count -= 4) >= 0) {
+            uint32_t tmp;
+            __asm__ (
+                    "adr         %[tmp], 1f                  \n\t"
+                    "vmvn.i32    q10, #0x3fff                \n\t"
+                    "vld1.32     {q11}, [%[tmp]]             \n\t"
+                    "vdup.32     q8, %[fx]                   \n\t"
+                    "vdup.32     q9, %[dx]                   \n\t"
+                    "vsra.u32    q10, #31                    \n\t"
+                    "vmla.u32    q8, q9, q11                 \n\t"
+                    "vshl.u32    q9, #2                      \n\t"
+                    "b           2f                          \n\t"
+                    "1:                                      \n\t"
+                    ".long       0                           \n\t"
+                    ".long       1                           \n\t"
+                    ".long       2                           \n\t"
+                    ".long       3                           \n\t"
+                    "2:                                      \n\t"
+                    "vand        q11, q8, q10                \n\t"
+                    "vshr.u32    q12, q8, #18                \n\t"
+                    "vadd.i32    q11, q12                    \n\t"
+                    "vadd.i32    q8, q9                      \n\t"
+                    "subs        %[count], #4                \n\t"
+                    "vst1.32     {q11}, [%[dst]:128]!        \n\t"
+                    "bpl         2b                          \n\t"
+                    "vmov.32     %[fx], d16[0]               \n\t"
+            : // Outputs
+                    [count]"+l"(count),
+                      [dst]"+r"(dst),
+                       [fx]"+r"(fx),
+                      [tmp]"=&r"(tmp)
+            : // Inputs
+                    [dx]"r"(dx)
+            : // Clobbers
+                    "cc", "memory"
+            );
+        }
+        if ((count += 4-1) >= 0) {
+            do {
+                *dst++ = (fx & 0xffffc001) + (fx >> 18);
+                fx += dx;
+            } while (--count >= 0);
+        }
+#else // !defined(__ARM_64BIT_STATE)
+        if (count >= 8) {
+            SkFixed dx8 = dx * 8;
+            int32x4_t vdx8 = vdupq_n_s32(dx8);
+
+            int32x4_t wide_fx, wide_fx2;
+            wide_fx = vdupq_n_s32(fx);
+            wide_fx = vsetq_lane_s32(fx + dx, wide_fx, 1);
+            wide_fx = vsetq_lane_s32(fx + dx + dx, wide_fx, 2);
+            wide_fx = vsetq_lane_s32(fx + dx + dx + dx, wide_fx, 3);
+
+            wide_fx2 = vaddq_s32(wide_fx, vdupq_n_s32(4 * dx));
+
+            while (count >= 8) {
+                int32x4_t wide_out;
+                int32x4_t wide_out2;
+
+                wide_out = vshlq_n_s32(vshrq_n_s32(wide_fx, 12), 14);
+                wide_out = wide_out | (vshrq_n_s32(wide_fx,16) + vdupq_n_s32(1));
+
+                wide_out2 = vshlq_n_s32(vshrq_n_s32(wide_fx2, 12), 14);
+                wide_out2 = wide_out2 | (vshrq_n_s32(wide_fx2,16) + vdupq_n_s32(1));
+
+                vst1q_u32(dst, vreinterpretq_u32_s32(wide_out));
+                vst1q_u32(dst+4, vreinterpretq_u32_s32(wide_out2));
+
+                dst += 8;
+                fx += dx8;
+                wide_fx += vdx8;
+                wide_fx2 += vdx8;
+                count -= 8;
+            }
+        }
+
+        if (count & 1)
+        {
+            SkASSERT((fx >> (16 + 14)) == 0);
+            *dst++ = (fx >> 12 << 14) | ((fx >> 16) + 1);
+            fx += dx;
+        }
+        while ((count -= 2) >= 0)
+        {
+            SkASSERT((fx >> (16 + 14)) == 0);
+            *dst++ = (fx >> 12 << 14) | ((fx >> 16) + 1);
+            fx += dx;
+
+            *dst++ = (fx >> 12 << 14) | ((fx >> 16) + 1);
+            fx += dx;
+        }
+#endif
+    }
+
+    static inline int16x8_t clamp8(int32x4_t low, int32x4_t high, unsigned max) {
+        int16x8_t res;
+
+        // get the hi 16s of all those 32s
+        res = vuzpq_s16(vreinterpretq_s16_s32(low), vreinterpretq_s16_s32(high)).val[1];
+
+        // clamp
+        res = vmaxq_s16(res, vdupq_n_s16(0));
+        res = vminq_s16(res, vdupq_n_s16(max));
+
+        return res;
+    }
+
+    static inline int32x4_t clamp4(int32x4_t f, unsigned max) {
+        int32x4_t res;
+
+        // get the hi 16s of all those 32s
+        res = vshrq_n_s32(f, 16);
+
+        // clamp
+        res = vmaxq_s32(res, vdupq_n_s32(0));
+        res = vminq_s32(res, vdupq_n_s32(max));
+
+        return res;
+    }
+
+    static inline int32x4_t extract_low_bits_clamp4(int32x4_t fx, unsigned) {
+        int32x4_t ret;
+
+        ret = vshrq_n_s32(fx, 12);
+
+        /* We don't need the mask below because the caller will
+         * overwrite the non-masked bits
+         */
+        //ret = vandq_s32(ret, vdupq_n_s32(0xF));
+
+        return ret;
+    }
+
+    static inline int16x8_t repeat8(int32x4_t low, int32x4_t high, unsigned max) {
+        uint16x8_t res;
+        uint32x4_t tmpl, tmph;
+
+        // get the lower 16 bits
+        res = vuzpq_u16(vreinterpretq_u16_s32(low), vreinterpretq_u16_s32(high)).val[0];
+
+        // bare multiplication, not SkFixedMul
+        tmpl = vmull_u16(vget_low_u16(res), vdup_n_u16(max+1));
+        tmph = vmull_u16(vget_high_u16(res), vdup_n_u16(max+1));
+
+        // extraction of the 16 upper bits
+        res = vuzpq_u16(vreinterpretq_u16_u32(tmpl), vreinterpretq_u16_u32(tmph)).val[1];
+
+        return vreinterpretq_s16_u16(res);
+    }
+
+    static inline int32x4_t repeat4(int32x4_t f, unsigned max) {
+        uint16x4_t res;
+        uint32x4_t tmp;
+
+        // get the lower 16 bits
+        res = vmovn_u32(vreinterpretq_u32_s32(f));
+
+        // bare multiplication, not SkFixedMul
+        tmp = vmull_u16(res, vdup_n_u16(max+1));
+
+        // extraction of the 16 upper bits
+        tmp = vshrq_n_u32(tmp, 16);
+
+        return vreinterpretq_s32_u32(tmp);
+    }
+
+    static inline int32x4_t extract_low_bits_repeat_mirror4(int32x4_t fx, unsigned max) {
+        uint16x4_t res;
+        uint32x4_t tmp;
+        int32x4_t ret;
+
+        // get the lower 16 bits
+        res = vmovn_u32(vreinterpretq_u32_s32(fx));
+
+        // bare multiplication, not SkFixedMul
+        tmp = vmull_u16(res, vdup_n_u16(max + 1));
+
+        // shift and mask
+        ret = vshrq_n_s32(vreinterpretq_s32_u32(tmp), 12);
+
+        /* We don't need the mask below because the caller will
+         * overwrite the non-masked bits
+         */
+        //ret = vandq_s32(ret, vdupq_n_s32(0xF));
+
+        return ret;
+    }
+
+    template <unsigned   (*tile)(SkFixed, int),
+              int16x8_t (*tile8)(int32x4_t, int32x4_t, unsigned),
+             bool tryDecal>
+    static void nofilter_scale_neon(const SkBitmapProcState& s,
+                                    uint32_t xy[], int count, int x, int y) {
+        SkASSERT((s.fInvType & ~(SkMatrix::kTranslate_Mask |
+                                 SkMatrix::kScale_Mask)) == 0);
+
+        // we store y, x, x, x, x, x
+        const unsigned maxX = s.fPixmap.width() - 1;
+        SkFractionalInt fx;
+        {
+            const SkBitmapProcStateAutoMapper mapper(s, x, y);
+            const unsigned maxY = s.fPixmap.height() - 1;
+            *xy++ = tile(mapper.fixedY(), maxY);
+            fx = mapper.fractionalIntX();
+        }
+
+        if (0 == maxX) {
+            // all of the following X values must be 0
+            memset(xy, 0, count * sizeof(uint16_t));
+            return;
+        }
+
+        const SkFractionalInt dx = s.fInvSxFractionalInt;
+
+        // test if we don't need to apply the tile proc
+        const SkFixed fixedFx = SkFractionalIntToFixed(fx);
+        const SkFixed fixedDx = SkFractionalIntToFixed(dx);
+        if (tryDecal && can_truncate_to_fixed_for_decal(fixedFx, fixedDx, count, maxX)) {
+            decal_nofilter_scale_neon(xy, fixedFx, fixedDx, count);
+            return;
+        }
+
+        if (count >= 8) {
+            SkFractionalInt dx2 = dx+dx;
+            SkFractionalInt dx4 = dx2+dx2;
+            SkFractionalInt dx8 = dx4+dx4;
+
+            // now build fx/fx+dx/fx+2dx/fx+3dx
+            SkFractionalInt fx1, fx2, fx3;
+            int32x4_t lbase, hbase;
+            int16_t *dst16 = (int16_t *)xy;
+
+            fx1 = fx+dx;
+            fx2 = fx1+dx;
+            fx3 = fx2+dx;
+
+            lbase = vdupq_n_s32(SkFractionalIntToFixed(fx));
+            lbase = vsetq_lane_s32(SkFractionalIntToFixed(fx1), lbase, 1);
+            lbase = vsetq_lane_s32(SkFractionalIntToFixed(fx2), lbase, 2);
+            lbase = vsetq_lane_s32(SkFractionalIntToFixed(fx3), lbase, 3);
+            hbase = vaddq_s32(lbase, vdupq_n_s32(SkFractionalIntToFixed(dx4)));
+
+            // store & bump
+            while (count >= 8) {
+
+                int16x8_t fx8;
+
+                fx8 = tile8(lbase, hbase, maxX);
+
+                vst1q_s16(dst16, fx8);
+
+                // but preserving base & on to the next
+                lbase = vaddq_s32 (lbase, vdupq_n_s32(SkFractionalIntToFixed(dx8)));
+                hbase = vaddq_s32 (hbase, vdupq_n_s32(SkFractionalIntToFixed(dx8)));
+                dst16 += 8;
+                count -= 8;
+                fx += dx8;
+            }
+            xy = (uint32_t *) dst16;
+        }
+
+        uint16_t* xx = (uint16_t*)xy;
+        for (int i = count; i > 0; --i) {
+            *xx++ = tile(SkFractionalIntToFixed(fx), maxX);
+            fx += dx;
+        }
+    }
+
+    template <unsigned              (*tile )(SkFixed, int),
+              int32x4_t             (*tile4)(int32x4_t, unsigned),
+              unsigned  (*extract_low_bits )(SkFixed, int),
+              int32x4_t (*extract_low_bits4)(int32x4_t, unsigned),
+              bool tryDecal>
+    static void filter_scale_neon(const SkBitmapProcState& s,
+                                  unsigned int * xy, int count, int x, int y) {
+        SkASSERT((s.fInvType & ~(SkMatrix::kTranslate_Mask |
+                                 SkMatrix::kScale_Mask)) == 0);
+        SkASSERT(s.fInvKy == 0);
+
+        auto pack = [&](SkFixed f, unsigned max, SkFixed one) {
+            unsigned i = tile(f, max);
+            i = (i << 4) | extract_low_bits(f, max);
+            return (i << 14) | (tile((f + one), max));
+        };
+
+        auto pack4 = [&](int32x4_t f, unsigned max, SkFixed one) {
+            int32x4_t ret, res;
+
+            res = tile4(f, max);
+
+            ret = extract_low_bits4(f, max);
+            ret = vsliq_n_s32(ret, res, 4);
+
+            res = tile4(f + vdupq_n_s32(one), max);
+            ret = vorrq_s32(vshlq_n_s32(ret, 14), res);
+
+            return ret;
+        };
+
+        const unsigned maxX = s.fPixmap.width() - 1;
+        const SkFixed one = s.fFilterOneX;
+        const SkFractionalInt dx = s.fInvSxFractionalInt;
+        SkFractionalInt fx;
+
+        {
+            const SkBitmapProcStateAutoMapper mapper(s, x, y);
+            const SkFixed fy = mapper.fixedY();
+            const unsigned maxY = s.fPixmap.height() - 1;
+            // compute our two Y values up front
+            *xy++ = pack(fy, maxY, s.fFilterOneY);
+            // now initialize fx
+            fx = mapper.fractionalIntX();
+        }
+
+        // test if we don't need to apply the tile proc
+        const SkFixed fixedFx = SkFractionalIntToFixed(fx);
+        const SkFixed fixedDx = SkFractionalIntToFixed(dx);
+        if (tryDecal && can_truncate_to_fixed_for_decal(fixedFx, fixedDx, count, maxX)) {
+            decal_filter_scale_neon(xy, fixedFx, fixedDx, count);
+            return;
+        }
+
+#ifndef __ARM_64BIT_STATE
+        if (tile == clamp && one == SK_Fixed1) {
+            SkASSERT(maxX < (1<<14)-1);
+            if (dx >= 0) {
+                --count;
+                while (count >= 0 && fx < 0) {
+                    *xy++ = 0;
+                    fx += dx;
+                    --count;
+                }
+                while (count >= 0 && ((uintptr_t) xy & 0xf) && fx < ((SkFractionalInt) maxX << 32)) {
+                    *xy++ = ((uint32_t)(fx >> 14) & 0xffffc000) + (uint32_t)(fx >> 32) + 1;
+                    fx += dx;
+                    --count;
+                }
+                if ((count -= 8-1) >= 0 && fx + 7*dx < ((SkFractionalInt) maxX << 32)) {
+                    SkFractionalInt rem = (((SkFractionalInt) maxX << 32) - 7*dx - fx - 1) / 8;
+                    int32_t rem_hi = rem >> 32;
+                    uint32_t rem_lo = (uint32_t) rem;
+                    int32_t fx_hi = fx >> 32;
+                    uint32_t fx_lo = (uint32_t) fx;
+                    __asm__ (
+                            "vmov        d16, %[fx_lo], %[fx_hi]     \n\t"
+                            "vmov        d24, %[dx_lo], %[dx_hi]     \n\t"
+                            "vadd.i64    d17, d16, d24               \n\t"
+                            "vmov        d25, %[dx_lo], %[dx_hi]     \n\t"
+                            "vmvn.i32    q13, #0x3fff                \n\t"
+                            "vadd.i64    d18, d17, d24               \n\t"
+                            "vmov.i32    q14, #1                     \n\t"
+                            "vadd.i64    d19, d18, d24               \n\t"
+                            "vshl.i64    q12, #2                     \n\t"
+                            "b           2f                          \n\t"
+                            "1:                                      \n\t"
+                            "vadd.i64    q8, q10, q12                \n\t"
+                            "vadd.i64    q9, q11, q12                \n\t"
+                            "2:                                      \n\t"
+                            "vadd.i64    q10, q8, q12                \n\t"
+                            "vadd.i64    q11, q9, q12                \n\t"
+                            "vshrn.i64   d16, q8, #14                \n\t"
+                            "vshrn.i64   d17, q9, #14                \n\t"
+                            "vand        q8, q13                     \n\t"
+                            "vorr        q8, q14                     \n\t"
+                            "vshrn.i64   d18, q10, #14               \n\t"
+                            "vshrn.i64   d19, q11, #14               \n\t"
+                            "vand        q9, q13                     \n\t"
+                            "subs        %[rem_lo], %[dx_lo]         \n\t"
+                            "vorr        q9, q14                     \n\t"
+                            "sbcs        %[rem_hi], %[dx_hi]         \n\t"
+                            "vsra.u32    q8, #18                     \n\t"
+                            "subs        %[count], #8                \n\t"
+                            "vsra.u32    q9, #18                     \n\t"
+                            "it          pl                          \n\t"
+                            "teqpl       %[rem_hi], #0               \n\t"
+                            "vst1.32     {q8-q9}, [%[dst]:128]!      \n\t"
+                            "bpl         1b                          \n\t"
+                            "vadd.i64    d16, d20, d24               \n\t"
+                            "vmov        %[fx_lo], %[fx_hi], d16     \n\t"
+                    : // Outputs
+                             [count]"+l"(count),
+                               [dst]"+r"(xy),
+                            [rem_hi]"+l"(rem_hi),
+                            [rem_lo]"+l"(rem_lo),
+                             [fx_hi]"+r"(fx_hi),
+                             [fx_lo]"+r"(fx_lo)
+                    : // Inputs
+                            [dx_hi]"l"((int32_t) (dx >> 32)),
+                            [dx_lo]"l"((uint32_t) dx)
+                    : // Clobbers
+                            "cc", "memory"
+                    );
+                    fx = ((SkFractionalInt) fx_hi << 32) | fx_lo;
+                }
+                count += 8-1;
+                while (count >= 0 && fx < ((SkFractionalInt) maxX << 32)) {
+                    *xy++ = ((uint32_t)(fx >> 14) & 0xffffc000) + (uint32_t)(fx >> 32) + 1;
+                    fx += dx;
+                    --count;
+                }
+                while (count >= 0) {
+                    *xy++ = (maxX << 18) + maxX;
+                    --count;
+                }
+            } else {
+                // Reflection case. Don't bother to optimize this as much -
+                // not even sure if it's used!
+                while (count >= 1 && fx >= ((SkFractionalInt) maxX << 32)) {
+                    *xy++ = (maxX << 18) + maxX;
+                    fx += dx;
+                    --count;
+                }
+                while (count >= 1 && fx >= 0) {
+                    *xy++ = ((uint32_t)(fx >> 14) & 0xffffc000) + (uint32_t)(fx >> 32) + 1;
+                    fx += dx;
+                    --count;
+                }
+                while (count >= 1) {
+                    *xy++ = 0;
+                    --count;
+                }
+            }
+        }
+        else
+        {
+        // Drop back to old code for repeat or other values of 'one'
+#endif
+        if (count >= 4) {
+            int32x4_t wide_fx;
+
+            wide_fx = vdupq_n_s32(SkFractionalIntToFixed(fx));
+            wide_fx = vsetq_lane_s32(SkFractionalIntToFixed(fx+dx), wide_fx, 1);
+            wide_fx = vsetq_lane_s32(SkFractionalIntToFixed(fx+dx+dx), wide_fx, 2);
+            wide_fx = vsetq_lane_s32(SkFractionalIntToFixed(fx+dx+dx+dx), wide_fx, 3);
+
+            while (count >= 4) {
+                int32x4_t res;
+
+                res = pack4(wide_fx, maxX, one);
+
+                vst1q_u32(xy, vreinterpretq_u32_s32(res));
+
+                wide_fx += vdupq_n_s32(SkFractionalIntToFixed(dx+dx+dx+dx));
+                fx += dx+dx+dx+dx;
+                xy += 4;
+                count -= 4;
+            }
+        }
+
+        while (--count >= 0) {
+            *xy++ = pack(SkFractionalIntToFixed(fx), maxX, one);
+            fx += dx;
+        }
+#ifndef __ARM_64BIT_STATE
+        }
+#endif
+    }
+
+    static const SkBitmapProcState::MatrixProc ClampX_ClampY_Procs[] = {
+        nofilter_scale_neon<clamp, clamp8, true>,
+        filter_scale_neon<clamp,
+                          clamp4,
+                          extract_low_bits_clamp_clamp,
+                          extract_low_bits_clamp4,
+                          true>,
+        nofilter_affine<clamp, clamp>,       filter_affine<clamp, clamp, extract_low_bits_clamp_clamp>,
+    };
+
+    static const SkBitmapProcState::MatrixProc RepeatX_RepeatY_Procs[] = {
+        nofilter_scale_neon<repeat, repeat8, false>,
+        filter_scale_neon<repeat,
+                          repeat4,
+                          extract_low_bits_general,
+                          extract_low_bits_repeat_mirror4,
+                          false>,
+        nofilter_affine<repeat, repeat>,        filter_affine<repeat, repeat, extract_low_bits_general>
+    };
+#else
+
 static const SkBitmapProcState::MatrixProc ClampX_ClampY_Procs[] = {
     nofilter_scale <clamp, clamp, true>, filter_scale <clamp, clamp, extract_low_bits_clamp_clamp, true>,
     nofilter_affine<clamp, clamp>,       filter_affine<clamp, clamp, extract_low_bits_clamp_clamp>,
@@ -254,6 +783,9 @@ static const SkBitmapProcState::MatrixPr
     nofilter_scale <repeat, repeat, false>, filter_scale <repeat, repeat, extract_low_bits_general, false>,
     nofilter_affine<repeat, repeat>,        filter_affine<repeat, repeat, extract_low_bits_general>
 };
+
+#endif
+
 static const SkBitmapProcState::MatrixProc MirrorX_MirrorY_Procs[] = {
     nofilter_scale <mirror, mirror,  false>, filter_scale <mirror, mirror, extract_low_bits_general, false>,
     nofilter_affine<mirror, mirror>,         filter_affine<mirror, mirror, extract_low_bits_general>,
--- a/src/third_party/skia/src/core/SkBlitter_ARGB32.cpp
+++ b/src/third_party/skia/src/core/SkBlitter_ARGB32.cpp
@@ -11,6 +11,7 @@
 #include "src/core/SkCoreBlitters.h"
 #include "src/core/SkUtils.h"
 #include "src/core/SkXfermodePriv.h"
+#include "src/opts/SkBlitMask_opts.h"
 
 static inline int upscale_31_to_32(int value) {
     SkASSERT((unsigned)value <= 31);
@@ -1184,6 +1185,7 @@ static void drive(SkPMColor* dst, const
     }
 }
 
+#if 0
 static void blend_row_A8(SkPMColor* dst, const void* mask, const SkPMColor* src, int n) {
     auto cov = (const uint8_t*)mask;
     drive(dst, src, cov, n, [](U8x4 d, U8x4 s, U8x4 c) {
@@ -1192,6 +1194,7 @@ static void blend_row_A8(SkPMColor* dst,
         return s_aa + skvx::approx_scale(d, 255 - alpha);
     });
 }
+#endif
 
 static void blend_row_A8_opaque(SkPMColor* dst, const void* mask, const SkPMColor* src, int n) {
     auto cov = (const uint8_t*)mask;
@@ -1296,7 +1299,8 @@ void SkARGB32_Shader_Blitter::blitMask(c
         if (mask.fFormat == SkMask::kA8_Format && opaque) {
             blend_row = blend_row_A8_opaque;
         } else if (mask.fFormat == SkMask::kA8_Format) {
-            blend_row = blend_row_A8;
+            // blend_row_A8 has been ported to SkOpts, but not the others yet
+            blend_row = SkOpts::blit_row_s32a_a8;
         } else if (mask.fFormat == SkMask::kLCD16_Format && opaque) {
             blend_row = blend_row_LCD16_opaque;
         } else if (mask.fFormat == SkMask::kLCD16_Format) {
--- a/src/third_party/skia/src/core/SkOpts.cpp
+++ b/src/third_party/skia/src/core/SkOpts.cpp
@@ -58,6 +58,7 @@ namespace SkOpts {
     DEFINE_DEFAULT(create_xfermode);
 
     DEFINE_DEFAULT(blit_mask_d32_a8);
+    DEFINE_DEFAULT(blit_row_s32a_a8);
 
     DEFINE_DEFAULT(blit_row_color32);
     DEFINE_DEFAULT(blit_row_s32a_opaque);
@@ -89,6 +90,11 @@ namespace SkOpts {
     DEFINE_DEFAULT(S32_alpha_D32_filter_DXDY);
 
     DEFINE_DEFAULT(interpret_skvm);
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+    DEFINE_DEFAULT(S32_opaque_D32_filter_DX);
+#else
+    decltype(S32_opaque_D32_filter_DX) S32_opaque_D32_filter_DX = SK_OPTS_NS::S32_alpha_D32_filter_DX;
+#endif
 #undef DEFINE_DEFAULT
 
 #define M(st) (StageFn)SK_OPTS_NS::st,
--- a/src/third_party/skia/src/core/SkOpts.h
+++ b/src/third_party/skia/src/core/SkOpts.h
@@ -28,6 +28,7 @@ namespace SkOpts {
 
     extern void (*blit_mask_d32_a8)(SkPMColor*, size_t, const SkAlpha*, size_t, SkColor, int, int);
     extern void (*blit_row_color32)(SkPMColor*, const SkPMColor*, int, SkPMColor);
+    extern void (*blit_row_s32a_a8)(SkPMColor*, const void*, const SkPMColor*, int);
     extern void (*blit_row_s32a_opaque)(SkPMColor*, const SkPMColor*, int, U8CPU);
 
     // Swizzle input into some sort of 8888 pixel, {premul,unpremul} x {rgba,bgra}.
@@ -67,6 +68,9 @@ namespace SkOpts {
     extern void (*S32_alpha_D32_filter_DXDY)(const SkBitmapProcState&,
                                              const uint32_t* xy, int count, SkPMColor*);
 
+    extern void (*S32_opaque_D32_filter_DX)(const SkBitmapProcState&,
+                                            const uint32_t* xy, int count, SkPMColor*);
+
 #define M(st) +1
     // We can't necessarily express the type of SkJumper stage functions here,
     // so we just use this void(*)(void) as a stand-in.
--- a/src/third_party/skia/src/core/SkSpan.h
+++ b/src/third_party/skia/src/core/SkSpan.h
@@ -65,8 +65,10 @@ private:
 template <typename T, typename S>
 inline constexpr SkSpan<T> SkMakeSpan(T* p, S s) { return SkSpan<T>{p, SkTo<size_t>(s)}; }
 
-template <size_t N, typename T>
-inline constexpr SkSpan<T> SkMakeSpan(T(&a)[N]) { return SkSpan<T>{a, N}; }
+// *** Caused redefinition errors in v82 (but was OK in in v82??)
+//     but doesn't seem to be needed
+//template <size_t N, typename T>
+//inline constexpr SkSpan<T> SkMakeSpan(T(&a)[N]) { return SkSpan<T>{a, N}; }
 
 template <typename Container>
 inline auto SkMakeSpan(Container& c)
--- a/src/third_party/skia/src/opts/SkBitmapProcState_opts.h
+++ b/src/third_party/skia/src/opts/SkBitmapProcState_opts.h
@@ -387,6 +387,257 @@ static void decode_packed_coordinates_an
         }
     }
 
+#elif defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+
+#define S32_ALPHA_D32_FILTER_DX_1PIX_NEON(opt)               \
+            "ldr         %[x], [%[xy]], #4           \n\t"   \
+            "uxth        %[tmp2], %[x], ror #16      \n\t"   \
+            "lsl         %[tmp3], %[x], #2           \n\t"   \
+            "bic         %[tmp2], #3                 \n\t"   \
+            "uxth        %[tmp3], %[tmp3]            \n\t"   \
+            "add         %[tmp0], %[row0], %[tmp2]   \n\t"   \
+            "add         %[tmp1], %[row0], %[tmp3]   \n\t"   \
+            "add         %[tmp2], %[row1], %[tmp2]   \n\t"   \
+            "add         %[tmp3], %[row1], %[tmp3]   \n\t"   \
+            "lsr         %[x], #14                   \n\t"   \
+            "vldr        s0, [%[tmp0]]               \n\t"   \
+            "and         %[x], #0xf                  \n\t"   \
+            "vldr        s1, [%[tmp1]]               \n\t"   \
+            "vldr        s2, [%[tmp2]]               \n\t"   \
+            "vldr        s3, [%[tmp3]]               \n\t"   \
+            "vdup.16     d2, %[x]                    \n\t"   \
+            "vsub.i16    d3, d23, d2                 \n\t"   \
+            "vmull.u8    q2, d0, d31                 \n\t"   \
+            "vmlal.u8    q2, d1, d30                 \n\t"   \
+            "vmul.u16    d0, d4, d3                  \n\t"   \
+            "vmla.u16    d0, d5, d2                  \n\t"   \
+            "vshr.u16    d0, #8                      \n\t"   \
+            "vmul.u16    d0, d10                     \n\t"   \
+            opt"                                     \n\t"   \
+            "vshrn.u16   d0, q0, #8                  \n\t"   \
+            "vst1.32     {d0[0]}, [%[dst]:32]!       \n\t"   \
+
+void S32_alpha_D32_filter_DX(const SkBitmapProcState& s,
+                             const uint32_t* SK_RESTRICT xy,
+                             int count, SkPMColor* SK_RESTRICT colors) {
+    SkASSERT(count > 0 && colors != nullptr);
+    SkASSERT(s.fFilterQuality != kNone_SkFilterQuality);
+    SkASSERT(4 == s.fPixmap.info().bytesPerPixel());
+    SkASSERT(s.fAlphaScale <= 256);
+
+    int y0, y1, wy;
+    decode_packed_coordinates_and_weight(*xy++, &y0, &y1, &wy);
+
+    auto row0 = (const uint32_t*)( (const char*)s.fPixmap.addr() + y0 * s.fPixmap.rowBytes() ),
+         row1 = (const uint32_t*)( (const char*)s.fPixmap.addr() + y1 * s.fPixmap.rowBytes() );
+
+    uint32_t tmp0, tmp1, tmp2, tmp3, x;
+    __asm__ volatile (
+            "vpush       {q4-q5}                     \n\t"
+            "vmov.i16    d22, #0xf                   \n\t"
+            "vmov.i16    d23, #0x10                  \n\t"
+            "vmov.i32    q12, #0x3fff                \n\t"
+            "vdup.32     q13, %[row0]                \n\t"
+            "vdup.32     q14, %[row1]                \n\t"
+            "vdup.i8     d30, %[subY]                \n\t"
+            "vmov.i8     d31, #16                    \n\t"
+            "vdup.16     q5, %[alpha]                \n\t"
+            "vshl.i32    q12, #2                     \n\t"
+            "tst         %[dst], #0xc                \n\t"
+            "vsub.i8     d31, d30                    \n\t"
+            "beq         2f                          \n\t"
+
+            "1:                                      \n\t"
+            S32_ALPHA_D32_FILTER_DX_1PIX_NEON(
+            "add         %[tmp0], %[dst], #4         \n\t"
+            "subs        %[len], #1                  \n\t"
+            "it          ne                          \n\t"
+            "tstne       %[tmp0], #0xc"
+            )
+            "bne         1b                          \n\t"
+
+            "2:"
+            "subs        %[len], #4                  \n\t"
+            "bmi         13f                         \n\t"
+
+            "vld1.32     {q8}, [%[xy]]!              \n\t"
+            "vshr.u32    q9, q8, #16                 \n\t"
+            "vand        q9, q12                     \n\t"
+            "vadd.i32    q1, q13, q9                 \n\t"
+            "vshl.i32    q0, q8, #2                  \n\t"
+            "vand        q0, q12                     \n\t"
+            "vadd.i32    q2, q13, q0                 \n\t"
+            "vmov        %[tmp0], s4                 \n\t"
+            "vmov        %[tmp1], s5                 \n\t"
+            "vadd.i32    q3, q14, q9                 \n\t"
+            "vmov        %[tmp2], %[tmp3], d3        \n\t"
+
+            "11:                                     \n\t"
+            "vadd.i32    q4, q14, q0                 \n\t"
+            "vldr        s4, [%[tmp0]]               \n\t"
+            "vmov        %[tmp0], s8                 \n\t"
+            "vldr        s5, [%[tmp1]]               \n\t"
+            "vmov        %[tmp1], s9                 \n\t"
+            "vldr        s6, [%[tmp2]]               \n\t"
+            "vmov        %[tmp2], s10                \n\t"
+            "vldr        s7, [%[tmp3]]               \n\t"
+            "vmov        %[tmp3], s11                \n\t"
+            "vldr        s8, [%[tmp0]]               \n\t"
+            "vmov        %[tmp0], s12                \n\t"
+            "vldr        s9, [%[tmp1]]               \n\t"
+            "vmov        %[tmp1], s13                \n\t"
+            "vldr        s10, [%[tmp2]]              \n\t"
+            "vmov        %[tmp2], s14                \n\t"
+            "vldr        s11, [%[tmp3]]              \n\t"
+            "vmov        %[tmp3], s15                \n\t"
+            "vldr        s12, [%[tmp0]]              \n\t"
+            "vmov        %[tmp0], s16                \n\t"
+            "vldr        s13, [%[tmp1]]              \n\t"
+            "vmov        %[tmp1], s17                \n\t"
+            "vldr        s14, [%[tmp2]]              \n\t"
+            "vmov        %[tmp2], s18                \n\t"
+            "vldr        s15, [%[tmp3]]              \n\t"
+            "vmov        %[tmp3], s19                \n\t"
+            "vldr        s16, [%[tmp0]]              \n\t"
+            "vshrn.i32   d1, q8, #14                 \n\t"
+            "vldr        s17, [%[tmp1]]              \n\t"
+            "vand        d1, d22                     \n\t"
+            "vldr        s18, [%[tmp2]]              \n\t"
+            "vsub.i16    d0, d23, d1                 \n\t"
+            "vldr        s19, [%[tmp3]]              \n\t"
+            "vmull.u8    q10, d2, d31                \n\t"
+            "vmlal.u8    q10, d6, d30                \n\t"
+            "vmull.u8    q1, d3, d31                 \n\t"
+            "vmlal.u8    q1, d7, d30                 \n\t"
+            "vmull.u8    q3, d4, d31                 \n\t"
+            "subs        %[len], #4                  \n\t"
+            "vmlal.u8    q3, d8, d30                 \n\t"
+            "bmi         12f                         \n\t"
+
+            "  vld1.32     {q8}, [%[xy]]!            \n\t"
+            "vmull.u8    q2, d5, d31                 \n\t"
+            "vmlal.u8    q2, d9, d30                 \n\t"
+            "vmul.u16    d8, d20, d0[0]              \n\t"
+            "  vshr.u32    d18, d16, #16             \n\t"
+            "vmul.u16    d9, d21, d0[1]              \n\t"
+            "  vshr.u32    d19, d17, #16             \n\t"
+            "vmul.u16    d20, d2, d0[2]              \n\t"
+            "  vand        d18, d24                  \n\t"
+            "vmul.u16    d21, d3, d0[3]              \n\t"
+            "  vand        d19, d25                  \n\t"
+            "vmla.u16    d8, d6, d1[0]               \n\t"
+            "  vadd.i32    d2, d26, d18              \n\t"
+            "vmla.u16    d9, d7, d1[1]               \n\t"
+            "  vadd.i32    d3, d27, d19              \n\t"
+            "vmla.u16    d20, d4, d1[2]              \n\t"
+            "  vshl.i32    d0, d16, #2               \n\t"
+            "vmla.u16    d21, d5, d1[3]              \n\t"
+            "  vshl.i32    d1, d17, #2               \n\t"
+            "  vand        q0, q12                   \n\t"
+            "  vadd.i32    q2, q13, q0               \n\t"
+            "vshr.u16    q4, #8                      \n\t"
+            "vshr.u16    q10, #8                     \n\t"
+            "vmul.u16    q4, q5                      \n\t"
+            "vmul.u16    q10, q5                     \n\t"
+            "  vmov        %[tmp0], %[tmp1], d2      \n\t"
+            "  vadd.i32    q3, q14, q9               \n\t"
+            "  vmov        %[tmp2], %[tmp3], d3      \n\t"
+            "vshrn.u16   d8, q4, #8                  \n\t"
+            "vshrn.u16   d9, q10, #8                 \n\t"
+            "vst1.32     {q4}, [%[dst]:128]!         \n\t"
+            "b           11b                         \n\t"
+
+            "12:                                     \n\t"
+            "vmull.u8    q2, d5, d31                 \n\t"
+            "vmlal.u8    q2, d9, d30                 \n\t"
+            "vmul.u16    d8, d20, d0[0]              \n\t"
+            "vmul.u16    d9, d21, d0[1]              \n\t"
+            "vmul.u16    d20, d2, d0[2]              \n\t"
+            "vmul.u16    d21, d3, d0[3]              \n\t"
+            "vmla.u16    d8, d6, d1[0]               \n\t"
+            "vmla.u16    d9, d7, d1[1]               \n\t"
+            "vmla.u16    d20, d4, d1[2]              \n\t"
+            "vmla.u16    d21, d5, d1[3]              \n\t"
+            "vshr.u16    q4, #8                      \n\t"
+            "vshr.u16    q10, #8                     \n\t"
+            "vmul.u16    q4, q5                      \n\t"
+            "vmul.u16    q10, q5                     \n\t"
+            "vshrn.u16   d8, q4, #8                  \n\t"
+            "vshrn.u16   d9, q10, #8                 \n\t"
+            "vst1.32     {q4}, [%[dst]:128]!         \n\t"
+
+            "13:                                     \n\t"
+            "adds        %[len], #4-1                \n\t"
+            "bmi         22f                         \n\t"
+
+            "21:                                     \n\t"
+            S32_ALPHA_D32_FILTER_DX_1PIX_NEON("subs %[len], #1")
+            "bpl         21b                         \n\t"
+
+            "22:                                     \n\t"
+            "vpop        {q4-q5}                     \n\t"
+    : // Outputs
+             [dst]"+r"(colors),
+              [xy]"+r"(xy),
+             [len]"+r"(count),
+            [tmp0]"=&r"(tmp0),
+            [tmp1]"=&r"(tmp1),
+            [tmp2]"=&r"(tmp2),
+            [tmp3]"=&r"(tmp3),
+               [x]"=&r"(x)
+    : // Inputs
+            [alpha]"r"(s.fAlphaScale),
+             [row0]"r"(row0),
+             [row1]"r"(row1),
+             [subY]"r"(wy)
+    : // Clobbers
+            "cc", "memory"
+    );
+}
+
+        // Copied from just below
+        static void filter_and_scale_by_alpha(unsigned x, unsigned y,
+                                              SkPMColor a00, SkPMColor a01,
+                                              SkPMColor a10, SkPMColor a11,
+                                              SkPMColor *dst,
+                                              uint16_t scale) {
+            uint8x8_t vy, vconst16_8, v16_y, vres;
+            uint16x4_t vx, vconst16_16, v16_x, tmp, vscale;
+            uint32x2_t va0, va1;
+            uint16x8_t tmp1, tmp2;
+
+            vy = vdup_n_u8(y);                // duplicate y into vy
+            vconst16_8 = vmov_n_u8(16);       // set up constant in vconst16_8
+            v16_y = vsub_u8(vconst16_8, vy);  // v16_y = 16-y
+
+            va0 = vdup_n_u32(a00);            // duplicate a00
+            va1 = vdup_n_u32(a10);            // duplicate a10
+            va0 = vset_lane_u32(a01, va0, 1); // set top to a01
+            va1 = vset_lane_u32(a11, va1, 1); // set top to a11
+
+            tmp1 = vmull_u8(vreinterpret_u8_u32(va0), v16_y); // tmp1 = [a01|a00] * (16-y)
+            tmp2 = vmull_u8(vreinterpret_u8_u32(va1), vy);    // tmp2 = [a11|a10] * y
+
+            vx = vdup_n_u16(x);                // duplicate x into vx
+            vconst16_16 = vmov_n_u16(16);      // set up constant in vconst16_16
+            v16_x = vsub_u16(vconst16_16, vx); // v16_x = 16-x
+
+            tmp = vmul_u16(vget_high_u16(tmp1), vx);        // tmp  = a01 * x
+            tmp = vmla_u16(tmp, vget_high_u16(tmp2), vx);   // tmp += a11 * x
+            tmp = vmla_u16(tmp, vget_low_u16(tmp1), v16_x); // tmp += a00 * (16-x)
+            tmp = vmla_u16(tmp, vget_low_u16(tmp2), v16_x); // tmp += a10 * (16-x)
+
+            if (scale < 256) {
+                vscale = vdup_n_u16(scale);        // duplicate scale
+                tmp = vshr_n_u16(tmp, 8);          // shift down result by 8
+                tmp = vmul_u16(tmp, vscale);       // multiply result by scale
+            }
+
+            vres = vshrn_n_u16(vcombine_u16(tmp, vcreate_u16(0)), 8); // shift down result by 8
+            vst1_lane_u32(dst, vreinterpret_u32_u8(vres), 0);         // store result
+        }
+
+
 #else
 
     // The NEON code only actually differs from the portable code in the
@@ -533,6 +784,203 @@ static void decode_packed_coordinates_an
                                                        const uint32_t*, int, SkPMColor*) = nullptr;
 #endif
 
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+
+#define S32_OPAQUE_D32_FILTER_DX_1PIX_NEON(opt)              \
+            "ldr         %[x], [%[xy]], #4           \n\t"   \
+            "uxth        %[tmp2], %[x], ror #16      \n\t"   \
+            "lsl         %[tmp3], %[x], #2           \n\t"   \
+            "bic         %[tmp2], #3                 \n\t"   \
+            "uxth        %[tmp3], %[tmp3]            \n\t"   \
+            "add         %[tmp0], %[row0], %[tmp2]   \n\t"   \
+            "add         %[tmp1], %[row0], %[tmp3]   \n\t"   \
+            "add         %[tmp2], %[row1], %[tmp2]   \n\t"   \
+            "add         %[tmp3], %[row1], %[tmp3]   \n\t"   \
+            "lsr         %[x], #14                   \n\t"   \
+            "vldr        s0, [%[tmp0]]               \n\t"   \
+            "and         %[x], #0xf                  \n\t"   \
+            "vldr        s1, [%[tmp1]]               \n\t"   \
+            "vldr        s2, [%[tmp2]]               \n\t"   \
+            "vldr        s3, [%[tmp3]]               \n\t"   \
+            "vdup.16     d2, %[x]                    \n\t"   \
+            "vsub.i16    d3, d23, d2                 \n\t"   \
+            "vmull.u8    q2, d0, d31                 \n\t"   \
+            "vmlal.u8    q2, d1, d30                 \n\t"   \
+            "vmul.u16    d0, d4, d3                  \n\t"   \
+            "vmla.u16    d0, d5, d2                  \n\t"   \
+            opt"                                     \n\t"   \
+            "vshrn.u16   d0, q0, #8                  \n\t"   \
+            "vst1.32     {d0[0]}, [%[dst]:32]!       \n\t"   \
+
+void S32_opaque_D32_filter_DX(const SkBitmapProcState& s,
+                              const uint32_t* SK_RESTRICT xy,
+                              int count, SkPMColor* SK_RESTRICT colors) {
+    SkASSERT(count > 0 && colors != nullptr);
+    SkASSERT(s.fFilterQuality != kNone_SkFilterQuality);
+    SkASSERT(4 == s.fPixmap.info().bytesPerPixel());
+    SkASSERT(s.fAlphaScale == 256);
+
+    int y0, y1, wy;
+    decode_packed_coordinates_and_weight(*xy++, &y0, &y1, &wy);
+
+    auto row0 = (const uint32_t*)( (const char*)s.fPixmap.addr() + y0 * s.fPixmap.rowBytes() ),
+         row1 = (const uint32_t*)( (const char*)s.fPixmap.addr() + y1 * s.fPixmap.rowBytes() );
+
+    uint32_t tmp0, tmp1, tmp2, tmp3, x;
+    __asm__ volatile (
+            "vpush       {q4}                        \n\t"
+            "vmov.i16    d22, #0xf                   \n\t"
+            "vmov.i16    d23, #0x10                  \n\t"
+            "vmov.i32    q12, #0x3fff                \n\t"
+            "vdup.32     q13, %[row0]                \n\t"
+            "vdup.32     q14, %[row1]                \n\t"
+            "vdup.i8     d30, %[subY]                \n\t"
+            "vmov.i8     d31, #16                    \n\t"
+            "vshl.i32    q12, #2                     \n\t"
+            "tst         %[dst], #0xc                \n\t"
+            "vsub.i8     d31, d30                    \n\t"
+            "beq         2f                          \n\t"
+
+            "1:                                      \n\t"
+            S32_OPAQUE_D32_FILTER_DX_1PIX_NEON(
+            "add         %[tmp0], %[dst], #4         \n\t"
+            "subs        %[len], #1                  \n\t"
+            "it          ne                          \n\t"
+            "tstne       %[tmp0], #0xc"
+            )
+            "bne         1b                          \n\t"
+
+            "2:"
+            "subs        %[len], #4                  \n\t"
+            "bmi         13f                         \n\t"
+
+            "vld1.32     {q8}, [%[xy]]!              \n\t"
+            "vshr.u32    q9, q8, #16                 \n\t"
+            "vand        q9, q12                     \n\t"
+            "vadd.i32    q1, q13, q9                 \n\t"
+            "vshl.i32    q0, q8, #2                  \n\t"
+            "vand        q0, q12                     \n\t"
+            "vadd.i32    q2, q13, q0                 \n\t"
+            "vmov        %[tmp0], s4                 \n\t"
+            "vmov        %[tmp1], s5                 \n\t"
+
+            "11:                                     \n\t"
+            "vadd.i32    q3, q14, q9                 \n\t"
+            "vmov        %[tmp2], %[tmp3], d3        \n\t"
+            "vadd.i32    q4, q14, q0                 \n\t"
+            "vldr        s4, [%[tmp0]]               \n\t"
+            "vmov        %[tmp0], s8                 \n\t"
+            "vldr        s5, [%[tmp1]]               \n\t"
+            "vmov        %[tmp1], s9                 \n\t"
+            "vldr        s6, [%[tmp2]]               \n\t"
+            "vmov        %[tmp2], s10                \n\t"
+            "vldr        s7, [%[tmp3]]               \n\t"
+            "vmov        %[tmp3], s11                \n\t"
+            "vldr        s8, [%[tmp0]]               \n\t"
+            "vmov        %[tmp0], s12                \n\t"
+            "vldr        s9, [%[tmp1]]               \n\t"
+            "vmov        %[tmp1], s13                \n\t"
+            "vldr        s10, [%[tmp2]]              \n\t"
+            "vmov        %[tmp2], s14                \n\t"
+            "vldr        s11, [%[tmp3]]              \n\t"
+            "vmov        %[tmp3], s15                \n\t"
+            "vldr        s12, [%[tmp0]]              \n\t"
+            "vmov        %[tmp0], s16                \n\t"
+            "vldr        s13, [%[tmp1]]              \n\t"
+            "vmov        %[tmp1], s17                \n\t"
+            "vldr        s14, [%[tmp2]]              \n\t"
+            "vmov        %[tmp2], s18                \n\t"
+            "vldr        s15, [%[tmp3]]              \n\t"
+            "vmov        %[tmp3], s19                \n\t"
+            "vldr        s16, [%[tmp0]]              \n\t"
+            "vshrn.i32   d1, q8, #14                 \n\t"
+            "vldr        s17, [%[tmp1]]              \n\t"
+            "vand        d1, d22                     \n\t"
+            "vldr        s18, [%[tmp2]]              \n\t"
+            "vsub.i16    d0, d23, d1                 \n\t"
+            "vldr        s19, [%[tmp3]]              \n\t"
+            "vmull.u8    q10, d2, d31                \n\t"
+            "vmlal.u8    q10, d6, d30                \n\t"
+            "vmull.u8    q1, d3, d31                 \n\t"
+            "vmlal.u8    q1, d7, d30                 \n\t"
+            "vmull.u8    q3, d4, d31                 \n\t"
+            "subs        %[len], #4                  \n\t"
+            "vmlal.u8    q3, d8, d30                 \n\t"
+            "bmi         12f                         \n\t"
+
+            "  vld1.32     {q8}, [%[xy]]!            \n\t"
+            "vmull.u8    q2, d5, d31                 \n\t"
+            "vmlal.u8    q2, d9, d30                 \n\t"
+            "vmul.u16    d8, d20, d0[0]              \n\t"
+            "  vshr.u32    d18, d16, #16             \n\t"
+            "vmul.u16    d9, d21, d0[1]              \n\t"
+            "  vshr.u32    d19, d17, #16             \n\t"
+            "vmul.u16    d20, d2, d0[2]              \n\t"
+            "  vand        d18, d24                  \n\t"
+            "vmul.u16    d21, d3, d0[3]              \n\t"
+            "  vand        d19, d25                  \n\t"
+            "vmla.u16    d8, d6, d1[0]               \n\t"
+            "  vadd.i32    d2, d26, d18              \n\t"
+            "vmla.u16    d9, d7, d1[1]               \n\t"
+            "  vadd.i32    d3, d27, d19              \n\t"
+            "vmla.u16    d20, d4, d1[2]              \n\t"
+            "  vshl.i32    d0, d16, #2               \n\t"
+            "vmla.u16    d21, d5, d1[3]              \n\t"
+            "  vshl.i32    d1, d17, #2               \n\t"
+            "  vand        q0, q12                   \n\t"
+            "  vadd.i32    q2, q13, q0               \n\t"
+            "  vmov        %[tmp0], s4               \n\t"
+            "  vmov        %[tmp1], s5               \n\t"
+            "vshrn.u16   d8, q4, #8                  \n\t"
+            "vshrn.u16   d9, q10, #8                 \n\t"
+            "vst1.32     {q4}, [%[dst]:128]!         \n\t"
+            "b           11b                         \n\t"
+
+            "12:                                     \n\t"
+            "vmull.u8    q2, d5, d31                 \n\t"
+            "vmlal.u8    q2, d9, d30                 \n\t"
+            "vmul.u16    d8, d20, d0[0]              \n\t"
+            "vmul.u16    d9, d21, d0[1]              \n\t"
+            "vmul.u16    d20, d2, d0[2]              \n\t"
+            "vmul.u16    d21, d3, d0[3]              \n\t"
+            "vmla.u16    d8, d6, d1[0]               \n\t"
+            "vmla.u16    d9, d7, d1[1]               \n\t"
+            "vmla.u16    d20, d4, d1[2]              \n\t"
+            "vmla.u16    d21, d5, d1[3]              \n\t"
+            "vshrn.u16   d8, q4, #8                  \n\t"
+            "vshrn.u16   d9, q10, #8                 \n\t"
+            "vst1.32     {q4}, [%[dst]:128]!         \n\t"
+
+            "13:                                     \n\t"
+            "adds        %[len], #4-1                \n\t"
+            "bmi         22f                         \n\t"
+
+            "21:                                     \n\t"
+            S32_OPAQUE_D32_FILTER_DX_1PIX_NEON("subs %[len], #1")
+            "bpl         21b                         \n\t"
+
+            "22:                                     \n\t"
+            "vpop        {q4}                        \n\t"
+    : // Outputs
+             [dst]"+r"(colors),
+              [xy]"+r"(xy),
+             [len]"+r"(count),
+            [tmp0]"=&r"(tmp0),
+            [tmp1]"=&r"(tmp1),
+            [tmp2]"=&r"(tmp2),
+            [tmp3]"=&r"(tmp3),
+               [x]"=&r"(x)
+    : // Inputs
+            [row0]"r"(row0),
+            [row1]"r"(row1),
+            [subY]"r"(wy)
+    : // Clobbers
+            "cc", "memory"
+    );
+}
+
+#endif
+
 }  // namespace SK_OPTS_NS
 
 #endif
--- a/src/third_party/skia/src/opts/SkBlitMask_opts.h
+++ b/src/third_party/skia/src/opts/SkBlitMask_opts.h
@@ -226,6 +226,322 @@ namespace SK_OPTS_NS {
     }
 }
 
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+
+// These macros permit optionally-included features to be switched using a parameter to another macro
+#define YES(x) x
+#define NO(x)
+
+// How far ahead (pixels) to preload (undefine to disable prefetch) - determined empirically
+#define PREFETCH_DISTANCE "52"
+
+#ifdef PREFETCH_DISTANCE
+#define IF_PRELOAD YES
+#else
+#define IF_PRELOAD NO
+#endif
+
+/// Macro to load 1..7 source and mask pixels in growing powers-of-2 in size - suitable for leading pixels
+#define S32A_A8_LOAD_SM_LEADING_7(r0, r1, r2, r3, s_base, r4, m_base, opt1, opt2)                       \
+                opt1"                                                                           \n\t"   \
+                "tst         %[group_size], #1                                                  \n\t"   \
+                opt2"                                                                           \n\t"   \
+                "beq         1f                                                                 \n\t"   \
+                "vld1.8      {"#r4"[1]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[1],"#r1"[1],"#r2"[1],"#r3"[1]}, [%["#s_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+                "lsls        %[tmp], %[group_size], #30                                         \n\t"   \
+                "bpl         1f                                                                 \n\t"   \
+                "vld1.8      {"#r4"[2]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[2],"#r1"[2],"#r2"[2],"#r3"[2]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[3]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[3],"#r1"[3],"#r2"[3],"#r3"[3]}, [%["#s_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+                "bcc         1f                                                                 \n\t"   \
+                "vld1.8      {"#r4"[4]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[4],"#r1"[4],"#r2"[4],"#r3"[4]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[5]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[5],"#r1"[5],"#r2"[5],"#r3"[5]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[6]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[6],"#r1"[6],"#r2"[6],"#r3"[6]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[7]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[7],"#r1"[7],"#r2"[7],"#r3"[7]}, [%["#s_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+
+/// Macro to load or store 1..7 destination pixels in growing powers-of-2 in size - suitable for leading pixels
+#define S32A_A8_LOADSTORE_D_LEADING_7(ls, r0, r1, r2, r3, d_base)                                       \
+                "tst         %[group_size], #1                                                  \n\t"   \
+                "beq         1f                                                                 \n\t"   \
+                "v"#ls"4.8   {"#r0"[1],"#r1"[1],"#r2"[1],"#r3"[1]}, [%["#d_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+                "lsls        %[tmp], %[group_size], #30                                         \n\t"   \
+                "add         %[tmp], %["#d_base"], #4                                           \n\t"   \
+                "bpl         1f                                                                 \n\t"   \
+                "v"#ls"4.8   {"#r0"[2],"#r1"[2],"#r2"[2],"#r3"[2]}, [%["#d_base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[3],"#r1"[3],"#r2"[3],"#r3"[3]}, [%[tmp]:32], %[eight]       \n\t"   \
+                "1:                                                                             \n\t"   \
+                "bcc         1f                                                                 \n\t"   \
+                "v"#ls"4.8   {"#r0"[4],"#r1"[4],"#r2"[4],"#r3"[4]}, [%["#d_base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[5],"#r1"[5],"#r2"[5],"#r3"[5]}, [%[tmp]:32], %[eight]       \n\t"   \
+                "v"#ls"4.8   {"#r0"[6],"#r1"[6],"#r2"[6],"#r3"[6]}, [%["#d_base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[7],"#r1"[7],"#r2"[7],"#r3"[7]}, [%[tmp]:32], %[eight]       \n\t"   \
+                "1:                                                                             \n\t"   \
+
+/// Macro to load 1..7 source and mask pixels in shrinking powers-of-2 in size - suitable for trailing pixels
+#define S32A_A8_LOAD_SM_TRAILING_7(r0, r1, r2, r3, s_base, r4, m_base, opt1, opt2)                      \
+                opt1"                                                                           \n\t"   \
+                "lsls        %[tmp], %[group_size], #30                                         \n\t"   \
+                opt2"                                                                           \n\t"   \
+                "bcc         1f                                                                 \n\t"   \
+                "vld1.8      {"#r4"[0]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[0],"#r1"[0],"#r2"[0],"#r3"[0]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[1]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[1],"#r1"[1],"#r2"[1],"#r3"[1]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[2]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[2],"#r1"[2],"#r2"[2],"#r3"[2]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[3]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[3],"#r1"[3],"#r2"[3],"#r3"[3]}, [%["#s_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+                "bpl         1f                                                                 \n\t"   \
+                "vld1.8      {"#r4"[4]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[4],"#r1"[4],"#r2"[4],"#r3"[4]}, [%["#s_base"]:32]!          \n\t"   \
+                "vld1.8      {"#r4"[5]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[5],"#r1"[5],"#r2"[5],"#r3"[5]}, [%["#s_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+                "tst         %[group_size], #1                                                  \n\t"   \
+                "beq         1f                                                                 \n\t"   \
+                "vld1.8      {"#r4"[6]}, [%["#m_base"]]!                                        \n\t"   \
+                "vld4.8      {"#r0"[6],"#r1"[6],"#r2"[6],"#r3"[6]}, [%["#s_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+
+/// Macro to load or store 1..7 destination pixels in shrinking powers-of-2 in size - suitable for trailing pixels
+#define S32A_A8_LOADSTORE_D_TRAILING_7(ls, r0, r1, r2, r3, d_base)                                      \
+                "lsls        %[tmp], %[group_size], #30                                         \n\t"   \
+                "add         %[tmp], %["#d_base"], #4                                           \n\t"   \
+                "bcc         1f                                                                 \n\t"   \
+                "v"#ls"4.8   {"#r0"[0],"#r1"[0],"#r2"[0],"#r3"[0]}, [%["#d_base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[1],"#r1"[1],"#r2"[1],"#r3"[1]}, [%[tmp]:32], %[eight]       \n\t"   \
+                "v"#ls"4.8   {"#r0"[2],"#r1"[2],"#r2"[2],"#r3"[2]}, [%["#d_base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[3],"#r1"[3],"#r2"[3],"#r3"[3]}, [%[tmp]:32], %[eight]       \n\t"   \
+                "1:                                                                             \n\t"   \
+                "bpl         1f                                                                 \n\t"   \
+                "v"#ls"4.8   {"#r0"[4],"#r1"[4],"#r2"[4],"#r3"[4]}, [%["#d_base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[5],"#r1"[5],"#r2"[5],"#r3"[5]}, [%[tmp]:32], %[eight]       \n\t"   \
+                "1:                                                                             \n\t"   \
+                "tst         %[group_size], #1                                                  \n\t"   \
+                "beq         1f                                                                 \n\t"   \
+                "v"#ls"4.8   {"#r0"[6],"#r1"[6],"#r2"[6],"#r3"[6]}, [%["#d_base"]:32]!          \n\t"   \
+                "1:                                                                             \n\t"   \
+
+/// Macro to do shortcut testing for "over" compositing of 32bpp premultiplied ARGB source and 8-bit alpha mask
+#define S32A_A8_TEST(dst_adjust)                                                                        \
+                "vmov        %[mlo], %[mhi], d16                                                \n\t"   \
+                "vmov        %[alo], s6                                                         \n\t"   \
+                "vmov        %[ahi], s7                                                         \n\t"   \
+                "and         %[tmp], %[mlo], %[mhi]                                             \n\t"   \
+                "orrs        %[mlo], %[mhi]                                                     \n\t"   \
+                "it          ne                                                                 \n\t"   \
+                "orrsne      %[mlo], %[alo], %[ahi]                                             \n\t"   \
+                "it          eq                                                                 \n\t"   \
+                "addeq       %[dst], " dst_adjust "                                             \n\t"   \
+                "beq         9f                                                                 \n\t"   \
+                "and         %[tmp], %[alo]                                                     \n\t"   \
+                "and         %[tmp], %[ahi]                                                     \n\t"   \
+                "cmp         %[tmp], #-1                                                        \n\t"   \
+                "beq         5f                                                                 \n\t"   \
+
+/// Macro to do testing and "over" compositing of a group of 1..7 32bpp premultiplied ARGB source and 1..7 8-bit alpha mask leading or trailing pixels
+#define S32A_A8_7PIX_PROCESS(load_sm_7, loadstore_d_7, size)                                            \
+    do {                                                                                                \
+        __asm__ volatile (                                                                              \
+                /* Load the leading/trailing source pixels,                                             \
+                 * after initialising all the unused indexes from the first pixel                       \
+                 * so the all-opaque and all-transparent tests still work */                            \
+                load_sm_7(d0, d1, d2, d3, src, d16, msk,                                                \
+                "vld1.8      {d16[]}, [%[msk]]",                                                        \
+                "vld4.8      {d0[], d1[], d2[], d3[]}, [%[src]]")                                       \
+                S32A_A8_TEST("%[group_size], lsl #2")                                                   \
+                /* Translucency used, or a mixture of opaque and transparent */                         \
+                loadstore_d_7(ld, d4, d5, d6, d7, dst)                                                  \
+                "sub         %[dst], %[group_size], lsl #2                                      \n\t"   \
+                S32A_A8_8PIX_BLEND(, NO, NO)                                                      \
+                loadstore_d_7(st, d0, d1, d2, d3, dst)                                                  \
+                /* Drop through */                                                                      \
+                "9:                                                                             \n\t"   \
+        : /* Outputs */                                                                                 \
+                [mlo]"=&r"(mlo),                                                                        \
+                [mhi]"=&r"(mhi),                                                                        \
+                [alo]"=&r"(alo),                                                                        \
+                [ahi]"=&r"(ahi),                                                                        \
+                [tmp]"=&r"(tmp),                                                                        \
+                [src]"+r"(src),                                                                         \
+                [msk]"+r"(msk),                                                                         \
+                [dst]"+r"(dst)                                                                          \
+        : /* Inputs */                                                                                  \
+                [group_size]"r"(size),                                                                  \
+                     [eight]"r"(eight)                                                                  \
+        : /* Clobbers */                                                                                \
+                "cc", "memory"                                                                          \
+        );                                                                                              \
+    } while (0)
+
+/// Macro to do "over" compositing blending on 8 32bpp premultiplied ARGB source and 8 8-bit alpha mask pixels
+/// which are with either translucent or a mixture of opaque and transparent.
+/// Relies on A(x) to determine whether to emit code in ARM state (as opposed to Thumb state).
+/// @arg align           bit-alignment specifier on destination loads/stores (optional)
+/// @arg if_loadstore    YES or NO: whether to do load/store of destination
+/// @arg if_preload      YES or NO: whether to insert prefetch instructions
+#define S32A_A8_8PIX_BLEND(align, if_loadstore, if_preload)                                        \
+if_loadstore(   "vld4.8      {d4-d7}, [%[dst]"#align"]                                          \n\t")  \
+if_preload(     "sub         %[tmp], %[len], #1                                                 \n\t")  \
+                "vmull.u8    q9, d3, d16                                                        \n\t"   \
+if_preload(     "cmp         %[tmp], #" PREFETCH_DISTANCE "                                     \n\t")  \
+                "vmull.u8    q10, d0, d16                                                       \n\t"   \
+if_preload(     "it          cs                                                                 \n\t")  \
+if_preload(     "movcs       %[tmp], #" PREFETCH_DISTANCE "                                     \n\t")  \
+                "vmull.u8    q11, d1, d16                                                       \n\t"   \
+                "vmull.u8    q8, d2, d16                                                        \n\t"   \
+                "vrshr.u16   q1, q9, #8                                                         \n\t"   \
+if_preload(     "pld         [%[msk], %[tmp]]                                                   \n\t")  \
+                "vrshr.u16   q0, q10, #8                                                        \n\t"   \
+if_preload(     "pld         [%[src], %[tmp], lsl #2]                                           \n\t")  \
+                "vraddhn.u16 d3, q9, q1                                                         \n\t"   \
+if_preload(     "add         %[tmp], #32/4                                                      \n\t")  \
+                "vrshr.u16   q9, q11, #8                                                        \n\t"   \
+                "vrshr.u16   q12, q8, #8                                                        \n\t"   \
+                "vmvn        d2, d3                                                             \n\t"   \
+if_preload(     "pld         [%[dst], %[tmp], lsl #2]                                           \n\t")  \
+                "vraddhn.u16 d0, q10, q0                                                        \n\t"   \
+                "vmull.u8    q10, d4, d2                                                        \n\t"   \
+                "vmull.u8    q13, d5, d2                                                        \n\t"   \
+                "vmull.u8    q14, d6, d2                                                        \n\t"   \
+                "vmull.u8    q15, d7, d2                                                        \n\t"   \
+                "vrshr.u16   q2, q10, #8                                                        \n\t"   \
+                "vrshr.u16   q3, q13, #8                                                        \n\t"   \
+                "vraddhn.u16 d1, q11, q9                                                        \n\t"   \
+                "vrshr.u16   q9, q14, #8                                                        \n\t"   \
+                "vrshr.u16   q11, q15, #8                                                       \n\t"   \
+                "vraddhn.u16 d4, q10, q2                                                        \n\t"   \
+                "vraddhn.u16 d5, q13, q3                                                        \n\t"   \
+                "vraddhn.u16 d2, q8, q12                                                        \n\t"   \
+                "vraddhn.u16 d6, q14, q9                                                        \n\t"   \
+                "vraddhn.u16 d7, q15, q11                                                       \n\t"   \
+                "vadd.u8     q0, q2                                                             \n\t"   \
+                "vadd.u8     q1, q3                                                             \n\t"   \
+                "5:                                                                             \n\t"   \
+if_loadstore(   "vst4.8      {d0-d3}, [%[dst]"#align"]!                                         \n\t")  \
+
+#endif
+
+/*not static*/ inline
+void blit_row_s32a_a8(SkPMColor* dst, const void* vmask, const SkPMColor* src, int n) {
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+    const SkAlpha* msk = static_cast<const SkAlpha*>(vmask);
+    uint32_t tmp, mlo, mhi, alo, ahi;
+    const int eight = 8;
+    if (n < 15) {
+        // Too short to attempt aligned processing
+        if (n & 8) {
+            __asm__ (
+                    "vld1.8      {d16}, [%[msk]]!                                                   \n\t"
+                    "vld4.8      {d0-d3}, [%[src]]!                                                 \n\t"
+                    S32A_A8_TEST("#8*4")
+                    /* Translucency used, or a mixture of opaque and transparent */
+                    S32A_A8_8PIX_BLEND(, YES, NO)
+                    /* Drop through */
+                    "9:                                                                             \n\t"
+            :  /* Outputs */
+                    [mlo]"=&r"(mlo),
+                    [mhi]"=&r"(mhi),
+                    [alo]"=&r"(alo),
+                    [ahi]"=&r"(ahi),
+                    [tmp]"=&r"(tmp),
+                    [src]"+r"(src),
+                    [msk]"+r"(msk),
+                    [dst]"+r"(dst)
+            : /* Inputs */
+            : /* Clobbers */
+                    "cc", "memory"
+            );
+        }
+        if (n & 7)
+            S32A_A8_7PIX_PROCESS(S32A_A8_LOAD_SM_TRAILING_7, S32A_A8_LOADSTORE_D_TRAILING_7, n & 7);
+    } else {
+        // The last 0 - 7 pixels (starting from a 4-pixel boundary) are handled together
+        uintptr_t startrup = (uintptr_t) dst / sizeof (*dst) + 3;
+        uintptr_t end = (uintptr_t) dst / sizeof (*dst) + n;
+        size_t trailing;
+        if ((end & 3) == 0)
+            // No blocks of <8 pixels used at end in these cases
+            trailing = 0;
+        else
+            // If length (discounting alignment to 4-pixel boundaries) is an odd number of 4-pixels,
+            // assign 4 pixels to trailing end to avoid possibility of a leading run of exactly 4,
+            // otherwise use <4 trailing pixels to maximise central 8-pixel blocks
+            trailing = ((startrup ^ end) & 4) + (end & 3);
+        // The inner loop handles an integer number (0+) of 8-pixel blocks at 4-pixel boundaries
+        // The 0 - 7 pixels leading up to this are handled together
+        size_t leading = (n - trailing) & 7;
+
+        // Do leading pixels
+        if (leading != 0) {
+            n -= leading;
+            S32A_A8_7PIX_PROCESS(S32A_A8_LOAD_SM_LEADING_7, S32A_A8_LOADSTORE_D_LEADING_7, leading);
+        }
+
+        // Do inner loop
+        __asm__ (
+                "subs        %[len], #8                                                         \n\t"
+                "bcc         50f                                                                \n\t"
+
+                "10:                                                                            \n\t"
+                "vld1.8      {d16}, [%[msk]]!                                                   \n\t"
+                "vld4.8      {d0-d3}, [%[src]]!                                                 \n\t"
+                S32A_A8_TEST("#8*4")
+                /* Translucency used, or a mixture of opaque and transparent */
+                S32A_A8_8PIX_BLEND(:128, YES, IF_PRELOAD)
+                /* Drop through */
+                "9:                                                                             \n\t"
+                "subs        %[len], #8                                                         \n\t"
+                "bcs         10b                                                                \n\t"
+                "50:                                                                            \n\t"
+        : // Outputs
+                [mlo]"=&r"(mlo),
+                [mhi]"=&r"(mhi),
+                [alo]"=&r"(alo),
+                [ahi]"=&r"(ahi),
+                [tmp]"=&r"(tmp),
+                [src]"+r"(src),
+                [msk]"+r"(msk),
+                [dst]"+r"(dst),
+                [len]"+r"(n)
+        : // Inputs
+        : // Clobbers
+                "cc", "memory"
+        );
+
+        // Do trailing pixels.
+        if (n & 7)
+            S32A_A8_7PIX_PROCESS(S32A_A8_LOAD_SM_TRAILING_7, S32A_A8_LOADSTORE_D_TRAILING_7, n & 7);
+    }
+#else
+    auto mask = (const uint8_t*)vmask;
+
+#ifdef SK_SUPPORT_LEGACY_A8_MASKBLITTER
+    for (int i = 0; i < n; ++i) {
+        if (mask[i]) {
+            dst[i] = SkBlendARGB32(src[i], dst[i], mask[i]);
+        }
+    }
+#else
+    Sk4px::MapDstSrcAlpha(n, dst, src, mask, [](const Sk4px& d, const Sk4px& s, const Sk4px& aa) {
+        const auto s_aa = s.approxMulDiv255(aa);
+        return s_aa + d.approxMulDiv255(s_aa.alphas().inv());
+    });
+#endif
+#endif
+}
+
 }  // SK_OPTS_NS
 
 #endif//SkBlitMask_opts_DEFINED
--- a/src/third_party/skia/src/opts/SkBlitRow_opts.h
+++ b/src/third_party/skia/src/opts/SkBlitRow_opts.h
@@ -151,6 +151,9 @@ inline void blit_row_color32(SkPMColor*
 }
 
 #if defined(SK_ARM_HAS_NEON)
+#ifdef __ARM_64BIT_STATE
+// No attempt has been made to adapt the inline assembly version for AArch64
+// so fall back to the less performant version that uses intrinsics instead
 
 // Return a uint8x8_t value, r, computed as r[i] = SkMulDiv255Round(x[i], y[i]), where r[i], x[i],
 // y[i] are the i-th lanes of the corresponding NEON vectors.
@@ -187,8 +190,193 @@ static inline uint8x8_t SkPMSrcOver_neon
     return vadd_u8(src, SkMulDiv255Round_neon8(nalphas, dst));
 }
 
+#else // __ARM_64BIT_STATE
+// Inline ARM AArch32 assembly version
+
+// Macros to specify instructions to only include if targeting ARM or Thumb instruction sets
+#ifdef __thumb__
+#define A(x)
+#define T(x) x
+#else
+#define A(x) x
+#define T(x)
+#endif
+
+// These macros permit optionally-included features to be switched using a parameter to another macro
+#define YES(x) x
+#define NO(x)
+
+// How far ahead (pixels) to preload (undefine to disable prefetch) - determined empirically
+#undef PREFETCH_DISTANCE
+#define PREFETCH_DISTANCE "24"
+
+#ifdef PREFETCH_DISTANCE
+#define IF_PRELOAD YES
+#else
+#define IF_PRELOAD NO
 #endif
 
+/// Macro to load or store 1..7 pixels in growing powers-of-2 in size - suitable for leading pixels
+#define S32A_LOADSTORE_LEADING_7(ls, r0, r1, r2, r3, base, opt)                                       \
+                "tst         %[group_size], #1                                                \n\t"   \
+                opt"                                                                          \n\t"   \
+                "beq         1f                                                               \n\t"   \
+                "v"#ls"4.8   {"#r0"[1],"#r1"[1],"#r2"[1],"#r3"[1]}, [%["#base"]:32]!          \n\t"   \
+                "1:                                                                           \n\t"   \
+                "lsls        %[tmp], %[group_size], #30                                       \n\t"   \
+                "add         %[tmp], %["#base"], #4                                           \n\t"   \
+                "bpl         1f                                                               \n\t"   \
+                "v"#ls"4.8   {"#r0"[2],"#r1"[2],"#r2"[2],"#r3"[2]}, [%["#base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[3],"#r1"[3],"#r2"[3],"#r3"[3]}, [%[tmp]:32], %[eight]     \n\t"   \
+                "1:                                                                           \n\t"   \
+                "bcc         1f                                                               \n\t"   \
+                "v"#ls"4.8   {"#r0"[4],"#r1"[4],"#r2"[4],"#r3"[4]}, [%["#base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[5],"#r1"[5],"#r2"[5],"#r3"[5]}, [%[tmp]:32], %[eight]     \n\t"   \
+                "v"#ls"4.8   {"#r0"[6],"#r1"[6],"#r2"[6],"#r3"[6]}, [%["#base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[7],"#r1"[7],"#r2"[7],"#r3"[7]}, [%[tmp]:32], %[eight]     \n\t"   \
+                "1:                                                                           \n\t"   \
+
+/// Macro to load or store 1..7 pixels in shrink powers-of-2 in size - suitable for trailing pixels
+#define S32A_LOADSTORE_TRAILING_7(ls, r0, r1, r2, r3, base, opt)                                      \
+                "lsls        %[tmp], %[group_size], #30                                       \n\t"   \
+                "add         %[tmp], %["#base"], #4                                           \n\t"   \
+                opt"                                                                          \n\t"   \
+                "bcc         1f                                                               \n\t"   \
+                "v"#ls"4.8   {"#r0"[0],"#r1"[0],"#r2"[0],"#r3"[0]}, [%["#base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[1],"#r1"[1],"#r2"[1],"#r3"[1]}, [%[tmp]:32], %[eight]     \n\t"   \
+                "v"#ls"4.8   {"#r0"[2],"#r1"[2],"#r2"[2],"#r3"[2]}, [%["#base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[3],"#r1"[3],"#r2"[3],"#r3"[3]}, [%[tmp]:32], %[eight]     \n\t"   \
+                "1:                                                                           \n\t"   \
+                "bpl         1f                                                               \n\t"   \
+                "v"#ls"4.8   {"#r0"[4],"#r1"[4],"#r2"[4],"#r3"[4]}, [%["#base"]:32], %[eight] \n\t"   \
+                "v"#ls"4.8   {"#r0"[5],"#r1"[5],"#r2"[5],"#r3"[5]}, [%[tmp]:32], %[eight]     \n\t"   \
+                "1:                                                                           \n\t"   \
+                "tst         %[group_size], #1                                                \n\t"   \
+                "beq         1f                                                               \n\t"   \
+                "v"#ls"4.8   {"#r0"[6],"#r1"[6],"#r2"[6],"#r3"[6]}, [%["#base"]:32]!          \n\t"   \
+                "1:                                                                           \n\t"   \
+
+/// Macro to do testing and "over" compositing of a group of 1..7 32bpp premultiplied ARGB leading or trailing pixels
+#define S32A_OPAQUE_7PIX_PROCESS(loadstore_7, size)                                                   \
+    do {                                                                                              \
+        __asm__ volatile (                                                                            \
+                /* Load the leading/trailing source pixels,                                           \
+                 * after initialising all the unused indexes from the first pixel                     \
+                 * so the all-opaque and all-transparent tests still work */                          \
+                loadstore_7(ld, d0, d1, d2, d3, src,                                                  \
+                "vld4.8      {d0[],d1[],d2[],d3[]}, [%[src]]")                                        \
+                /* Test for all-opaque or all-transparent */                                          \
+                "vmov        %[alo], s6                                                       \n\t"   \
+                "vmov        %[ahi], s7                                                       \n\t"   \
+                "vmvn        d31, d3                                                          \n\t"   \
+                "orrs        %[tmp], %[alo], %[ahi]                                           \n\t"   \
+                "it          eq                                                               \n\t"   \
+                "addeq       %[dst], %[group_size], lsl #2                                    \n\t"   \
+                "beq         9f                                                               \n\t"   \
+                "cmp         %[alo], #-1                                                      \n\t"   \
+                "it          eq                                                               \n\t"   \
+                "cmpeq       %[ahi], #-1                                                      \n\t"   \
+                "beq         5f                                                               \n\t"   \
+                /* Translucency used, or a mixture of opaque and transparent */                       \
+                loadstore_7(ld, d20, d21, d22, d23, dst, )                                            \
+                "sub         %[dst], %[group_size], lsl #2                                    \n\t"   \
+                S32A_OPAQUE_8PIX_BLEND(, , q0, q1,, NO, NO, NO)                                       \
+                "5:                                                                           \n\t"   \
+                loadstore_7(st, d0, d1, d2, d3, dst, )                                                \
+                /* Drop through */                                                                    \
+                "9:                                                                           \n\t"   \
+        : /* Outputs */                                                                               \
+                [alo]"=&r"(alo),                                                                      \
+                [ahi]"=&r"(ahi),                                                                      \
+                [tmp]"=&r"(tmp),                                                                      \
+                [src]"+r"(src),                                                                       \
+                [dst]"+r"(dst)                                                                        \
+        : /* Inputs */                                                                                \
+                [group_size]"r"(size),                                                                \
+                     [eight]"r"(eight)                                                                \
+        : /* Clobbers */                                                                              \
+                "cc", "memory"                                                                        \
+        );                                                                                            \
+    } while (0)
+
+/// Macro to do testing and "over" compositing of an aligned group of 8 32bpp premultiplied ARGB leading or trailing pixels
+#define S32A_OPAQUE_8PIX_PROCESS(align, if_load)                                                      \
+    do {                                                                                              \
+        __asm__ (                                                                                     \
+if_load(        "vld4.8      {d0-d3}, [%[src]]!                                               \n\t")  \
+                /* Test for all-opaque or all-transparent */                                          \
+                "vmov        %[alo], s6                                                       \n\t"   \
+                "vmov        %[ahi], s7                                                       \n\t"   \
+                "vmvn        d31, d3                                                          \n\t"   \
+                "orrs        %[tmp], %[alo], %[ahi]                                           \n\t"   \
+                "it          eq                                                               \n\t"   \
+                "addeq       %[dst], #8*4                                                     \n\t"   \
+                "beq         9f                                                               \n\t"   \
+                "cmp         %[alo], #-1                                                      \n\t"   \
+                "it          eq                                                               \n\t"   \
+                "cmpeq       %[ahi], #-1                                                      \n\t"   \
+                "beq         5f                                                               \n\t"   \
+                /* Translucency used, or a mixture of opaque and transparent */                       \
+                S32A_OPAQUE_8PIX_BLEND(align, , q0, q1, "5:", YES, NO, NO)                            \
+                /* Drop through */                                                                    \
+                "9:                                                                           \n\t"   \
+        :  /* Outputs */                                                                              \
+                [alo]"=&r"(alo),                                                                      \
+                [ahi]"=&r"(ahi),                                                                      \
+                [tmp]"=&r"(tmp),                                                                      \
+                [src]"+r"(src),                                                                       \
+                [dst]"+r"(dst)                                                                        \
+        : /* Inputs */                                                                                \
+        : /* Clobbers */                                                                              \
+                "cc", "memory"                                                                        \
+        );                                                                                            \
+    } while (0)
+
+/// Macro to do "over" compositing blending on 8 32bpp premultiplied ARGB pixels
+/// which are with either translucent or a mixture of opaque and transparent.
+/// Relies on A(x) to determine whether to emit code in ARM state (as opposed to Thumb state).
+/// @arg align           bit-alignment specifier on destination loads/stores (optional)
+/// @arg other_src_alpha D-register specifier for alpha source in other bank (only IF_OVERLAP)
+/// @arg src0            Q-register specifier for blue/green source in this bank
+/// @arg src1            Q-register specifier for red/alpha source in this bank
+/// @arg opt             optional instruction to emit
+/// @arg if_loadstore    YES or NO: whether to do load/store
+/// @arg if_overlap      YES or NO: whether to interleave processing of next iteration
+/// @arg if_preload      YES or NO: whether to insert prefetch instructions
+#define S32A_OPAQUE_8PIX_BLEND(align, other_src_alpha, src0, src1, opt, if_loadstore, if_overlap, if_preload) \
+if_loadstore(   "vld4.8      {d20-d23}, [%[dst]"#align"]                                      \n\t")  \
+if_preload(     "sub         %[tmp], %[len], #1                                               \n\t")  \
+if_overlap(     "vmov        %[alo], %[ahi], "#other_src_alpha"                               \n\t")  \
+if_preload(     "cmp         %[tmp], #" PREFETCH_DISTANCE "                                   \n\t")  \
+                "vmull.u8    q8, d20, d31                                                     \n\t"   \
+if_preload(     "it          cs                                                               \n\t")  \
+if_preload(     "movcs       %[tmp], #" PREFETCH_DISTANCE "                                   \n\t")  \
+                "vmull.u8    q9, d21, d31                                                     \n\t"   \
+                "vmull.u8    q10, d22, d31                                                    \n\t"   \
+                "vmull.u8    q11, d23, d31                                                    \n\t"   \
+if_preload(     "pld         [%[src], %[tmp], lsl #2]                                         \n\t")  \
+                "vrshr.u16   q12, q8, #8                                                      \n\t"   \
+if_preload(     "add         %[tmp], #(32+32)/4                                               \n\t")  \
+                "vrshr.u16   q13, q9, #8                                                      \n\t"   \
+                "vrshr.u16   q14, q10, #8                                                     \n\t"   \
+                "vrshr.u16   q15, q11, #8                                                     \n\t"   \
+if_preload(     "pld         [%[dst], %[tmp], lsl #2]                                         \n\t")  \
+                "vraddhn.u16 d16, q8, q12                                                     \n\t"   \
+                "vraddhn.u16 d17, q9, q13                                                     \n\t"   \
+                "vraddhn.u16 d18, q10, q14                                                    \n\t"   \
+                "vraddhn.u16 d19, q11, q15                                                    \n\t"   \
+if_overlap(     "mvn         %[tmp], %[alo]                                                   \n\t")  \
+if_overlap(     "vmvn        d31, "#other_src_alpha"                                          \n\t")  \
+if_overlap(A(   "orr         %[alo], %[ahi]                                                   \n\t")) \
+                "vadd.i8     "#src0", q8                                                      \n\t"   \
+if_overlap(A(   "mvn         %[ahi], %[ahi]                                                   \n\t")) \
+                "vadd.i8     "#src1", q9                                                      \n\t"   \
+                opt"                                                                          \n\t"   \
+if_loadstore(   "vst4.8      {"#src0", "#src1"}, [%[dst]"#align"]!                            \n\t")  \
+
+#endif // __ARM_64BIT_STATE
+#endif // defined(SK_ARM_HAS_NEON)
+
 /*not static*/ inline
 void blit_row_s32a_opaque(SkPMColor* dst, const SkPMColor* src, int len, U8CPU alpha) {
     SkASSERT(alpha == 0xFF);
@@ -392,6 +580,10 @@ void blit_row_s32a_opaque(SkPMColor* dst
     }
 
 #elif defined(SK_ARM_HAS_NEON)
+#ifdef __ARM_64BIT_STATE
+    // No attempt has been made to adapt the inline assembly version for AArch64
+    // so fall back to the less performant version that uses intrinsics instead
+
     // Do 8-pixels at a time. A 16-pixels at a time version of this code was also tested, but it
     // underperformed on some of the platforms under test for inputs with frequent transitions of
     // alpha (corresponding to changes of the conditions [~]alpha_u64 == 0 below). It may be worth
@@ -438,6 +630,154 @@ void blit_row_s32a_opaque(SkPMColor* dst
         vst1_lane_u32(dst, vreinterpret_u32_u8(result), 0);
     }
     return;
+
+#else // __ARM_64BIT_STATE
+    // Inline ARM AArch32 assembly version
+    uint32_t tmp, alo, ahi;
+    const int eight = 8;
+    if (len < 15) {
+        // Too short to attempt aligned processing
+        if (len & 8)
+            S32A_OPAQUE_8PIX_PROCESS(, YES);
+        if (len & 7)
+            S32A_OPAQUE_7PIX_PROCESS(S32A_LOADSTORE_TRAILING_7, len & 7);
+    } else {
+        // The last 8 - 15 pixels (starting from a 4-pixel boundary) are handled together
+        uintptr_t startrup = (uintptr_t) dst / sizeof (*dst) + 3;
+        uintptr_t end = (uintptr_t) dst / sizeof (*dst) + len;
+        size_t trailing;
+        if ((end & 3) == 0)
+            // No blocks of <8 pixels used at end in these cases
+            trailing = 8;
+        else
+            // If length (discounting alignment to 4-pixel boundaries) is an odd number of 4-pixels,
+            // assign this to trailing end to avoid possibility of a leading run of exactly 4
+            trailing = 8 + ((startrup ^ end) & 4) + (end & 3);
+        // The inner loop handles an integer number (0+) of 16-pixel blocks at 4-pixel boundaries
+        // The 0..15 pixels leading up to this are handled together
+        size_t leading8 = (len - trailing) & 8;
+        size_t leading7 = (len - trailing) & 7;
+
+        // Do leading pixels
+        if (leading7 != 0) {
+            len -= leading7;
+            S32A_OPAQUE_7PIX_PROCESS(S32A_LOADSTORE_LEADING_7, leading7);
+        }
+        if (leading8 != 0) {
+            len -= 8;
+            S32A_OPAQUE_8PIX_PROCESS(:128, YES);
+        }
+
+        // Do inner loop
+        __asm__ (
+                // We enter and leave each iteration of the inner loop with the source
+                // pointer 8 pixels ahead and the destination pointer 8 pixels behind
+                // in order to permit good pipelining. The count of remaining pixels is
+                // reduced by 16 to allow the loop termination test to be combined with
+                // the decrementing of the remaining length.
+                "sub         %[dst], #8*4                                                     \n\t"
+                "vld4.8      {d0-d3}, [%[src]]!                                               \n\t"
+                "subs        %[len], #16                                                      \n\t"
+                "bcc         49f                                                              \n\t"
+
+                "10:                                                                          \n\t"
+                // Move alpha to ARM registers for comparison
+                "vmov        %[alo], s6                                                       \n\t"
+                "vmov        %[ahi], s7                                                       \n\t"
+                // Fetch source data for next iteration
+                "vld4.8      {d4-d7}, [%[src]]!                                               \n\t"
+                "add         %[dst], #8*4                                                     \n\t"
+                // Test if all source pixels are transparent (alpha=0)
+                "orrs        %[tmp], %[alo], %[ahi]                                           \n\t"
+                "beq         19f                                                              \n\t"
+                // Find inverse alpha in case full blending required
+                "vmvn        d31, d3                                                          \n\t"
+                // Test if all source pixels are opaque (alpha=0xff)
+                "cmp         %[alo], #-1                                                      \n\t"
+                "it          eq                                                               \n\t"
+                "cmpeq       %[ahi], #-1                                                      \n\t"
+                "bne         30f                                                              \n\t"
+                // Opaque case: copy source to destination
+                "vst4.8      {d0-d3}, [%[dst]:128]                                            \n\t"
+                // Drop through
+                "19:                                                                          \n\t"
+
+                // Move alpha to ARM registers for comparison
+                "vmov        %[alo], s14                                                      \n\t"
+                "vmov        %[ahi], s15                                                      \n\t"
+                // Fetch source data for next iteration
+                "vld4.8      {d0-d3}, [%[src]]!                                               \n\t"
+                "add         %[dst], #8*4                                                     \n\t"
+                // Test if all source pixels are transparent (alpha=0)
+                "orrs        %[tmp], %[alo], %[ahi]                                           \n\t"
+                "beq         29f                                                              \n\t"
+                // Find inverse alpha in case full blending required
+                "vmvn        d31, d7                                                          \n\t"
+                // Test if all source pixels are opaque (alpha=0xff)
+                "cmp         %[alo], #-1                                                      \n\t"
+                "it          eq                                                               \n\t"
+                "cmpeq       %[ahi], #-1                                                      \n\t"
+                "bne         40f                                                              \n\t"
+                // Opaque case: copy source to destination
+                "vst4.8      {d4-d7}, [%[dst]:128]                                            \n\t"
+                // Drop through
+                "29:                                                                          \n\t"
+                "subs        %[len], #16                                                      \n\t"
+                "bcs         10b                                                              \n\t"
+                "b           49f                                                              \n\t"
+
+                // Mixed or translucent pixels in d0-d3
+                "30:                                                                          \n\t"
+                S32A_OPAQUE_8PIX_BLEND(:128, d7, q0, q1,, YES, YES, IF_PRELOAD)
+A(              "teq         %[alo], #0                                                       \n\t")
+T(              "orrs        %[alo], %[alo], %[ahi]                                           \n\t")
+                "vld4.8      {d0-d3}, [%[src]]!                                               \n\t"
+                "beq         29b                                                              \n\t"
+A(              "orrs        %[tmp], %[tmp], %[ahi]                                           \n\t")
+T(              "orns        %[tmp], %[tmp], %[ahi]                                           \n\t")
+                "bne         40f                                                              \n\t"
+                "vst4.8      {d4-d7}, [%[dst]:128]                                            \n\t"
+                "b           29b                                                              \n\t"
+
+                // Mixed or translucent pixels in d4-d7
+                "40:                                                                          \n\t"
+                S32A_OPAQUE_8PIX_BLEND(:128, d3, q2, q3, \
+                "subs        %[len], #16", YES, YES, NO)
+                "bcc         50f                                                              \n\t"
+A(              "teq         %[alo], #0                                                       \n\t")
+T(              "orrs        %[alo], %[alo], %[ahi]                                           \n\t")
+                "vld4.8      {d4-d7}, [%[src]]!                                               \n\t"
+                "beq         19b                                                              \n\t"
+A(              "orrs        %[tmp], %[tmp], %[ahi]                                           \n\t")
+T(              "orns        %[tmp], %[tmp], %[ahi]                                           \n\t")
+                "bne         30b                                                              \n\t"
+                "vst4.8      {d0-d3}, [%[dst]:128]                                            \n\t"
+                "b           19b                                                              \n\t"
+
+                "49:                                                                          \n\t"
+                "add         %[dst], #8*4                                                     \n\t"
+                "50:                                                                          \n\t"
+        : // Outputs
+                [dst]"+r"(dst),
+                [src]"+r"(src),
+                [len]"+r"(len),
+                [alo]"+r"(alo),
+                [ahi]"+r"(ahi),
+                [tmp]"+r"(tmp)
+        : // Inputs
+        : // Clobbers
+                "cc", "memory"
+        );
+
+        // Do trailing pixels.
+        // There will always be more than 8 of these, and the first 8 are already in d0-d3
+        S32A_OPAQUE_8PIX_PROCESS(:128, NO);
+        if (len & 7)
+            S32A_OPAQUE_7PIX_PROCESS(S32A_LOADSTORE_TRAILING_7, len & 7);
+    }
+    return;
+
+#endif // __ARM_64BIT_STATE
 #endif
 
     while (len-- > 0) {
--- a/src/third_party/skia/src/opts/SkUtils_opts.h
+++ b/src/third_party/skia/src/opts/SkUtils_opts.h
@@ -34,7 +34,81 @@ namespace SK_OPTS_NS {
         memsetT(buffer, value, count);
     }
     /*not static*/ inline void memset32(uint32_t buffer[], uint32_t value, int count) {
+#if defined(SK_ARM_HAS_NEON) && !defined(__ARM_64BIT_STATE)
+        uint32_t *p1 = buffer;
+        uint32_t off;
+        __asm__ volatile (
+                "vdup.32     q0, %[p2]                     \n\t"
+                "cmp         %[n], #3+16                   \n\t"
+                "vdup.32     q1, %[p2]                     \n\t"
+                "blo         20f                           \n\t"
+
+                // Long case (at least one 16-byte-aligned 64-byte block)
+                "ands        %[off], %[buffer], #12        \n\t"
+                "bne         15f                           \n\t"
+
+                // 16-byte aligned. Set up inner loop
+                "10:                                       \n\t"
+                "mov         %[off], #64                   \n\t"
+                "sub         %[n], #16                     \n\t"
+                "add         %[p2], %[p1], #32             \n\t"
+
+                // Inner loop
+                "11:                                       \n\t"
+                "vst1.32     {q0-q1}, [%[p1] :128], %[off] \n\t"
+                "subs        %[n], #16                     \n\t"
+                "vst1.32     {q0-q1}, [%[p2] :128], %[off] \n\t"
+                "bhs         11b                           \n\t"
+
+                // Handle trailing 1..15 words
+                "12:                                       \n\t"
+                "lsls        %[n], #29                     \n\t"
+                "bcc         1f                            \n\t"
+                "vst1.32     {q0-q1}, [%[p1]]!             \n\t"
+                "1:                                        \n\t"
+                "bpl         1f                            \n\t"
+                "vst1.32     {q0}, [%[p1]]!                \n\t"
+                "1:                                        \n\t"
+                "lsls        %[n], #2                      \n\t"
+                "it          cs                            \n\t"
+                "vstmcs      %[p1]!, {d0}                  \n\t"
+                "it          mi                            \n\t"
+                "vstmmi      %[p1]!, {s0}                  \n\t"
+                "b           90f                           \n\t"
+
+                // Handle first 1..3 words to achieve 16-byte alignment
+                "15:                                       \n\t"
+                "rsb         %[off], #16                   \n\t"
+                "sub         %[n], %[off], lsr #2          \n\t"
+                "lsls        %[off], #29                   \n\t"
+                "it          mi                            \n\t"
+                "vstmmi      %[p1]!, {s0}                  \n\t"
+                "it          cs                            \n\t"
+                "vstmcs      %[p1]!, {d0}                  \n\t"
+                "b           10b                           \n\t"
+
+                // Short case
+                "20:                                       \n\t"
+                "cmp         %[n], #8                      \n\t"
+                "blo         12b                           \n\t"
+                "sub         %[n], #8                      \n\t"
+                "vst1.8      {q0-q1}, [%[p1]]!             \n\t"
+                "b           12b                           \n\t"
+
+                "90:                                       \n\t"
+        : // Outputs
+                 [p2]"+r"(value),
+                  [n]"+r"(count),
+                 [p1]"+r"(p1),
+                [off]"=&r"(off)
+        : // Inputs
+                [buffer]"r"(buffer)
+        : // Clobbers
+                "cc", "memory"
+        );
+#else
         memsetT(buffer, value, count);
+#endif
     }
     /*not static*/ inline void memset64(uint64_t buffer[], uint64_t value, int count) {
         memsetT(buffer, value, count);
