Index: chromium-113.0.5672.63/third_party/skia/BUILD.gn
===================================================================
--- chromium-113.0.5672.63.orig/third_party/skia/BUILD.gn
+++ chromium-113.0.5672.63/third_party/skia/BUILD.gn
@@ -282,6 +282,12 @@ opts("skx") {
   }
 }
 
+opts("vsx") {
+  enabled = current_cpu == "ppc64"
+  sources = skia_opts.vsx_sources
+  cflags = [ "-mcpu=power9", "-mtune=power9" ]
+}
+
 # Any feature of Skia that requires third-party code should be optional and use this template.
 template("optional") {
   if (invoker.enabled) {
@@ -1495,6 +1501,7 @@ skia_component("skia") {
     ":skx",
     ":sse42",
     ":ssse3",
+    ":vsx",
     ":webp_decode",
     ":webp_encode",
     ":wuffs",
@@ -1672,6 +1679,7 @@ skia_static_library("pathkit") {
     ":hsw",
     ":sse42",
     ":ssse3",
+    ":vsx",
   ]
 
   sources = []
Index: chromium-113.0.5672.63/third_party/skia/gn/shared_sources.gni
===================================================================
--- chromium-113.0.5672.63.orig/third_party/skia/gn/shared_sources.gni
+++ chromium-113.0.5672.63/third_party/skia/gn/shared_sources.gni
@@ -23,4 +23,5 @@ skia_opts = {
   avx_sources = avx
   hsw_sources = hsw
   skx_sources = skx
+  vsx_sources = ssse3
 }
Index: chromium-113.0.5672.63/third_party/skia/gn/skia/BUILD.gn
===================================================================
--- chromium-113.0.5672.63.orig/third_party/skia/gn/skia/BUILD.gn
+++ chromium-113.0.5672.63/third_party/skia/gn/skia/BUILD.gn
@@ -163,6 +163,8 @@ config("default") {
       "-mfpmath=sse",
     ]
     ldflags += [ "-m32" ]
+  } else if (current_cpu == "ppc64") {
+    cflags += [ "-mcpu=power9", "-mtune=power9" ]
   }
 
   if (malloc != "" && !is_win) {
Index: chromium-113.0.5672.63/third_party/skia/include/core/SkTypes.h
===================================================================
--- chromium-113.0.5672.63.orig/third_party/skia/include/core/SkTypes.h
+++ chromium-113.0.5672.63/third_party/skia/include/core/SkTypes.h
@@ -193,5 +193,41 @@ static constexpr uint32_t SK_InvalidGenI
 */
 static constexpr uint32_t SK_InvalidUniqueID = 0;
 
+//////////////////////////////////////////////////////////////////////
+// PPC defines
+
+#if defined(__powerpc64__) || defined(__PPC64__)
+    #define SK_CPU_PPC64
+#endif
+
+// Newer versions of clang and gcc for ppc64 ship with wrappers that translate
+// Intel vector intrinsics into PPC VSX instrinsics, so we can pretend to have
+// to be Intel. Currently, full API support for SSSE3 on POWER8 and later
+// processors.
+#if defined(__POWER8_VECTOR__) && defined(__has_include) && \
+  !defined(SK_CPU_SSE_LEVEL)
+
+    // Clang ships both Intel and PPC headers in its PPC version, storing the
+    // PPC compatibility in a subdirectory that the compiler will include before
+    // its standard library include directory.
+    #if (__has_include(<tmmintrin.h>) && !defined(__clang__)) || \
+         __has_include(<ppc_wrappers/tmmintrin.h>)
+        #define SK_CPU_SSE_LEVEL    SK_CPU_SSE_LEVEL_SSSE3
+    #elif (__has_include(<emmintrin.h>) && !defined(__clang__)) || \
+           __has_include(<ppc_wrappers/emmintrin.h>)
+        #define SK_CPU_SSE_LEVEL    SK_CPU_SSE_LEVEL_SSE2
+    #endif
+
+    #ifdef SK_CPU_SSE_LEVEL
+        #define SK_PPC64_HAS_SSE_COMPAT
+        #ifndef NO_WARN_X86_INTRINSICS
+            #define NO_WARN_X86_INTRINSICS
+        #endif
+        #if defined(__clang__)
+            #define SK_PPC64_CLANG_MFPPR_BUG
+        #endif
+    #endif
+#endif
+
 
 #endif
Index: chromium-113.0.5672.63/third_party/skia/src/core/SkSpinlock.cpp
===================================================================
--- chromium-113.0.5672.63.orig/third_party/skia/src/core/SkSpinlock.cpp
+++ chromium-113.0.5672.63/third_party/skia/src/core/SkSpinlock.cpp
@@ -31,7 +31,8 @@
 #endif
 
 // Renamed from "pause" to avoid conflict with function defined in unistd.h
-#if SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SSE2
+#if SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SSE2 && \
+    !defined(SK_PPC64_CLANG_MFPPR_BUG)
     #include <emmintrin.h>
     static void do_pause() { _mm_pause(); }
 #else
Index: chromium-113.0.5672.63/third_party/skia/src/opts/SkBitmapProcState_opts.h
===================================================================
--- chromium-113.0.5672.63.orig/third_party/skia/src/opts/SkBitmapProcState_opts.h
+++ chromium-113.0.5672.63/third_party/skia/src/opts/SkBitmapProcState_opts.h
@@ -21,7 +21,13 @@
 // The rest are scattershot at the moment but I want to get them
 // all migrated to be normal code inside SkBitmapProcState.cpp.
 
-#if SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SSE2
+#if defined(SK_PPC64_HAS_SSE_COMPAT)
+    #if SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SSSE3
+        #include <tmmintrin.h>
+    #else
+        #include <emmintrin.h>
+    #endif
+#elif SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SSE2
     #include <immintrin.h>
 #elif defined(SK_ARM_HAS_NEON)
     #include <arm_neon.h>
Index: chromium-113.0.5672.63/third_party/skia/src/opts/SkBlitRow_opts.h
===================================================================
--- chromium-113.0.5672.63.orig/third_party/skia/src/opts/SkBlitRow_opts.h
+++ chromium-113.0.5672.63/third_party/skia/src/opts/SkBlitRow_opts.h
@@ -100,7 +100,7 @@
 #endif
 
 #if SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SSE2
-    #include <immintrin.h>
+    #include <emmintrin.h>
 
     static inline __m128i SkPMSrcOver_SSE2(const __m128i& src, const __m128i& dst) {
         __m128i scale = _mm_sub_epi32(_mm_set1_epi32(256),
Index: chromium-113.0.5672.63/third_party/skia/src/opts/SkRasterPipeline_opts.h
===================================================================
--- chromium-113.0.5672.63.orig/third_party/skia/src/opts/SkRasterPipeline_opts.h
+++ chromium-113.0.5672.63/third_party/skia/src/opts/SkRasterPipeline_opts.h
@@ -48,6 +48,8 @@ using NoCtx = const void*;
     #define JUMPER_IS_SCALAR
 #elif defined(SK_ARM_HAS_NEON)
     #define JUMPER_IS_NEON
+#elif defined(SK_PPC64_HAS_SSE_COMPAT)
+    #define JUMPER_IS_VSX
 #elif SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SKX
     #define JUMPER_IS_SKX
 #elif SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_AVX2
@@ -80,6 +82,8 @@ using NoCtx = const void*;
     #include <math.h>
 #elif defined(JUMPER_IS_NEON)
     #include <arm_neon.h>
+#elif defined(JUMPER_IS_VSX)
+    #include <emmintrin.h>
 #else
     #include <immintrin.h>
 #endif
@@ -719,7 +723,7 @@ namespace SK_OPTS_NS {
         }
     }
 
-#elif defined(JUMPER_IS_SSE2) || defined(JUMPER_IS_SSE41) || defined(JUMPER_IS_AVX)
+#elif defined(JUMPER_IS_SSE2) || defined(JUMPER_IS_SSE41) || defined(JUMPER_IS_AVX) || defined(JUMPER_IS_VSX)
 template <typename T> using V = T __attribute__((ext_vector_type(4)));
     using F   = V<float   >;
     using I32 = V< int32_t>;
@@ -791,6 +795,8 @@ template <typename T> using V = T __attr
     SI F floor_(F v) {
     #if defined(JUMPER_IS_SSE41) || defined(JUMPER_IS_AVX)
         return _mm_floor_ps(v);
+    #elif defined(JUMPER_IS_VSX)
+        return vec_floor(v);
     #else
         F roundtrip = _mm_cvtepi32_ps(_mm_cvttps_epi32(v));
         return roundtrip - if_then_else(roundtrip > v, 1, 0);
@@ -1079,6 +1085,13 @@ SI F from_half(U16 h) {
 #elif defined(JUMPER_IS_HSW) || defined(JUMPER_IS_SKX)
     return _mm256_cvtph_ps(h);
 
+#elif defined(JUMPER_IS_VSX) && __has_builtin(__builtin_vsx_xvcvhpsp)
+    #if defined(SK_CPU_LENDIAN)
+        return __builtin_vsx_xvcvhpsp({h[0], 0, h[1], 0, h[2], 0, h[3], 0});
+    #else
+        return __builtin_vsx_xvcvhpsp({0, h[0], 0, h[1], 0, h[2], 0, h[3]});
+    #endif
+
 #else
     // Remember, a half is 1-5-10 (sign-exponent-mantissa) with 15 exponent bias.
     U32 sem = expand(h),
@@ -1100,6 +1113,13 @@ SI U16 to_half(F f) {
 #elif defined(JUMPER_IS_HSW) || defined(JUMPER_IS_SKX)
     return _mm256_cvtps_ph(f, _MM_FROUND_CUR_DIRECTION);
 
+#elif defined(JUMPER_IS_VSX) && __has_builtin(__builtin_vsx_xvcvsphp)
+    __vector unsigned short v = __builtin_vsx_xvcvsphp(f);
+    #if defined(SK_CPU_LENDIAN)
+        return U16{v[0], v[2], v[4], v[6]};
+    #else
+        return U16{v[1], v[3], v[5], v[7]};
+    #endif
 #else
     // Remember, a float is 1-8-23 (sign-exponent-mantissa) with 127 exponent bias.
     U32 sem = sk_bit_cast<U32>(f),
@@ -1133,7 +1153,7 @@ static constexpr size_t N = sizeof(F) /
     // instead of {b,a} on the stack.  Narrow stages work best for __vectorcall.
     #define ABI __vectorcall
     #define JUMPER_NARROW_STAGES 1
-#elif defined(__x86_64__) || defined(SK_CPU_ARM64)
+#elif defined(__x86_64__) || defined(SK_CPU_ARM64) || defined(SK_CPU_PPC64)
     // These platforms are ideal for wider stages, and their default ABI is ideal.
     #define ABI
     #define JUMPER_NARROW_STAGES 0
@@ -4517,7 +4537,8 @@ SI F sqrt_(F x) {
     __m256 lo,hi;
     split(x, &lo,&hi);
     return join<F>(_mm256_sqrt_ps(lo), _mm256_sqrt_ps(hi));
-#elif defined(JUMPER_IS_SSE2) || defined(JUMPER_IS_SSE41) || defined(JUMPER_IS_AVX)
+#elif defined(JUMPER_IS_SSE2) || defined(JUMPER_IS_SSE41) \
+  || defined(JUMPER_IS_AVX) || defined(JUMPER_IS_VSX)
     __m128 lo,hi;
     split(x, &lo,&hi);
     return join<F>(_mm_sqrt_ps(lo), _mm_sqrt_ps(hi));
@@ -4556,6 +4577,10 @@ SI F floor_(F x) {
     __m128 lo,hi;
     split(x, &lo,&hi);
     return join<F>(_mm_floor_ps(lo), _mm_floor_ps(hi));
+#elif defined(JUMPER_IS_VSX)
+    __m128 lo,hi;
+    split(x, &lo,&hi);
+    return join<F>(vec_floor(lo), vec_floor(hi));
 #else
     F roundtrip = cast<F>(cast<I32>(x));
     return roundtrip - if_then_else(roundtrip > x, F(1), F(0));
Index: chromium-113.0.5672.63/third_party/skia/src/opts/SkSwizzler_opts.h
===================================================================
--- chromium-113.0.5672.63.orig/third_party/skia/src/opts/SkSwizzler_opts.h
+++ chromium-113.0.5672.63/third_party/skia/src/opts/SkSwizzler_opts.h
@@ -12,7 +12,9 @@
 #include "src/base/SkVx.h"
 #include <utility>
 
-#if SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SSSE3
+#if defined(SK_PPC64_HAS_SSE_COMPAT)
+    #include <emmintrin.h>
+#elif SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SSSE3
     #include <immintrin.h>
 #elif defined(SK_ARM_HAS_NEON)
     #include <arm_neon.h>
